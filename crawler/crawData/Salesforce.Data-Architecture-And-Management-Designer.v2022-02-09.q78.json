[{"content":"A customer is operating in a highly reputated industry and is planning to implement SF. The customer information maintained in SF, includes the following:\nPersonally, identifiable information (PII)\nIP restrictions on profiles organized by Geographic location\nFinancial records that need to be private and accessible only by the assigned Sales associate.\nUser should not be allowed to export information from Salesforce.\nEnterprise security has mandate access to be restricted to users within a specific geography and detail monitoring of user activity. Which 3 Salesforce shield capabilities should a data architect recommend? Choose 3 answers:","options":["A. Prevent Sales users access to customer PII information","B. Transaction security policies to prevent export of SF Data.","C. Event monitoring to monitor all user activities","D. Encrypt Sensitive Customer information maintained in SF.","E. Restrict access to SF from users outside specific geography"],"answer":"B,D,E","title":"Question 1","explanation":""},{"content":"Universal Containers (UC) has a very large and complex Salesforce org with hundreds of validation rules and triggers. The triggers are responsible for system updates and data manipulation as records are created or updates by users. A majority of the automation tool within UC'' org were not designed to run during a data load. UC is importing 100,000 records into Salesforce across several objects over the weekend.\nWhat should a data architect do to mitigate any unwanted results during the import?","options":["A. Bulkily the trigger to handle import leads.","B. Ensure duplication and matching rules and defined.","C. Import the data in smaller batches over a 24-hour period.","D. Ensure validation rules, triggers and other automation tools are disabled."],"answer":"D","title":"Question 2","explanation":""},{"content":"Universal Containers (UC) has an Application custom object, which has tens of millions of records created in the past 5 years. UC needs the last 5 years of data to exist in Salesforce at all times for reporting and queries. UC is currently encountering performance issues when reporting and running queries on this Object using date ranges as filters. Which two options can be used to improve report performance?","options":["A. Ask support to create a skinny table for Application with the necessary reporting fields.","B. Add custom indexes to all fields on Application without a standard index.","C. Add custom indexes to the Date fields used for filtering the report.","D. Run multiple reports to get different pieces of the data and combine them."],"answer":"A,C","title":"Question 3","explanation":""},{"content":"UC has a variety of systems across its technology landscape, including SF, legacy enterprise resource planning (ERP) applications and homegrown CRM tools. UC has decided that they would like to consolidate all customer, opportunity and order data into Salesforce as part of its master data management (MDM) strategy.\nWhat are the 3 key steps that a data architect should take when merging data from multiple systems into Salesforce? Choose 3 answers:","options":["A. Analyze each system's data model and perform gap analysis","B. Install a 3rd party AppExchange tool to handle the merger","C. Create new fields to store additional values from all the systems.","D. Work with Stakeholders to define record and field survivorship rules","E. Utilize an ETL tool to merge, transform and de-duplicate data."],"answer":"A,D,E","title":"Question 4","explanation":""},{"content":"NTO uses salesforce to manage relationships and track sales opportunities. It has 10 million customers and 100 million opportunities. The CEO has been complaining 10 minutes to run and sometimes failed to load, throwing a time out error.\nWhich 3 options should help improve the dashboard performance?\nChoose 3 answers:","options":["A. Use selective queries to reduce the amount of data being returned.","B. De-normalize the data by reducing the number of joins.","C. Reduce the amount of data queried by archiving unused opportunity records.","D. Remove widgets from the dashboard to reduce the number of graphics loaded.","E. Run the dashboard for CEO and send it via email."],"answer":"A,B,C","title":"Question 5","explanation":""},{"content":"Universal Containers keeps its Account data in Salesforce and its Invoice data in a third -party ERP system. They have connected the Invoice data through a Salesforce external object. They want data from both Accounts and Invoices visible in one report in one place. What two approaches should an architect suggest for achieving this solution? Choose 2 answers","options":["A. Create a separate Salesforce report for Accounts and Invoices and combine them in a dashboard.","B. Create a Visualforce page combining Salesforce Account data and Invoice external object data.","C. Create a report combining data from the Account standard object and the Invoices external object.","D. Create a report in an external system combining Salesforce Account data and Invoice data from the ERP."],"answer":"B,D","title":"Question 6","explanation":""},{"content":"Northern Trail Outfitters has these simple requirements for a data export process:\nFile format should be in CSV.\nProcess should be scheduled and run once per week.\nThe expert should be configurable through the Salesforce UI.\nWhich tool should a data architect leverage to accomplish these requirements?","options":["A. Data loader","B. Bulk API","C. Data export wizard","D. Third-party ETL tool"],"answer":"C","title":"Question 7","explanation":""},{"content":"Cloud Kicks is launching a Partner Community, which will allow users to register shipment requests that are then processed by Cloud Kicks employees. Shipment requests contain header information, and then a list of no more than 5 items being shipped.\nFirst, Cloud Kicks will introduce its community to 6,000 customers in North America, and then to 24,000 customers worldwide within the next two years. Cloud Kicks expects 12 shipment requests per week per customer, on average, and wants customers to be able to view up to three years of shipment requests and use Salesforce reports.\nWhat is the recommended solution for the Cloud Kicks Data Architect to address the requirements?","options":["A. Create an external custom object to track shipment requests and a child external object to track shipment items. External objects are stored off-platform in Heroku's Postgres database.","B. Create a custom object to track shipment requests and a child custom object to track shipment items. Implement an archiving process that moves data off-platform after three years.","C. Create a custom object to track shipment requests with five lookup custom fields for each item being shipped Implement an archiving process that moves data off-platform after three years.","D. Create an external custom object to track shipment requests with five lookup custom fields for each item being shipped. External objects are stored off-platform in Heroku's Postgres database."],"answer":"B","title":"Question 8","explanation":""},{"content":"Universal Containers (UC) uses Salesforce for tracking opportunities (Opportunity). UC uses an internal ERP system for tracking deliveries and invoicing. The ERP system supports SOAP API and OData for bi-directional integration between Salesforce and the ERP system. UC has about one million opportunities. For each opportunity, UC sends 12 invoices, one per month. UC sales reps have requirements to view current invoice status and invoice amount from the opportunity page. When creating an object to model invoices, what should the architect recommend, considering performance and data storage space?","options":["A. Use Streaming API to get the current status from the ERP and display on the Opportunity page.","B. Create an external object Invoice _x with a Lookup relationship with Opportunity.","C. Create a custom object Invoice _c with a Lookup relationship with Opportunity.","D. Create a custom object Invoice _c with a master -detail relationship with Opportunity."],"answer":"B","title":"Question 9","explanation":""},{"content":"A large retail company has recently chosen SF as its CRM solution. They have the following record counts:\n2500000 accounts\n25000000 contacts\nWhen doing an initial performance test, the data architect noticed an extremely slow response for reports and list views.\nWhat should a data architect do to solve the performance issue?","options":["A. Load only the data that the users is permitted to access","B. Limit data loading to the 2000 most recently created records.","C. Create a skinny table to represent account and contact objects.","D. Add custom indexes on frequently searched account and contact objects fields"],"answer":"D","title":"Question 10","explanation":""},{"content":"UC has a legacy client server app that as a relational data base that needs to be migrated to salesforce.\nWhat are the 3 key actions that should be done when data modeling in salesforce?\nChoose 3 answers:","options":["A. Identify data elements to be persisted in salesforce.","B. Work with legacy application owner to analysis legacy data model.","C. Implement legacy data model within salesforce using custom fields.","D. Map legacy data to salesforce custom objects.","E. Map legacy data to salesforce objects."],"answer":"A,C,E","title":"Question 11","explanation":""},{"content":"Universal Containers has a rollup summary field on account to calculate the number of contacts associated with an account. During the account load, Salesforce is throwing an \"UNABLE _TO_LOCK_ROW\" error.\nWhich solution should a data architect recommend to resolve the error?","options":["A. Leverage Data Loader's platform API to load data.","B. Perform a batch job in parallel mode and reduce the batch size.","C. Defer rollup summary field calculation during data migration.","D. Perform a batch job in serial mode and reduce the batch size."],"answer":"D","title":"Question 12","explanation":""},{"content":"Which two best practices should be followed when using SOSL for searching?","options":["A. Use searches against single Objects for greater speed and accuracy.","B. Keep searches specific and avoid wildcards where possible.","C. Use SOSL option to ignore custom indexes as search fields are pre-indexed.","D. Use Find in \"ALL FIELDS\" for faster searches."],"answer":"B,D","title":"Question 13","explanation":""},{"content":"Universal Containers has a public website with several forms that create Lead records in Salesforce using the REST API. When designing these forms, which two techniques will help maintain a high level of data quality?","options":["A. Prefer picklist form fields over free text fields, where possible.","B. Use cookies to track when visitors submit multiple forms.","C. Do client-side validation of phone number and email field formats.","D. Ensure the website visitor is browsing using an HTTPS connection."],"answer":"A,C","title":"Question 14","explanation":""},{"content":"Cloud Kicks currently has a Public Read/Write sharing model for the company's Contacts. Cloud Kicks management team requests that only the owner of a contact record be allowed to delete that contact.\nWhat should an Architect do to meet these requirements?","options":["A. Check if the current user is NOT the owner by creating a validation rule on the Contact object.","B. Set the profile of the users to remove delete permission from the Contact object.","C. Set the Sharing settings as Public Read Only for the Contact object.","D. Check if the current user is NOT the owner by creating a \"before delete\" trigger."],"answer":"D","title":"Question 15","explanation":""},{"content":"UC is building a salesforce application to track contacts and their respective conferences that they have attended with the following requirements:\n1. Contacts will be stored in the standard contact object.\n2. Conferences will be stored in a custom conference__c object.\n3. Each contact may attend multiple conferences and each conference may be related to multiple contacts.\nHow should a data architect model the relationship between the contact and conference objects?","options":["A. Create a master detail relationship field on the Conference object.","B. Create a master detail relationship field on the Contact object.","C. Implement a Contact Conference junction object with master detail relationship to both contact and conference__c.","D. Create a lookup relationship field on contact object."],"answer":"C","title":"Question 16","explanation":""},{"content":"A large insurance provider is looking to implement Salesforce. The following exist.\n1. Multiple channel for lead acquisition\n2. Duplication leads across channels\n3. Poor customer experience and higher costs\nOn analysis, it found that there are duplicate leads that are resulting to mitigate the issues?","options":["A. Build process is manually search and merge duplicates.","B. Implement third-party solution to clean and event lead data.","C. Standard lead information across all channels.","D. Build a custom solution to identify and merge duplicate leads.","E. Implement de-duplication strategy to prevent duplicate leads"],"answer":"B,C,E","title":"Question 17","explanation":""},{"content":"NTO has decided to franchise its brand. Upon implementation, 1000 franchisees will be able to access BTO's product information and track large customer sales and opportunities through a portal. The Franchisees will also be able to run monthly and quarterly sales reports and projections as well as view the reports in dashboards.\nWhich licenses does NTO need to provide these features to the Franchisees?","options":["A. Customer Community license","B. Lightning Platform license","C. Partner Community license","D. Salesforce Sales Cloud license"],"answer":"C","title":"Question 18","explanation":""},{"content":"Universal Containers (CU) is in the process of implementing an enterprise data warehouse (EDW). UC needs to extract 100 million records from Salesforce for migration to the EDW.\nWhat data extraction strategy should a data architect use for maximum performance?","options":["A. Install a third-party AppExchange tool.","B. Use the Bulk API in parallel mode.","C. Call the REST API in successive queries.","D. Utilize PK Chunking with the Bulk API."],"answer":"D","title":"Question 19","explanation":""},{"content":"DreamHouse Realty has a legacy system that captures Branch Offices and Transactions. DreamHouse Realty has 15 Branch Offices. Transactions can relate to any Branch Office. DreamHouse Realty has created hundreds of thousands of Transactions per year.\nA Data Architect needs to denormalize this data model into a single Transaction object with a Branch Office picklist.\nWhat are two important considerations for the Data Architect in this scenario? (Choose two.)","options":["A. Limitations on Org data storage.","B. Bulk API limitations on picklist fields.","C. Limitations on master-detail relationships.","D. Standard list view in-line editing."],"answer":"A,B","title":"Question 20","explanation":""},{"content":"Universal Containers is planning out their archiving and purging plans going forward for their custom objects Topic__c and Comment__c. Several options are being considered, including analytics snapshots, offsite storage, scheduled purges, etc. Which three questions should be considered when designing an appropriate archiving strategy?","options":["A. Which profiles and users currently have access to these custom object records?","B. How many fields are defined on the custom objects that need to be archived?","C. Are there any regulatory restrictions that will influence the archiving and purging plans?","D. Will the data being archived need to be reported on or accessed in any way in the future?","E. If reporting is necessary, can the information be aggregated into fewer, summary records?"],"answer":"C,D,E","title":"Question 21","explanation":""},{"content":"An architect is planning on having different batches to load one million Opportunities into Salesforce using the Bulk API in parallel mode. What should be considered when loading the Opportunity records?","options":["A. Create indexes on Opportunity object text fields.","B. Sort batches by Name field values.","C. Order batches by Auto -number field.","D. Group batches by the AccountId field."],"answer":"C","title":"Question 22","explanation":""},{"content":"Universal Containers has a large number of Opportunity fields (100) that they want to track field history on. Which two actions should an architect perform in order to meet this requirement? Choose 2 answers","options":["A. Use Analytic Snapshots to store a copy of the record when changed.","B. Select the 100 fields in the Opportunity Set History Tracking page.","C. Create a custom object to store a copy of the record when changed.","D. Create a custom object to store the previous and new field values."],"answer":"C,D","title":"Question 23","explanation":""},{"content":"A customer wants to maintain geographic location information including latitude and longitude in a custom object. What would a data architect recommend to satisfy this requirement?","options":["A. Create a geolocation custom field to maintain this requirement","B. Create formula fields with geolocation function for this requirement.","C. Create custom fields to maintain latitude and longitude information","D. Recommend app exchange packages to support this requirement."],"answer":"C","title":"Question 24","explanation":""},{"content":"Get Cloudy Consulting monitors 15,000 servers, and these servers automatically record their status every 10 minutes. Because of company policy, these status reports must be maintained for 5 years. Managers at Get Cloudy Consulting need access to up to one week's worth of these status reports with all of their details.\nAn Architect is recommending what data should be integrated into Salesforce and for how long it should be stored in Salesforce.\nWhich two limits should the Architect be aware of? (Choose two.)","options":["A. Webservice callout limits","B. API Request limits","C. Workflow rule limits","D. Data storage limits"],"answer":"B,D","title":"Question 25","explanation":""},{"content":"Salesforce is being deployed in Ursa Major Solar's disparate, multi-system ERP environment. Ursa major Solar wants to maintain data synchronization between systems.\nWhich two techniques should be used to achieve this goal? (Choose two.)","options":["A. Build synchronization reports and dashboards.","B. Utilize an MDM strategy to outline a single source of truth.","C. Integrate Salesforce with the ERP environment.","D. Utilize workbench to update files within systems."],"answer":"B,C","title":"Question 26","explanation":""},{"content":"To avoid creating duplicate Contacts, a customer frequently uses Data Loader to upsert Contact records into Salesforce. What common error should the data architect be aware of when using upsert?","options":["A. Errors with using the wrong external Id will cause the load to fail.","B. Errors with duplicate external Id values within the same CSV file.","C. Errors when a duplicate Contact name is found cause upsert to fail.","D. Errors with records being updated and inserted in the same CSV file."],"answer":"B","title":"Question 27","explanation":""},{"content":"Universal Containers (UC) has a multi-level master-detail relationship for opportunities, a custom opportunity line item object, and a custom discount request. UC has opportunity as master and custom line item object as detail in master-detail relationship. UC also has a custom line item object as master and a custom discount request object as detail in another master-detail relationship. UC has a requirement to show all sums of discounts across line items at an opportunity level. What is the recommended solution to address these requirements?","options":["A. Remove the master-detail relationships and rely completely on workflow/triggers to summarize the discount amount.","B. Roll-up discount request amount at the line-item-level and line-item-level summary discount at the opportunity level.","C. Update the master-detail relationships to lookup relationships in order to allow the discount amount to roll up.","D. Use roll-up for the line-item-level summary and a trigger for the opportunity amount summary, as only one level roll-up is allowed."],"answer":"B","title":"Question 28","explanation":""},{"content":"The architect is planning a large data migration for Universal Containers from their legacy CRM system to Salesforce. What three things should the architect consider to optimize performance of the data migration? Choose 3 answers","options":["A. Remove custom indexes on the data being loaded.","B. Determine if the legacy system is still in use.","C. Defer sharing calculations of the Salesforce Org.","D. Review the time zones of the User loading the data.","E. Deactivate approval processes and workflow rules."],"answer":"A,C,E","title":"Question 29","explanation":""},{"content":"NTO has 1 million customer records spanning 25 years. As part of its new SF project, NTO would like to create a master data management strategy to help preserve the history and relevance of its customer data.\nWhich 3 activities will be required to identify a successful master data management strategy? Choose 3 answers:","options":["A. Identify data to be replicated","B. Define the systems of record for critical data","C. Create a data archive strategy","D. Install a data warehouse","E. Choose a Business Intelligence tool."],"answer":"A,B,C","title":"Question 30","explanation":""},{"content":"Ursa Major Solar has defined a new Data Quality Plan for their Salesforce data.\nWhich two approaches should an Architect recommend to enforce the plan throughout the organization? (Choose two.)","options":["A. Enforce critical business processes by using Workflow, Validation Rules, and Apex code.","B. Schedule a weekly dashboard displaying records that are missing information to be sent to managers for review.","C. Ensure all data is stored in an external system and set up an integration to Salesforce for view-only access.","D. Schedule reports that will automatically catch duplicates and merge or delete the records every week."],"answer":"A,B","title":"Question 31","explanation":""},{"content":"Universal Containers (UC) has a Salesforce instance with over 10.000 Account records. They have noticed similar, but not identical. Account names and addresses. What should UC do to ensure proper data quality?","options":["A. Run a report, find Accounts whose name starts with the same five characters, then merge those Accounts.","B. Enable Account de -duplication by creating matching rules in Salesforce, which will mass merge duplicate Accounts.","C. Make the Account Owner clean their Accounts' addresses, then merge Accounts with the same address.","D. Use a service to standardize Account addresses, then use a 3rd -party tool to merge Accounts based on rules."],"answer":"B","title":"Question 32","explanation":""},{"content":"Universal Container is using Salesforce for Opportunity management and enterprise resource planning (ERP) for order management. Sales reps do not have access to the ERP and have no visibility into order status.\nWhat solution a data architect recommend to give the sales team visibility into order status?","options":["A. leverage Salesforce Connect top bring the order line item from the legacy system to Salesforce.","B. Build real-time integration to pull order line items into Salesforce when viewing orders.","C. Build batch jobs to push order line items to salesforce.","D. Leverage Canvas to bring the order management UI in to the Salesforce tab."],"answer":"A","title":"Question 33","explanation":""},{"content":"Universal Containers (UC) wants to ensure their data on 100,000 Accounts pertaining mostly to US-based companies is enriched and cleansed on an ongoing basis. UC is looking for a solution that allows easy monitoring of key data quality metrics. What should be the recommended solution to meet this requirement?","options":["A. Use declarative approach by installing and configuring Data.com Prospector to monitor Account data quality.","B. Implement Batch Apex that calls out a third-party data quality API in order to monitor Account data quality.","C. Use a declarative approach by installing and configuring Data.com Clean to monitor Account data quality.","D. Implement an Apex Trigger on Account that queries a third-party data quality API to monitor Account data quality."],"answer":"C","title":"Question 34","explanation":""},{"content":"UC needs to load a large volume of leads into salesforce on a weekly basis. During this process the validation rules are disabled.\nWhat should a data architect recommend to ensure data quality is maintained in salesforce.","options":["A. Allow validation rules to be activated during the load of leads into salesforce.","B. Activate validation rules once the leads are loaded into salesforce to maintain quality.","C. Ensure the lead data is preprocessed for quality before loading into salesforce.","D. Develop custom APEX batch process to improve quality once the load is completed."],"answer":"D","title":"Question 35","explanation":""},{"content":"NTO has implemented salesforce for its sales users. The opportunity management in salesforce is implemented as follows:\n1. Sales users enter their opportunities in salesforce for forecasting and reporting purposes.\n2. NTO has a product pricing system (PPS) that is used to update opportunity amount field on opportunities on a daily basis.\n3. PPS is the trusted source within the NTO for opportunity amount.\n4. NTO uses opportunity forecast for its sales planning and management.\nSales users have noticed that their updates to the opportunity amount field are overwritten when PPS updates their opportunities.\nHow should a data architect address this overriding issue?","options":["A. Change PPS integration to update only opportunity amount fields when values is NULL.","B. Create a custom field for opportunity amount that PPS updates separating the field that sales user updates.","C. Change opportunity amount field access to read only for sales users using field level security.","D. Create a custom field for opportunity amount that sales users update separating the fields that PPS updates."],"answer":"C","title":"Question 36","explanation":""},{"content":"Universal Containers has deployed Salesforce for case management The company is having difficulty understanding what percentage of cases are resolved from the initial call to their support organization. What first step is recommended to implement a reporting solution to measure the support reps case closure rates?","options":["A. Create Contact and Opportunity Reports and Dashboards.","B. Install AppExchange packages for available reports.","C. Create a report on Case analytic snapshots.","D. Enable field history tracking on the Case object."],"answer":"D","title":"Question 37","explanation":""},{"content":"Northern trail Outfitters (NTO) uses Sales Cloud and service Cloud to manage sales and support processes. Some of NTOs team are complaining they see new fields on their page unsure of which values need be input. NTO is concerned about lack of governance in making changes to Salesforce.\nWhich governance measure should a data architect recommend to solve this issue?","options":["A. Create reports to identify which users are leaving blank, and use external data sources o agreement the missing data.","B. Create validation rules with error messages to explain why the fields is used","C. Create and manage a data dictionary and ups a governance process for changes made to common objects.","D. Add description fields to explain why the field is used, and mark the field as required."],"answer":"C","title":"Question 38","explanation":""},{"content":"Which three characteristics of a Skinny table help improve report and query performance?","options":["A. Skinny tables do not include records that are available in the recycle bin.","B. Skinny tables are kept in sync with changes to data in the source tables.","C. Skinny tables can be used to create custom indexes on multi-select picklist fields.","D. Skinny tables can contain frequently used fields and thereby help avoid joins.","E. Skinny tables provide a view across multiple objects for easy access to combined data."],"answer":"B,D,E","title":"Question 39","explanation":""},{"content":"Universal Containers has millions of rows of data in Salesforce that are being used in reports to evaluate historical trends. Performance has become an issue, as well as data storage limits. Which two strategies should be recommended when talking with stakeholders?","options":["A. Use Data Loader to extract data, aggregate it, and write it back to a custom object, then delete the original records.","B. Configure the Salesforce Archiving feature to archive older records and remove them from the data storage limits.","C. Combine Analytics Snapshots with a purging plan by reporting on the snapshot data and deleting the original records.","D. Use scheduled batch Apex to copy aggregate information into a custom object and delete the original records."],"answer":"B,D","title":"Question 40","explanation":""},{"content":"Universal containers is implementing Salesforce lead management. UC Procure lead data from multiple sources and would like to make sure lead data as company profile and location information. Which solution should a data architect recommend to make sure lead data has both profile and location information? Option","options":["A. Ask sales people to search for populating company profile and location data","B. Run reports to identify records which does not have company profile and location data","C. Leverage external data providers populate company profile and location data","D. Export data out of Salesforce and send to another team to populate company profile and location data"],"answer":"B","title":"Question 41","explanation":""},{"content":"Universal Containers has 30 million case records. The Case object has 80 fields. Agents are reporting performance issues and time-outs while running case reports in the Salesforce org.\nWhich solution should a data architect recommend to improve reporting performance?","options":["A. Create a custom object to store aggregate data and run reports.","B. Build reports using custom Lightning components.","C. Move data off of the platform and run reporting outside Salesforce, and give access to reports.","D. Contact Salesforce support to enable skinny table for cases."],"answer":"A","title":"Question 42","explanation":""},{"content":"Universal Containers is integrating a new Opportunity engagement system with Salesforce. According to their Master Data Management strategy, Salesforce is the system of record for Account, Contact, and Opportunity dat a. However, there does seem to be valuable Opportunity data in the new system that potentially conflicts with what is stored in Salesforce. What is the recommended course of action to appropriately integrate this new system?","options":["A. Stakeholders should be brought together to discuss the appropriate data strategy moving forward.","B. A policy should be adopted so that the system whose record was most recently updated should prevail in conflicts.","C. The Opportunity engagement system should become the system of record for Opportunity records.","D. The MDM strategy defines Salesforce as the system of record, so Salesforce Opportunity values prevail in all conflicts."],"answer":"A","title":"Question 43","explanation":""},{"content":"Universal Containers has defined a new Data Quality Plan for their Salesforce data and wants to know how they can enforce it throughout the organization. Which two approaches should an architect recommend to enforce this new plan?\nChoose 2 answers","options":["A. Store all data in an external system and set up an integration to Salesforce for view -only access.","B. Schedule reports that will automatically catch duplicates and merge or delete the records every week.","C. Use Workflow, Validation Rules, and Force.com code (Apex) to enforce critical business processes.","D. Schedule a weekly dashboard displaying records that are missing information to be sent to managers for review."],"answer":"C,D","title":"Question 44","explanation":""},{"content":"Universal Container require all customers to provide either a phone number of an email address when registering for an account.\nWhat should the data architect use to ensure this requirement is met?","options":["A. Apex Class","B. Process Builder","C. required Fields","D. validation Rule"],"answer":"D","title":"Question 45","explanation":""},{"content":"Universal Containers (UC) has users complaining about reports timing out or simply taking too long to run What two actions should the data architect recommend to improve the reporting experience? Choose 2 answers","options":["A. Enable Divisions for large data objects.","B. Share each report with fewer users.","C. Create one skinny table per report.","D. Index key fields used in report criteria."],"answer":"C,D","title":"Question 46","explanation":""},{"content":"UC is planning a massive SF implementation with large volumes of dat\na. As part of the org's implementation, several roles, territories, groups, and sharing rules have been configured. The data architect has been tasked with loading all of the required data, including user data, in a timely manner.\nWhat should a data architect do to minimize data load times due to system calculations?","options":["A. Leverage the Bulk API and concurrent processing with multiple batches","B. Load the data through data loader, and turn on parallel processing.","C. Enable defer sharing calculations, and suspend sharing rule calculations","D. Enable granular locking to avoid \"UNABLE _TO_LOCK_ROW\" error."],"answer":"C","title":"Question 47","explanation":""},{"content":"Universal Containers (UC) is using Salesforce Sales & Service Cloud for B2C sales and customer service but they are experiencing a lot of duplicate customers in the system. Which are two recommended approaches for UC to avoid duplicate data and increase the level of data quality?","options":["A. Use Duplicate Management.","B. Use an Enterprise Service Bus.","C. Use Data.com Clean","D. Use a data wharehouse."],"answer":"A,C","title":"Question 48","explanation":""},{"content":"A customer needs a sales model that allows the following:\nOpportunities need to be assigned to sales people based on the zip code.\nEach sales person can be assigned to multiple zip codes.\nEach zip code is assigned to a sales area definition. Sales is aggregated by sales area for reporting.\nWhat should a data architect recommend?","options":["A. Assign opportunities using list views using zip code.","B. Allow sales users to manually assign opportunity ownership based on zip code.","C. Add custom fields in opportunities for zip code and use assignment rules.","D. Configure territory management feature to support opportunity assignment."],"answer":"D","title":"Question 49","explanation":""},{"content":"All accounts and opportunities are created in Salesforce. Salesforce is integrated with three systems:\n* An ERP system feeds order data into Salesforce and updates both Account and Opportunity records.\n* An accounting system feeds invoice data into Salesforce and updates both Account and Opportunity records.\n* A commission system feeds commission data into Salesforce and updates both Account and Opportunity records.\nHow should the architect determine which of these systems is the system of record?","options":["A. Whatever integration data flow runs last will, by default, determine which system is the system of record.","B. Data flows should be reviewed with the business users to determine the system of record per object or field.","C. Whatever system updates the attribute or object should be the system of record for that field or object.","D. Account and opportunity data originates in Salesforce, and therefore Salesforce is the system of record."],"answer":"B","title":"Question 50","explanation":""},{"content":"Universal Containers (UC) has deployed Salesforce to manage Marketing. Sales, and Support efforts in a multi -system ERP environment After reaching the limits of native reports & dashboards. UC leadership is looking to understand what options can be used to provide more analytical insights. What two approaches should an architect recommend? Choose 2 answers","options":["A. Setup Audit Trails","B. Wave Analytics","C. Weekly Snapshots","D. AppExchange Apps"],"answer":"B,D","title":"Question 51","explanation":""},{"content":"Two million Opportunities need to be loaded in different batches into Salesforce using the Bulk API in parallel mode.\nWhat should an Architect consider when loading the Opportunity records?","options":["A. Group batches by the AccountId field.","B. Create indexes on Opportunity object text fields.","C. Order batches by Auto-number field.","D. Use the Name field values to sort batches."],"answer":"A","title":"Question 52","explanation":""},{"content":"Universal Containers (UC) has multi -level account hierarchies that represent departments within their major Accounts. Users are creating duplicate Contacts across multiple departments. UC wants to clean the data so as to have a single Contact across departments. What two solutions should UC implement to cleanse their data? Choose 2 answers","options":["A. Make use of a third -party tool to help merge duplicate Contacts across Accounts.","B. Use Data.com to standardize Contact address information to help identify duplicates.","C. Make use of the Merge Contacts feature of Salesforce to merge duplicates for an Account.","D. Use Workflow rules to standardize Contact information to identify and prevent duplicates."],"answer":"A,B","title":"Question 53","explanation":""},{"content":"Universal Containers (UC) provides shipping services to its customers. They use Opportunities to track customer shipments. At any given time, shipping status can be one of the 10 values. UC has 200,000 Opportunity records. When creating a new field to track shipping status on opportunity, what should the architect do to improve data quality and avoid data skew?","options":["A. Create a picklist field, values sorted alphabetically.","B. Create a Master -Detail to custom object ShippingStatus c.","C. Create a text field and make it an external ID.","D. Create a Lookup to custom object ShippingStatus c."],"answer":"A","title":"Question 54","explanation":""},{"content":"Developers at Universal Containers need to build a report for the business which displays Accounts opened in the past year grouped by industry. This report will also include information from contacts, opportunities, and orders. There are several million Accounts in the system. Which two options should be recommended to make this report perform well and satisfy the business need?","options":["A. Use an indexed data field with bounded data filters.","B. Use unbounded date ranges to filter the report.","C. Use triggers to populate denormalized related fields on the Account.","D. Use Formula fields to surface information I related entities on the report."],"answer":"A,B","title":"Question 55","explanation":""},{"content":"Northern Trail Outfitters (NTO) has a variety of customers that include householder, businesses, and individuals.\nThe following conditions exist within its system:\nNTO has a total of five million customers.\nDuplicate records exist, which is replicated across many systems, including Salesforce.\nGiven these conditions, there is a lack of consistent presentation and clear identification of a customer record.\nWhich three option should a data architect perform to resolve the issues with the customer data?","options":["A. Invest in data duplicate tool to de-dupe and merge duplicate records across all systems.","B. Create a unique global customer ID for each customer and store that in all system for referential identity.","C. Duplicate customer records across the system and provide a two-way sync of data between the systems.","D. Create a customer master database external to Salesforce as a system of truth and sync the customer data with all systems.","E. Use Salesforce CDC to sync customer data cross all systems to keep customer record in sync."],"answer":"A,B,D","title":"Question 56","explanation":""},{"content":"A large automobile company has implemented Salesforce for its sales associates. Leads flow from its website to Salesforce using a batch integration in Salesforce. The batch job converts the leads to Accounts in Salesforce. Customers visiting their retail stores are also created in Salesforce as Accounts.\nThe company has noticed a large number of duplicate Accounts in Salesforce. On analysis, it was found that certain customers could interact with its website and also visit the store. The sales associates use Global Search to search for customers in Salesforce before they create the customers.\nWhich option should a data architect choose to implement to avoid duplicates?","options":["A. leverage duplicate rules in Salesforce to validate duplicates during the account creation process.","B. Build a custom search functionality that allows sales associates to search for customer in real time upon visiting their retail stores.","C. Develop an Apex class that searches for duplicates and removes them nightly.","D. Implement an MDM solution to validate the customer information before creating Salesforce."],"answer":"A","title":"Question 57","explanation":""},{"content":"Universal Containers has a requirement to store more than 100 million records in salesforce and needs to create a custom big object to support this business requirement.\nWhich two tools should a data architect use to build custom object?","options":["A. Use Metadata API to create big object.","B. Use DX to create big object.","C. Go to Object manager In setup and select new to create big object.","D. Go to Big Object In setup select new to create big object."],"answer":"A,D","title":"Question 58","explanation":""},{"content":"UC migrating 100,000 Accounts from an enterprise resource planning (ERP) to salesforce and is concerned about ownership skew and performance.\nWhich 3 recommendations should a data architect provide to prevent ownership skew?\nChoose 3 answers:","options":["A. Keep users out of public groups that can be used as the source for sharing rules.","B. Assign \"view all\" permission on profile to give access to account.","C. Assign a default user as owner of accounts and assigned top most role in hierarchy.","D. Assign a default user as owner of account and do not assign any role to default user.","E. Assigned a default user as owner of accounts, and assign role in hierarchy."],"answer":"A,C,D","title":"Question 59","explanation":""},{"content":"UC has been using SF for 10 years. Lately, users have noticed, that the pages load slowly when viewing Customer and Account list view.\nTo mitigate, UC will implement a data archive strategy to reduce the amount of data actively loaded.\nWhich 2 tasks are required to define the strategy? Choose 2 answers:","options":["A. Identify the recovery time objective.","B. Identify the data retention requirements","C. Identify the recovery point objective.","D. Identify how the archive data will be accessed and used."],"answer":"B,D","title":"Question 60","explanation":""},{"content":"Universal Containers (UC) needs to run monthly and yearly reports on opportunities and orders for sales reporting. There are 5 million opportunities and 10 million orders. Sales users are complaining that the report will regularly timeout.\nWhat is the fastest and most effective way for a data architect to solve the time-out issue?","options":["A. Create custom fields on opportunity, and copy data from order into those custom fields and run all reports on Opportunity object.","B. Create an aggregate custom object that summarizes the monthly and yearly values into the required format for the required reports.","C. Extract opportunity and order data from Salesforce, and use a third-party reporting tool to run reports outside of Salesforce.","D. Create a skinny table in Salesforce, and copy order and opportunity fields into the skinny table and create the required reports on It."],"answer":"B","title":"Question 61","explanation":""},{"content":"US is implementing salesforce and will be using salesforce to track customer complaints, provide white papers on products and provide subscription (Fee) - based support.\nWhich license type will US users need to fulfil US's requirements?","options":["A. Lightning platform starter license.","B. Service cloud license.","C. Salesforce license.","D. Sales cloud license"],"answer":"B","title":"Question 62","explanation":""},{"content":"NTO has outgrown its current salesforce org and will be migrating to new org shortly. As part of this process NTO will be migrating all of its metadata and dat a. NTO's data model in the source org has a complex relationship hierarchy with several master detail and lookup relationships across objects, which should be maintained in target org.\nWhat 3 things should a data architect do to maintain the relationship hierarchy during migration?\nChoose 3 answers:","options":["A. Use data loader to export the data from source org and then import or Upsert into the target org in sequential order.","B. Create a external id field for each object in the target org and map source record ID's to this field.","C. Redefine the master detail relationship fields to lookup relationship fields in the target org.","D. Replace source record ID's with new record ID's from the target org in the import file.","E. Keep the relationship fields populated with the source record ID's in the import file."],"answer":"A,B,D","title":"Question 63","explanation":""},{"content":"In their legacy system. Universal Containers has a monthly accounts receivable report that compiles data from Accounts, Contacts, Opportunities, Orders. and Order Line Items. What difficulty will an architect run into when implementing this in Salesforce?","options":["A. Custom report types cannot contain Opportunity data.","B. A report cannot contain data from Accounts and Contacts.","C. Salesforce does not support Orders or Order Line Items.","D. Salesforce allows up to four objects in a single report type."],"answer":"D","title":"Question 64","explanation":""},{"content":"UC is trying to switch from legacy CRM to salesforce and wants to keep legacy CRM and salesforce in place till all the functionality is deployed in salesforce. The want to keep data in synch b/w Salesforce, legacy CRM and SAP. What is the recommendation.","options":["A. Do not integrate legacy CRM to Salesforce, but integrate salesforce to SAP","B. Integrate SAP with Salesforce, SAP to legacy CRM but not legacy CRM to Salesforce","C. Integrate legacy CRM to salesforce and keep data in synch till new functionality is in place","D. Suggest MDM solution and link MDM to salesforce and SAP"],"answer":"B,D","title":"Question 65","explanation":""},{"content":"A company has 12 million records, and a nightly integration queries these records.\nWhich two areas should a Data Architect investigate during troubleshooting if queries are timing out? (Choose two.)","options":["A. Create a formula field instead of having multiple filter criteria.","B. Make sure the query doesn't contain NULL in any filter criteria.","C. Create custom indexes on the fields used in the filter criteria.","D. Modify the integration users' profile to have View All Data."],"answer":"B,C","title":"Question 66","explanation":""},{"content":"Universal Containers (UC) has adopted Salesforce as its primary sales automated tool. UC has 100,00 customers with a growth rate of 10% a year, UC uses an on-premise web-based billing and invoice system that generates over 1 million invoices a year supporting a monthly billing cycle.\nThe UC sales team needs to be able to pull a customer record and view their account status, Invoice history, and opportunities without navigating outside of Salesforce.\nWhat should a data architect use to provide the sales team with the required functionality?","options":["A. Create a custom object and migrate the last 12 months of Invoice data into Salesforce so it can be displayed on the Account layout.","B. Create a visual force tab with the billing system encapsulated within an iframe.","C. Write an Apex callout and populate a related list to display on the account record.","D. Create a mashup page that will present the billing system records within Salesforce."],"answer":"D","title":"Question 67","explanation":""},{"content":"North Trail Outfitters (NTD) is in the process of evaluating big objects to store large amounts of asset data from an external system. NTO will need to report on this asset data weekly.\nWhich two native tools should a data architect recommend to achieve this reporting requirement?","options":["A. Standard reports and dashboards","B. Einstein Analytics","C. Standard SOQL queries","D. Async SOQL with a custom object"],"answer":"B,D","title":"Question 68","explanation":""},{"content":"Universal Containers (UC) is implementing its new Internet of Things technology, which consists of smart containers that provide information on container temperature and humidity updated every 10 minutes back to UC. There are roughly 10,000 containers equipped with this technology with the number expected to increase to 50,000 across the next five years. It is essential that Salesforce user have access to current and historical temperature and humidity data for each container. What is the recommended solution?","options":["A. Create a new Lightning Component that displays last humidity and temperature data for a specific container and can also display historical trends obtaining relevant data from UC's existing data warehouse.","B. Create new custom fields for temperature and humidity in the existing Container custom object, as well as an external ID field that is unique for each container. These custom fields are updated when a new measure is received.","C. Create a new Container Reading custom object with a master-detail relationship to Container which is created when a new measure is received for a specific container. Implement an archiving process that runs every hour.","D. Create a new Container Reading custom object, which is created when a new measure is received for a specific container. The Container Reading custom object has a master-detail relationship to the container object."],"answer":"C","title":"Question 69","explanation":""},{"content":"Every year, Ursa Major Solar has more than 1 million orders. Each order contains an average of 10 line items. The Chief Executive Officer (CEO) needs the Sales Reps to see how much money each customer generates year-over-year. However, data storage is running low in Salesforce.\nWhich approach for data archiving is appropriate for this scenario?","options":["A. 1. Annually delete orders and order line items. 2. Ensure the customer has order information in another system.","B. 1. Annually aggregate order amount data to store in a custom object. 2. Delete those orders and order line items.","C. 1. Annually export and delete orders and order line items. 2. Store them in a zip file in case the data is needed later.","D. 1. Annually export and delete order line items. 2. Store them in a zip file in case the data is needed later."],"answer":"B","title":"Question 70","explanation":""},{"content":"A large Automobile company has implemented SF for its Sales Associates. Leads flow from its website to SF using a batch integration in SF. The Batch job connects the leads to Accounts in SF. Customer visiting their retail stores are also created in SF as Accounts.\nThe company has noticed a large number of duplicate accounts in SF. On analysis, it was found that certain customers could interact with its website and also visit the store. The Sales associates use Global Search to search for customers in Salesforce before they create the customers.\nWhich scalable option should a data Architect choose to implement to avoid duplicates?","options":["A. Customize Account creation process to search if customer exists before creating an Account.","B. Build Custom search based on fields on Accounts which can be matched with customer when they visit the store","C. Create duplicate rules in SF to validate duplicates during the account creation process","D. Implement a MDM solution to validate the customer information before creating Accounts in SF."],"answer":"C","title":"Question 71","explanation":""},{"content":"UC is preparing to implement sales cloud and would like to its users to have read only access to an account record if they have access to its child opportunity record. How would a data architect implement this sharing requirement between objects?","options":["A. Implicit sharing will automatically handle with standard functionality.","B. Create an owner-based sharing rule.","C. Create a criteria-based sharing rule.","D. Add appropriate users to the account team."],"answer":"A","title":"Question 72","explanation":""},{"content":"NTO need to extract 50 million records from a custom object everyday from its Salesforce org. NTO is facing query timeout issues while extracting these records.\nWhat should a data architect recommend in order to get around the time out issue?","options":["A. Use a custom auto number and formula field and use that to chunk records while extracting data.","B. The REST API to extract data as it automatically chunks records by 200.","C. Ask SF support to increase the query timeout value.","D. Use ETL tool for extraction of records."],"answer":"D","title":"Question 73","explanation":""},{"content":"Universal Containers (UC) is a business that works directly with individual consumers (B2C). They are moving from a current home-grown CRM system to Salesforce. UC has about one million consumer records. What should the architect recommend for optimal use of Salesforce functionality and also to avoid data loading issues?","options":["A. Create a Custom Object Individual Consumer c to load all individual consumers.","B. Load one Account record and one Contact record for each individual consumer.","C. Create one Account and load individual consumers as Contacts linked to that one Account.","D. Load all individual consumers as Account records and avoid using the Contact object."],"answer":"B","title":"Question 74","explanation":""},{"content":"Universal Containers is creating a new B2C service offering for consumers to ship goods across continents. This is in addition to their well-established B2B offering. Their current Salesforce org uses the standard Account object to track B2B customers. They are expecting to have over 50,000,000 consumers over the next five years across their 50 business regions. B2C customers will be individuals. Household data is not required to be stored. What is the recommended data model for consumer account data to be stored in Salesforce?","options":["A. Use the Account object with Person Accounts and a new B2C page layout.","B. Use the Account object with a newly created Record Type for B2C customers.","C. Use 50 umbrella Accounts for each region, with customers as associated Contacts.","D. Create a new picklist value for B2C customers on the Account Type field."],"answer":"A","title":"Question 75","explanation":""},{"content":"Universal Containers (UC) is concerned that data is being corrupted daily either through negligence or maliciousness. They want to implement a backup strategy to help recover any corrupted data or data mistakenly changed or even deleted. What should the data architect consider when designing a field -level audit and recovery plan?","options":["A. Implement an AppExchange package.","B. Reduce data storage by purging old data.","C. Review projected data storage needs.","D. Schedule a weekly export file."],"answer":"B","title":"Question 76","explanation":""},{"content":"An Architect needs to document the data architecture for a multi-system, enterprise Salesforce implementation.\nWhich two key artifacts should the Architect use? (Choose two.)","options":["A. Data model","B. Integration specification","C. Non-functional requirements","D. User stories"],"answer":"A,B","title":"Question 77","explanation":""},{"content":"UC developers have created a new lightning component that uses an Apex controller using a SOQL query to populate a custom list view. Users are complaining that the component often fails to load and returns a time-out error.\nWhat tool should a data architect use to identify why the query is taking too long?","options":["A. Enable and use the query plan tool in the developer console.","B. Use Splunk to query the system logs looking for transaction time and CPU usage.","C. Use salesforce's query optimizer to analyze the query in the developer console.","D. Open a ticket with salesforce support to retrieve transaction logs to e analyzed for processing time."],"answer":"A","title":"Question 78","explanation":""}]