[{"content":"Universal Containers is looking to use Salesforce to manage their sales organization. They will be migrating legacy account data from two aging systems into Salesforce. Which two design considerations should an architect take to minimize data duplication? Choose 2 answers","options":["A. Use a workflow to check and prevent duplicates.","B. Import the data concurrently.","C. Clean data before importing to Salesforce.","D. Use Salesforce matching and duplicate rules."],"answer":"C,D","title":"Question 1","explanation":""},{"content":"Universal Containers is planning out their archiving and purging plans going forward for their custom objects Topic__c and Comment__c. Several options are being considered, including analytics snapshots, offsite storage, scheduled purges, etc. Which three questions should be considered when designing an appropriate archiving strategy?","options":["A. Which profiles and users currently have access to these custom object records?","B. If reporting is necessary, can the information be aggregated into fewer, summary records?","C. How many fields are defined on the custom objects that need to be archived?","D. Will the data being archived need to be reported on or accessed in any way in the future?","E. Are there any regulatory restrictions that will influence the archiving and purging plans?"],"answer":"B,D,E","title":"Question 2","explanation":""},{"content":"Universal Containers (UC) is implementing a new customer categorization process where customers should be assigned to a Gold, Silver, or Bronze category if they've purchased UC's new support service. Customers are expected to be evenly distributed across all three categories. Currently, UC has around 500,000 customers, and is expecting 1% of existing non-categorized customers to purchase UC's new support service every month over the next five years. What is the recommended solution to ensure long-term performance, bearing in mind the above requirements?","options":["A. Implement a new Categories custom object and create a lookup field from Account to Category.","B. Implement a new global picklist custom field with Gold, Silver, and Bronze values and enable it in Account.","C. Implement a new Categories custom object and a master-detail relationship from Account to Category.","D. Implement a new picklist custom field in the Account object with Gold, Silver, and Bronze values."],"answer":"D","title":"Question 3","explanation":""},{"content":"Universal Containers is experiencing frequent and persistent group membership locking issues that severely restricts its ability to manage manual and a automated updates at the same time.\nWhat should a data architect do in order to restore the issue?","options":["A. Enable parallel sharing rule calculation.","B. Enable granular locking","C. Enable defer sharing calculation","D. Enable implicit sharing"],"answer":"B","title":"Question 4","explanation":""},{"content":"NTO has decided to franchise its brand. Upon implementation, 1000 franchisees will be able to access BTO's product information and track large customer sales and opportunities through a portal. The Franchisees will also be able to run monthly and quarterly sales reports and projections as well as view the reports in dashboards.\nWhich licenses does NTO need to provide these features to the Franchisees?","options":["A. Partner Community license","B. Salesforce Sales Cloud license","C. Lightning Platform license","D. Customer Community license"],"answer":"A","title":"Question 5","explanation":""},{"content":"A customer needs a sales model that allows the following:\nOpportunities need to be assigned to sales people based on the zip code.\nEach sales person can be assigned to multiple zip codes.\nEach zip code is assigned to a sales area definition. Sales is aggregated by sales area for reporting.\nWhat should a data architect recommend?","options":["A. Add custom fields in opportunities for zip code and use assignment rules.","B. Allow sales users to manually assign opportunity ownership based on zip code.","C. Assign opportunities using list views using zip code.","D. Configure territory management feature to support opportunity assignment."],"answer":"D","title":"Question 6","explanation":""},{"content":"During the implementation of Salesforce, a customer has the following requirements for Sales Orders:\n1. Sales Order information needs to be shown to users in Salesforce.\n2. Sales Orders are maintained in the on-premises enterprise resource planning (ERP).\n3. Sales Order information has more than 150 million records.\n4. Sales Orders will not be updated in Salesforce.\nWhat should a data architect recommend for maintaining Sales Orders in salesforce?","options":["A. Us custom objects to maintain Sales Orders in Salesforce.","B. Use external objects to maintain Sales Order in Salesforce.","C. Use custom big objects to maintain Sales Orders in Salesforce.","D. Use Standard order object to maintain Sale Orders in Salesforce"],"answer":"B","title":"Question 7","explanation":""},{"content":"Universal Containers has successfully migrated 50 million records into five different objects multiple times in a full copy sandbox. The Integration Engineer wants to re-run the test again a month before it goes live into Production. What is the recommended approach to re-run the test?","options":["A. Truncate all 5 objects and hard delete before running the migration test.","B. Refresh the full copy sandbox and re-run the data migration test.","C. Truncate all 5 objects quickly and re-run the data migration test.","D. Hard delete all 5 objects' data and re-run the data migration test."],"answer":"B","title":"Question 8","explanation":""},{"content":"Universal Containers has defined a new Data Quality Plan for their Salesforce data and wants to know how they can enforce it throughout the organization. Which two approaches should an architect recommend to enforce this new plan?\nChoose 2 answers","options":["A. Store all data in an external system and set up an integration to Salesforce for view -only access.","B. Use Workflow, Validation Rules, and Force.com code (Apex) to enforce critical business processes.","C. Schedule reports that will automatically catch duplicates and merge or delete the records every week.","D. Schedule a weekly dashboard displaying records that are missing information to be sent to managers for review."],"answer":"B,D","title":"Question 9","explanation":""},{"content":"(NTO) has multiple salesforce orgs based on geographical reports (AMER, EMEA, APAC). NTO products are in the AMER org and need to be created in the EMEA and APAC after the products are approved.\nWhich two features should a data architect recommend to share records between salesforce orgs? Choose 2.","options":["A. Federation search","B. Salesforce 2 Salesforce","C. Salesforce connect.","D. Change data capture (CDC)"],"answer":"B,D","title":"Question 10","explanation":""},{"content":"Universal Container is Implementing salesforce and needs to migrate data from two legacy systems. UC would like to clean and duplicate data before migrate to Salesforce.\nWhich solution should a data architect recommend a clean migration?","options":["A. Define external IDs for an object, Insert data from one database, and use upsert for a second database","B. Set up staging data base, and define external IDs to merge, clean duplicate data, and load into Salesforce.","C. Define duplicate rules in Salesforce, and load data into Salesforce from both databases.","D. Define external IDs for an object, migrate second database to first database, and load into Salesforce."],"answer":"A","title":"Question 11","explanation":""},{"content":"Ursa Major Solar's legacy system has a quarterly accounts receivable report that compiles data from the following:\n- Accounts\n- Contacts\n- Opportunities\n- Orders\n- Order Line Items\nWhich issue will an architect have when implementing this in Salesforce?","options":["A. Salesforce does NOT support Orders or Order Line Items.","B. Custom report types CANNOT contain Opportunity data.","C. Salesforce does NOT allow more than four objects in a single report type.","D. A report CANNOT contain data from Accounts and Contacts."],"answer":"C","title":"Question 12","explanation":""},{"content":"Universal Containers (UC) is implementing a Salesforce project with large volumes of data and daily transactions. The solution includes both real-time web service integrations and Visualforce mash -ups with back -end systems. The Salesforce Full sandbox used by the project integrates with full-scale back -end testing systems. What two types of performance testing are appropriate for this project?\nChoose 2 answers","options":["A. Pre -go -live automated page -load testing against the Salesforce Full sandbox.","B. Post go -live automated page -load testing against the Salesforce Production org.","C. Stress testing against the web services hosted by the integration middleware.","D. Pre -go -live unit testing in the Salesforce Full sandbox."],"answer":"A,C","title":"Question 13","explanation":""},{"content":"UC has a roll-up summary field on Account to calculate the count of contacts associated with an account. During the account load, SF is throwing an \"Unable to lock a row\" error.\nWhich solution should a data architect recommend, to resolve the error?","options":["A. Leverage data loader platform API to load data.","B. Defer roll-up summary fields calculation during data migration.","C. Perform Batch job in parallel mode and reduce Batch size","D. Perform Batch job in serial mode and reduce batch size"],"answer":"C","title":"Question 14","explanation":""},{"content":"UC is rolling out Sales App globally to bring sales teams together on one platform. UC expects millions of opportunities and accounts to be creates and is concerned about the performance of the application.\nWhich 3 recommendations should the data architect make to avoid the data skew? Choose 3 answers.","options":["A. Limit associating 10000 opportunities to one account.","B. Limit associating 10000 records looking up to same records.","C. Limit assigning one user 10000 records ownership.","D. Use picklist fields rather than lookup to custom object.","E. Assign 10000 opportunities to one account."],"answer":"A,C","title":"Question 15","explanation":""},{"content":"UC has a variety of systems across its technology landscape, including SF, legacy enterprise resource planning (ERP) applications and homegrown CRM tools. UC has decided that they would like to consolidate all customer, opportunity and order data into Salesforce as part of its master data management (MDM) strategy.\nWhat are the 3 key steps that a data architect should take when merging data from multiple systems into Salesforce? Choose 3 answers:","options":["A. Work with Stakeholders to define record and field survivorship rules","B. Utilize an ETL tool to merge, transform and de-duplicate data.","C. Install a 3rd party AppExchange tool to handle the merger","D. Create new fields to store additional values from all the systems.","E. Analyze each system's data model and perform gap analysis"],"answer":"A,B,E","title":"Question 16","explanation":""},{"content":"Universal Containers has a public website with several forms that create Lead records in Salesforce using the REST API. When designing these forms, which two techniques will help maintain a high level of data quality?","options":["A. Use cookies to track when visitors submit multiple forms.","B. Prefer picklist form fields over free text fields, where possible.","C. Ensure the website visitor is browsing using an HTTPS connection.","D. Do client-side validation of phone number and email field formats."],"answer":"B,D","title":"Question 17","explanation":""},{"content":"Universal Containers (UC) owns a complex Salesforce org with many Apex classes, triggers, and automated processes that will modify records if available. UC has identified that, in its current development state, UC runs change of encountering race condition on the same record.\nWhat should a data architect recommend to guarantee that records are not being updated at the same time?","options":["A. Embed the keywords FOR UPDATE after SOQL statements.","B. Disable classes or triggers that have the potential to obtain the same record.","C. Migrate programmatic logic to processes and flows.","D. Refactor or optimize classes and trigger for maximum CPU performance."],"answer":"A","title":"Question 18","explanation":""},{"content":"Universal Containers (UC) loads bulk leads and campaigns from third-party lead aggregators on a weekly and monthly basis. The expected lead record volume is 500K records per week, and the expected campaign records volume is 10K campaigns per week. After the upload, Lead records are shared with various sales agents via sharing rules and added as Campaign members via Apex triggers on Lead creation. UC agents work on leads for 6 months, but want to keep the records in the system for at least 1 year for reference. Compliance requires them to be stored for a minimum of 3 years. After that, data can be deleted. What statement is true with respect to a data archiving strategy for UC?","options":["A. UC can leverage the Salesforce Data Backup and Recovery feature for data archival needs.","B. UC can leverage recycle bin capability, which guarantees record storage for 15 days after deletion.","C. UC can leverage a \"tier\"-based approach to classify the record storage need.","D. UC can store long-term lead records in custom storage objects to avoid counting against storage limits."],"answer":"C","title":"Question 19","explanation":""},{"content":"NTO has outgrown its current salesforce org and will be migrating to new org shortly. As part of this process NTO will be migrating all of its metadata and dat a. NTO's data model in the source org has a complex relationship hierarchy with several master detail and lookup relationships across objects, which should be maintained in target org.\nWhat 3 things should a data architect do to maintain the relationship hierarchy during migration?\nChoose 3 answers:","options":["A. Redefine the master detail relationship fields to lookup relationship fields in the target org.","B. Replace source record ID's with new record ID's from the target org in the import file.","C. Create a external id field for each object in the target org and map source record ID's to this field.","D. Use data loader to export the data from source org and then import or Upsert into the target org in sequential order.","E. Keep the relationship fields populated with the source record ID's in the import file."],"answer":"B,C,D","title":"Question 20","explanation":""},{"content":"A manager at Cloud Kicks is importing Leads into Salesforce and needs to avoid creating duplicate records.\nWhich two approaches should the manager take to achieve this goal? (Choose two.)","options":["A. Create a Workflow Rule to check for duplicate records.","B. Acquire an AppExchange Lead de-duplication application.","C. Run the Salesforce Lead Mass de-duplication tool.","D. Implement Salesforce Matching and Duplicate Rules."],"answer":"B,D","title":"Question 21","explanation":""},{"content":"Universal Containers wants to automatically archive all inactive Account data that is older than 3 years. The information does not need to remain accessible within the application. Which two methods should be recommended to meet this requirement? Choose 2 answers","options":["A. Schedule jobs to export and delete using the Data Loader.","B. Use the Force.com Workbench to export the data.","C. Schedule jobs to export and delete using an ETL tool.","D. Schedule a weekly export file from the Salesforce UI."],"answer":"A,C","title":"Question 22","explanation":""},{"content":"Universal Containers wants to develop a dashboard in Salesforce that will allow Sales Managers to do data exploration using their mobile device (i.e., drill down into sales-related data) and have the possibility of adding ad-hoc filters while on the move. What is a recommended solution for building data exploration dashboards in Salesforce?","options":["A. Create a standard Salesforce Dashboard and connect it to reports with the appropriate filters.","B. Create a Dashboard in an external reporting tool, export data to the tool, and add link to the dashboard in Salesforce.","C. Create a Dashboard in an external reporting tool, export data to the tool, and embed the dashboard in Salesforce using the Canval toolkit.","D. Create a Dashboard using Analytics Cloud that will allow the user to create ad-hoc lenses and drill down."],"answer":"D","title":"Question 23","explanation":""},{"content":"UC has to built a B2C ecommerce site on Heroku that shares customer and order data with a Heroku Postgres database. UC is currently utilizing Postgres as the single source of truth for both customers and orders. UC has asked a data architect to replicate the data into salesforce so that salesforce can now act as the system of record.\nWhat are the 3 considerations that data architect should weigh before implementing this requirement? Choose 23 answers:","options":["A. Determine if the data is driver of key process implemented within salesforce.","B. A selection of the tool required to replicate the data.\n         a. - Heroku Connect is required but this is confusing","C. Ensure there is a tight relationship between order data and an enterprise resource plaining (ERP) application.","D. Ensure the data is CRM center and able to populate standard of custom objects.","E. Consider whether the data is required for sales reports, dashboards and KPI's."],"answer":"A,D","title":"Question 24","explanation":""},{"content":"A company has 12 million records, and a nightly integration queries these records.\nWhich two areas should a Data Architect investigate during troubleshooting if queries are timing out? (Choose two.)","options":["A. Make sure the query doesn't contain NULL in any filter criteria.","B. Modify the integration users' profile to have View All Data.","C. Create a formula field instead of having multiple filter criteria.","D. Create custom indexes on the fields used in the filter criteria."],"answer":"A,D","title":"Question 25","explanation":""},{"content":"All accounts and opportunities are created in Salesforce. Salesforce is integrated with three systems:\n* An ERP system feeds order data into Salesforce and updates both Account and Opportunity records.\n* An accounting system feeds invoice data into Salesforce and updates both Account and Opportunity records.\n* A commission system feeds commission data into Salesforce and updates both Account and Opportunity records.\nHow should the architect determine which of these systems is the system of record?","options":["A. Account and opportunity data originates in Salesforce, and therefore Salesforce is the system of record.","B. Data flows should be reviewed with the business users to determine the system of record per object or field.","C. Whatever integration data flow runs last will, by default, determine which system is the system of record.","D. Whatever system updates the attribute or object should be the system of record for that field or object."],"answer":"B","title":"Question 26","explanation":""},{"content":"NTO would like to retrieve their SF orgs meta data programmatically for backup within a various external. Which API is the best fit for accomplishing this task?","options":["A. Tooling API","B. Metadata API","C. Bulk API in serial mode","D. SOAP API"],"answer":"B","title":"Question 27","explanation":""},{"content":"UC has large amount of orders coming in from its online portal. Historically all order are assigned to a generic user.\nWhich 2 measures should data architect recommend to avoid any performance issues while working with large number of order records? Choose 2 answers:","options":["A. Salesforce handles the assignment of orders automatically and there is no performance impact.","B. Create a pool of generic users and distribute the assignment of memory to the pool of users.","C. Clear the role field in the generic user record.","D. Create a role at top of role hierarchy and assign the role to the generic user."],"answer":"C,D","title":"Question 28","explanation":""},{"content":"Universal Containers (UC) is facing data quality issues where Sales Reps are creating duplicate customer accounts, contacts, and leads. UC wants to fix this issue immediately by prompting users about a record that possibly exists in Salesforce. UC wants a report regarding duplicate records. What would be the recommended approach to help UC start immediately?","options":["A. Create a duplicate rule for account, lead, and contact, use standard matching rules for these objects, and set the action to block for both creates and edits.","B. Create a duplicate rule for account, lead, and contact, use standard matching rules for these objects, and set the action to report and alert for both creates and edits.","C. Create a before insert and update trigger on account, contact, and lead, and send an error if a duplicate is found using a custom matching criteria.","D. Create an after insert and update trigger on the account, contact and lead, and send an error if a duplicate is found using a custom matching criteria."],"answer":"B","title":"Question 29","explanation":""},{"content":"Universal Containers is integrating a new Opportunity engagement system with Salesforce. According to their Master Data Management strategy, Salesforce is the system of record for Account, Contact, and Opportunity dat a. However, there does seem to be valuable Opportunity data in the new system that potentially conflicts with what is stored in Salesforce. What is the recommended course of action to appropriately integrate this new system?","options":["A. A policy should be adopted so that the system whose record was most recently updated should prevail in conflicts.","B. The Opportunity engagement system should become the system of record for Opportunity records.","C. Stakeholders should be brought together to discuss the appropriate data strategy moving forward.","D. The MDM strategy defines Salesforce as the system of record, so Salesforce Opportunity values prevail in all conflicts."],"answer":"C","title":"Question 30","explanation":""},{"content":"Universal Containers has deployed Salesforce for case management The company is having difficulty understanding what percentage of cases are resolved from the initial call to their support organization. What first step is recommended to implement a reporting solution to measure the support reps case closure rates?","options":["A. Create a report on Case analytic snapshots.","B. Enable field history tracking on the Case object.","C. Create Contact and Opportunity Reports and Dashboards.","D. Install AppExchange packages for available reports."],"answer":"B","title":"Question 31","explanation":""},{"content":"Cloud Kicks has the following requirements:\n- Data needs to be sent from Salesforce to an external system to generate invoices from their Order Management System (OMS).\n- A Salesforce administrator must be able to customize which fields will be sent to the external system without changing code.\nWhat are two approaches for fulfilling these requirements? (Choose two.)","options":["A. Enable the field -level security permissions for the fields to send.","B. A set<sobjectFieldset> to determine which fields to send in an HTTP callout.","C. A Field Set that determines which fields to send in an HTTP callout.","D. An Outbound Message to determine which fields to send to the OMS."],"answer":"C,D","title":"Question 32","explanation":""},{"content":"Universal Container (UC) has around 200,000 Customers (stored in Account object). They get 1 or 2 Orders every month from each Customer. Orders are stored in a custom object called \"Order c\"; this has about 50 fields. UC is expecting a growth of 10% year -over -year. What are two considerations an architect should consider to improve the performance of SOQL queries that retrieve data from the Order _c object? Choose 2 answers","options":["A. Work with Salesforce Support to enable Skinny Tables.","B. Reduce the number of triggers on Order _c object.","C. Use SOQL queries without WHERE conditions.","D. Make the queries more selective using indexed fields."],"answer":"A,D","title":"Question 33","explanation":""},{"content":"Northern Trail Outfitters (NTO) has the following systems:\nCustomer master-source of truth for customer information\nService cloud-customer support\nMarketing cloud-marketing support\nEnterprise data warehouse-business reporting\nThe customer data is duplicated across all these system and are not kept in sync. Customers are also complaining that they get repeated marketing emails and have to call into update their information.\nNTO is planning to implement master data management (MDM) solution across the enterprise.\nWhich three data will an MDM tool solve?\nChoose 3 answers","options":["A. Data accuracy and quality","B. Data completeness","C. Data standardization","D. Data loss and recovery","E. Data duplication"],"answer":"A,C,E","title":"Question 34","explanation":""},{"content":"A large retail B2C customer wants to build a 360 view of its customer for its call center agents. The customer interaction is currently maintained in the following system:\n1. Salesforce CRM\n2. Custom billing solution\n3. Customer Master Data management (MDM)\n4. Contract Management system\n5. Marketing solution\nWhat should a data architect recommend that would help upgrade uniquely identify customer across multiple systems:","options":["A. Create a custom field as external id to maintain the customer Id from the MDM solution.","B. Store the salesforce id in all the solutions to identify the customer.","C. Create a customer data base and use this id in all systems.","D. Create a custom object that will serve as a cross reference for the customer id."],"answer":"A","title":"Question 35","explanation":""},{"content":"NTO has 1 million customer records spanning 25 years. As part of its new SF project, NTO would like to create a master data management strategy to help preserve the history and relevance of its customer data.\nWhich 3 activities will be required to identify a successful master data management strategy? Choose 3 answers:","options":["A. Create a data archive strategy","B. Define the systems of record for critical data","C. Choose a Business Intelligence tool.","D. Install a data warehouse","E. Identify data to be replicated"],"answer":"A,B,E","title":"Question 36","explanation":""},{"content":"An Architect needs to document the data architecture for a multi-system, enterprise Salesforce implementation.\nWhich two key artifacts should the Architect use? (Choose two.)","options":["A. Data model","B. User stories","C. Integration specification","D. Non-functional requirements"],"answer":"A,C","title":"Question 37","explanation":""},{"content":"A casino is implementing salesforce and is planning to build a customer 360 view for a customer who visits its resorts. The casino currently maintained the following systems that records customer activity:\n1. Point of sales system: All purchases for a customer.\n2. Salesforce: All customer service activity and sales activity for a customer.\n3. Mobile app: All bookings, preferences and browser activity for a customer.\n4. Marketing: All email, SMS and social campaigns for a customer.\nCustomer service agents using salesforce would like to view the activities from all system to provide supports to customers. The information has to be current and real time.\nWhat strategy should the data architect implement to satisfy this requirement?","options":["A. Periodically upload summary information in salesforce to build 360 view.","B. Migrate customer activities from all 4 systems into salesforce.","C. Use a customer data mart to view the 360 view of customer.","D. Explore external data sources in salesforce to build 360 view of customer."],"answer":"D","title":"Question 38","explanation":""},{"content":"Universal Containers has two systems. Salesforce and an on -premise ERP system. An architect has been tasked with copying Opportunity records to the ERP once they reach a Closed/Won Stage. The Opportunity record in the ERP system will be read-only for all fields copied in from Salesforce. What is the optimal real-time approach that achieves this solution?","options":["A. Have the ERP poll Salesforce nightly and bring in the desired Opportunities.","B. Implement a workflow rule that sends Opportunity data through Outbound Messaging.","C. Implement an hourly integration to send Salesforce Opportunities to the ERP system.","D. Implement a Master Data Management system to determine system of record."],"answer":"B","title":"Question 39","explanation":""},{"content":"Universal Containers (UC) is implementing its new Internet of Things technology, which consists of smart containers that provide information on container temperature and humidity updated every 10 minutes back to UC. There are roughly 10,000 containers equipped with this technology with the number expected to increase to 50,000 across the next five years. It is essential that Salesforce user have access to current and historical temperature and humidity data for each container. What is the recommended solution?","options":["A. Create a new Lightning Component that displays last humidity and temperature data for a specific container and can also display historical trends obtaining relevant data from UC's existing data warehouse.","B. Create a new Container Reading custom object with a master-detail relationship to Container which is created when a new measure is received for a specific container. Implement an archiving process that runs every hour.","C. Create a new Container Reading custom object, which is created when a new measure is received for a specific container. The Container Reading custom object has a master-detail relationship to the container object.","D. Create new custom fields for temperature and humidity in the existing Container custom object, as well as an external ID field that is unique for each container. These custom fields are updated when a new measure is received."],"answer":"B","title":"Question 40","explanation":""},{"content":"Universal Containers (UC) uses the following Salesforce products:\nSales Cloud for customer management.\nMarketing Cloud for marketing.\nEinstein Analytics for business reporting.\nUC occasionally gets a list of prospects from third-party source as comma-separated values (CSV) files for marketing purposes. Historically, UC would load contact Lead object in Salesforce and sync to Marketing Cloud to send marketing communications. The number of records in the Lead object has grown over time and has been consuming large amounts of storage in Sales Cloud, UC is looking for recommendations to reduce the storage and advice on how to optimize the marketing Cloud to send marketing communications. The number of records in the Lead object has grown over time and has been consuming large amounts of storage in Sales Cloud, UC is looking for recommendations to reduce the storage and advice on how to optimize the marketing process.\nWhat should a data architect recommend to UC in order to immediately avoid storage issues in the future?","options":["A. Load the CSV files in an external database and sync with Marketing Cloud prior to sending marketing communications.","B. Load the contacts directly to Marketing Cloud and have a reconciliation process to track prospects that are converted to customers.","C. Load the CSV files in Einstein Analytics and sync with Marketing Cloud prior to sending marketing communications ;","D. Continue to use the existing process to use Lead object to sync with Marketing Cloud and delete Lead records from Sales after the sync is complete."],"answer":"C","title":"Question 41","explanation":""},{"content":"Universal Containers (UC) has over 10 million accounts with an average of 20 opportunities with each account. A Sales Executive at UC needs to generate a daily report for all opportunities in a specific opportunity stage.\nWhich two key considerations should be made to make sure the performance of the report is not degraded due to large data volume?","options":["A. Number of joins used in report query.","B. Number of records returned by report query.","C. Number of characters in report query.","D. Number of queries running at a time."],"answer":"A,B","title":"Question 42","explanation":""},{"content":"Universal Container require all customers to provide either a phone number of an email address when registering for an account.\nWhat should the data architect use to ensure this requirement is met?","options":["A. required Fields","B. Process Builder","C. validation Rule","D. Apex Class"],"answer":"C","title":"Question 43","explanation":""},{"content":"An architect has been asked to provide error messages when a future date is detected in a custom Birthdate _c field on the Contact object. The client wants the ability to translate the error messages. What are two approaches the architect should use to achieve this solution? Choose 2 answers","options":["A. Implement a third -party validation process with translate functionality.","B. Create a validation rule and translate the error message with translation workbench.","C. Create a trigger on Contact and add an error to the record with a custom label.","D. Create a workflow field update to set the standard ErrorMessage field."],"answer":"B,C","title":"Question 44","explanation":""},{"content":"Universal Containers (UC) is in the process of migrating lagacy inventory data from an enterprise resources planning (ERP) system into Sales Cloud with the following requirements:\nLegacy inventory data will be stored in a custom child objects called Inventory_c.\nInventory data should be related to the standard Account object.\nThe Inventory_c object should Inhent the same sharing rules as the Account object.\nAnytime an Account record is deleted in Salesforce, the related Inventory_c record(s) should be deleted as well.\nWhat type of relationship field should a data architect recommend in this scenario?","options":["A. Master-detail relationship filed on Account, related to Inventory_c","B. Indirect lookup relationship field on Account, related to Inventory_c","C. Lookup relationship fields on Inventory related to Account","D. Master-detail relationship filed on Inventory_c, related to Account"],"answer":"A","title":"Question 45","explanation":""},{"content":"UC has millions of case records with case history and SLA dat\na. UC's compliance team would like historical cases to be accessible for 10 years for Audit purpose.\nWhat solution should a data architect recommend?","options":["A. Use a custom object to store archived case data.","B. Use a custom Big object to store archived case data.","C. Archive Case data using Salesforce Archiving process","D. Purchase more data storage to support case object"],"answer":"B","title":"Question 46","explanation":""},{"content":"UC has multiple SF orgs that are distributed across regional branches. Each branch stores local customer data inside its org's Account and Contact objects. This creates a scenario where UC is unable to view customers across all orgs.\nUC has an initiative to create a 360-degree view of the customer, as UC would like to see Account and Contact data from all orgs in one place.\nWhat should a data architect suggest to achieve this 360-degree view of the customer?","options":["A. Use Salesforce Connect's cross-org adapter.","B. Use an ETL tool to migrate gap Accounts and Contacts into each org.","C. Consolidate the data from each org into a centralized datastore","D. Build a bidirectional integration between all orgs."],"answer":"C","title":"Question 47","explanation":""},{"content":"NTO has a loyalty program to reward repeat customers. The following conditions exists:\n1. Reward levels are earned based on the amount spent during the previous 12 months.\n2. The program will track every item a customer has bought and grant them points for discount.\n3. The program generates 100 million records each month.\nNTO customer support would like to see a summary of a customer's recent transaction and reward level(s) they have attained.\nWhich solution should the data architect use to provide the information within the salesforce for the customer support agents?","options":["A. Provide a button so that the agent can quickly open the point of sales system displaying the customer history.","B. Capture the reward program data in an external data store and present the 12 months trailing summary in salesforce using salesforce connect and then external object.","C. Create a custom big object to capture the reward program data and display it on the contact record and update nightly from the point-of-scale system.","D. Create a custom object in salesforce to capture and store all reward program. Populate nightly from the point-of-scale system, and present on the customer record."],"answer":"C","title":"Question 48","explanation":""},{"content":"North Trail Outfitters (NTO) operates a majority of its business from a central Salesforce org, NTO also owns several secondary orgs that the service, finance, and marketing teams work out of, At the moment, there is no integration between central and secondary orgs, leading to data-visibility issues.\nMoving forward, NTO has identified that a hub-and-spoke model is the proper architect to manage its data, where the central org is the hub and the secondary orgs are the spokes.\nWhich tool should a data architect use to orchestrate data between the hub org and spoke orgs?","options":["A. Develop custom APIs to poll the hub org for change data and push into the spoke orgs.","B. A backup and archive solution that extracts and restores data across orgs.","C. A middleware solution that extracts and distributes data across both the hub and spokes.","D. Develop custom APIs to poll the spoke for change data and push into the org."],"answer":"C","title":"Question 49","explanation":""},{"content":"Two million Opportunities need to be loaded in different batches into Salesforce using the Bulk API in parallel mode.\nWhat should an Architect consider when loading the Opportunity records?","options":["A. Group batches by the AccountId field.","B. Order batches by Auto-number field.","C. Use the Name field values to sort batches.","D. Create indexes on Opportunity object text fields."],"answer":"A","title":"Question 50","explanation":""},{"content":"An Architect needs information about who is creating, changing, or deleting certain fields within the past four months.\nHow can the Architect access this information?","options":["A. Remove \"customize application\" permissions from everyone else.","B. After exporting the metadata, search it for the fields in question.","C. Create a field history report for the fields in question.","D. After exporting the setup audit trail, find the fields in question."],"answer":"D","title":"Question 51","explanation":""},{"content":"Get Cloudy Consulting uses an invoicing system that has specific requirements. One requirement is that attachments associated with the Invoice_c custom object be classified by Types (i.e., \"\"Purchase Order\"\", \"\"Receipt\"\", etc.) so that reporting can be performed on invoices showing the number of attachments grouped by Type.\nWhat should an Architect do to categorize the attachments to fulfill these requirements?","options":["A. Create a custom picklist field for the Type on the standard Attachment object with the values.","B. Create a custom object related to the Invoice object with a picklist field for the Type.","C. Add a ContentType picklist field to the Attachment layout and create additional picklist options.","D. Add additional options to the standard ContentType picklist field for the Attachment object."],"answer":"B","title":"Question 52","explanation":""},{"content":"UC is trying to switch from legacy CRM to salesforce and wants to keep legacy CRM and salesforce in place till all the functionality is deployed in salesforce. The want to keep data in synch b/w Salesforce, legacy CRM and SAP. What is the recommendation.","options":["A. Integrate SAP with Salesforce, SAP to legacy CRM but not legacy CRM to Salesforce","B. Do not integrate legacy CRM to Salesforce, but integrate salesforce to SAP","C. Suggest MDM solution and link MDM to salesforce and SAP","D. Integrate legacy CRM to salesforce and keep data in synch till new functionality is in place"],"answer":"A,C","title":"Question 53","explanation":""},{"content":"NTO need to extract 50 million records from a custom object everyday from its Salesforce org. NTO is facing query timeout issues while extracting these records.\nWhat should a data architect recommend in order to get around the time out issue?","options":["A. Use ETL tool for extraction of records.","B. Ask SF support to increase the query timeout value.","C. Use a custom auto number and formula field and use that to chunk records while extracting data.","D. The REST API to extract data as it automatically chunks records by 200."],"answer":"A","title":"Question 54","explanation":""},{"content":"For a production cutover, a large number of Account records will be loaded into Salesforce from a legacy system. The legacy system does not have enough information to determine the Ownership for these Accounts upon initial load. Which two recommended options assign Account ownership to mitigate potential performance problems?","options":["A. Let a \"system user\" own the Account records and assign this user to the lowest-level role in the Role Hierarchy.","B. Let a \"system user\" own all the Account records and make this user part of the highest-level role in the Role Hierarchy.","C. Let a \"system user\" own all the Account records without assigning any role to this user in Role Hierarchy.","D. Let the VP of the Sales department, who will report directly to the senior VP, own all the Account records."],"answer":"A,C","title":"Question 55","explanation":""},{"content":"Cloud Kicks has the following requirements:\n* Their Shipment custom object must always relate to a Product, a Sender, and a Receiver (all separate custom objects).\n* If a Shipment is currently associated with a Product, Sender, or Receiver, deletion of those records should not be allowed.\n* Each custom object must have separate sharing models.\nWhat should an Architect do to fulfill these requirements?","options":["A. Create a Master-Detail relationship to each of the three parent records.","B. Create two Master-Detail and one Lookup relationship to the parent records.","C. Associate the Shipment to each parent record by using a VLOOKUP formula field.","D. Create a required Lookup relationship to each of the three parent records."],"answer":"D","title":"Question 56","explanation":""},{"content":"DreamHouse Realty has an integration that creates records in a Salesforce Custom Object. The Custom Object has a field marked as required on the page layout.\nDreamHouse Realty has noticed that many of the records coming from the external system are missing data in this field.\nThe Architect needs to ensure this field always contains data coming from the source system.\nWhich two approaches should the Architect take? Choose 2 answers","options":["A. Mark the field required in setup at the field level.","B. Blame the customer's external system for bad data.","C. Create a Workflow to default a value into this field.","D. Set up a Validation Rule to prevent blank values."],"answer":"A,D","title":"Question 57","explanation":""},{"content":"A customer wishes to migrate 700,000 Account records in a single migration into Salesforce. What is the recommended solution to migrate these records while minimizing migration time?","options":["A. Use Salesforce Bulk API in parallel mode.","B. Use Salesforce Bulk API in serial mode.","C. Use Salesforce Soap API in parallel mode.","D. Use Salesforce Soap API in serial mode."],"answer":"A","title":"Question 58","explanation":""},{"content":"UC is migrating individual customers (B2C) data from legacy systems to SF. There are millions of customers stored as accounts and contacts in legacy database.\nWhich object model should a data architect configure within SF ?","options":["A. Leverage custom person account object in SF","B. Leverage custom account and contact object in SF","C. Leverage standard account and contact object in SF","D. Leverage person account object in Salesforce"],"answer":"D","title":"Question 59","explanation":""},{"content":"Universal Containers (UC) is in the process of selling half of its company. As part of this split, UC's main Salesforce org will be divided into two org:org A and org B, UC has delivered these requirements to its data architect\n1. The data model for Org B will drastically change with different objects, fields, and picklist values.\n2. Three million records will need to be migrated from org A to org B for compliance reasons.\n3. The migrate will need occur within the next two month, prior to be split.\nWhich migrate strategy should a data architect use to successfully migrate the date?","options":["A. use as ETL tool to orchestrate the migration.","B. Use Data Loader for export and Data Import Wizard for import","C. Write a script to use the Bulk API","D. Use the Salesforces CLI to query, export, and import"],"answer":"C","title":"Question 60","explanation":""},{"content":"NTO has been using salesforce for sales and service for 10 years. For the past 2 years, the marketing group has noticed a raise from 0 to 35 % in returned mail when sending mail using the contact information stored in salesforce.\nWhich solution should the data architect use to reduce the amount of returned mails?","options":["A. Use a 3rd party data source to update contact information in salesforce.","B. Have the sales team to call all existing customers and ask to verify the contact details.","C. Email all customer and asked them to verify their information and to call NTO if their address is incorrect.","D. Delete contacts when the mail is returned to save postal cost to NTO."],"answer":"A","title":"Question 61","explanation":""},{"content":"To avoid creating duplicate Contacts, a customer frequently uses Data Loader to upsert Contact records into Salesforce. What common error should the data architect be aware of when using upsert?","options":["A. Errors with duplicate external Id values within the same CSV file.","B. Errors with using the wrong external Id will cause the load to fail.","C. Errors with records being updated and inserted in the same CSV file.","D. Errors when a duplicate Contact name is found cause upsert to fail."],"answer":"A","title":"Question 62","explanation":""},{"content":"UC is having issues using Informatica Cloud Louder to export +10MOrder records. Each Order record has 10 Order Line Items. What two steps can you take to help correct this? Choose two answers.","options":["A. Limit Batch to 10K records","B. Export Bulk API in parallel mode","C. Export in multiple batches","D. Use PK Chunking"],"answer":"C,D","title":"Question 63","explanation":""},{"content":"Northern Trail Outfitter has implemented Salesforce for its associates nationwide, Senior management is concerned that the executive dashboard are not reliable for their real-time decision-making. On analysis , the team the following issues with data entered in Salesforce.\nInformation in certain records is incomplete.\nIncorrect entry in certain fields causes records to be excluded in report fitters.\nDuplicate entries cause incorrect counts.\nWhich three steps should a data architect recommend to address the issues?","options":["A. Build a sales data warehouse with purpose-build data marts for dashboards and senior management reporting.","B. Explore third-party data providers to enrich and augment information entered in salesforce.","C. Leverage Salesforce features, such as validate rules, to avoid incomplete and incorrect records.","D. Periodically export data to cleanse data and import them back into Salesforce for executive reports.","E. design and implement data-quality dashboard to monitor and act on records that are incomplete or incorrect"],"answer":"A,B,C","title":"Question 64","explanation":""},{"content":"Universal Containers (UC) is implementing Salesforce Sales Cloud and Service Cloud. As part of their implementation, they are planning to create a new custom object (Shipments), which will have a lookup relationship to Opportunities. When creating shipment records, Salesforce users need to manually input a customer reference, which is provided by customers, and will be stored in the Customer_Reference__c text custom field. Support agents will likely use this customer reference to search for Shipment records when resolving shipping issues. UC is expecting to have around 5 million shipment records created per year. What is the recommended solution to ensure that support agents using global search and reports can quickly find shipment records?","options":["A. Implement an archiving process for shipment records created after three years.","B. Set Customer-Reference_c as an External ID (unique).","C. Implement an archiving process for shipment records created after five years.","D. Set Customer-Reference_c as an External ID (non-unique)."],"answer":"B","title":"Question 65","explanation":""},{"content":"Get Cloudy Consulting monitors 15,000 servers, and these servers automatically record their status every 10 minutes. Because of company policy, these status reports must be maintained for 5 years. Managers at Get Cloudy Consulting need access to up to one week's worth of these status reports with all of their details.\nAn Architect is recommending what data should be integrated into Salesforce and for how long it should be stored in Salesforce.\nWhich two limits should the Architect be aware of? (Choose two.)","options":["A. API Request limits","B. Workflow rule limits","C. Data storage limits","D. Webservice callout limits"],"answer":"A,C","title":"Question 66","explanation":""},{"content":"Universal Containers has a custom object with millions of rows of data.\nWhen executing SOQL queries, which three options prevent a query from being selective? (Choose three.)","options":["A. Using trailing % wildcards.","B. Using NOT and != operators.","C. Performing large loads and deletions.","D. Using leading % wildcards.","E. Using a custom index on a deterministic formula field."],"answer":"B,D,E","title":"Question 67","explanation":""},{"content":"Universal Containers (UC) has a very large and complex Salesforce org with hundreds of validation rules and triggers. The triggers are responsible for system updates and data manipulation as records are created or updates by users. A majority of the automation tool within UC'' org were not designed to run during a data load. UC is importing 100,000 records into Salesforce across several objects over the weekend.\nWhat should a data architect do to mitigate any unwanted results during the import?","options":["A. Ensure duplication and matching rules and defined.","B. Ensure validation rules, triggers and other automation tools are disabled.","C. Import the data in smaller batches over a 24-hour period.","D. Bulkily the trigger to handle import leads."],"answer":"B","title":"Question 68","explanation":""},{"content":"Universal Containers wants to implement a data -quality process to monitor the data that users are manually entering into the system through the Salesforce UI. Which approach should the architect recommend?","options":["A. Allow users to import their data using the Salesforce Import tools.","B. Utilize an app from the AppExchange to create data -quality dashboards.","C. Use Apex to validate the format of phone numbers and postal codes.","D. Utilize a 3rd -party solution from the AppExchange for data uploads."],"answer":"B","title":"Question 69","explanation":""},{"content":"UC migrating 100,000 Accounts from an enterprise resource planning (ERP) to salesforce and is concerned about ownership skew and performance.\nWhich 3 recommendations should a data architect provide to prevent ownership skew?\nChoose 3 answers:","options":["A. Keep users out of public groups that can be used as the source for sharing rules.","B. Assign a default user as owner of account and do not assign any role to default user.","C. Assign \"view all\" permission on profile to give access to account.","D. Assign a default user as owner of accounts and assigned top most role in hierarchy.","E. Assigned a default user as owner of accounts, and assign role in hierarchy."],"answer":"A,B,D","title":"Question 70","explanation":""},{"content":"The data architect for UC has written a SOQL query that will return all records from the Task object that do not have a value in the WhatId field:\nSelect id, description, Subject from Task where WhatId != NULL\nWhen the data architect usages the query to select values for a process a time out error occurs.\nWhat does the data architect need to change to make this query more performant?","options":["A. Change query to SOSL. ??","B. Remove description from the requested field set.","C. Add limit 100 to the query.","D. Change the where clause to filter by a deterministic defined value."],"answer":"D","title":"Question 71","explanation":""},{"content":"Universal Containers has a legacy system that captures Conferences and Venues. These Conferences can occur at any Venue. They create hundreds of thousands of Conferences per year. Historically, they have only used 20 Venues. Which two things should the data architect consider when denormalizing this data model into a single Conference object with a Venue picklist? Choose 2 answers","options":["A. Limitations on master -detail relationships.","B. Bulk API limitations on picklist fields.","C. Standard list view in -line editing.","D. Org data storage limitations."],"answer":"B,C","title":"Question 72","explanation":""},{"content":"Universal Containers (UC) has several custom Visualforce applications have been developed in which users are able to edit Opportunity records. UC struggles with data completeness on their Opportunity records and has decided to make certain fields required that have not been in the past. The newly required fields are dependent on the Stage of the Opportunity, such that certain fields are only required once an Opportunity advances to later stages. There are two fields. What is the simplest approach to handle this new requirement?","options":["A. Use a validation rule for each field that takes the Stage into consideration.","B. Write an Apex trigger that checks each field when records are saved.","C. Update these Opportunity field definitions in Setup to be required.","D. Update the Opportunity page layout to mark these fields as required."],"answer":"A","title":"Question 73","explanation":""},{"content":"Universal Containers (CU) is in the process of implementing an enterprise data warehouse (EDW). UC needs to extract 100 million records from Salesforce for migration to the EDW.\nWhat data extraction strategy should a data architect use for maximum performance?","options":["A. Install a third-party AppExchange tool.","B. Use the Bulk API in parallel mode.","C. Call the REST API in successive queries.","D. Utilize PK Chunking with the Bulk API."],"answer":"D","title":"Question 74","explanation":""},{"content":"Universal Containers (UC) is planning to move away from legacy CRM to Salesforce. As part of one-time data migration, UC will need to keep the original date when a contact was created in the legacy system. How should an Architect design the data migration solution to meet this requirement?","options":["A. Write an Apex trigger on the Contact object, before insert event to set the original value in a standard CreatedDate field.","B. Create a new field on Contact object to capture the Created Date. Hide the standard CreatedDate field using Field -Level Security.","C. After the data is migrated, perform an update on all records to set the original date in a standard CreatedDate field.","D. Enable \"Set Audit Fields\" and assign the permission to the user loading the data for the duration of the migration."],"answer":"D","title":"Question 75","explanation":""}]