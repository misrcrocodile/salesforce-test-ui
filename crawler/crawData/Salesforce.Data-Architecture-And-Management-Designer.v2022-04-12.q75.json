[{"content":"UC has been using SF for 10 years. Lately, users have noticed, that the pages load slowly when viewing Customer and Account list view.\nTo mitigate, UC will implement a data archive strategy to reduce the amount of data actively loaded.\nWhich 2 tasks are required to define the strategy? Choose 2 answers:","options":["A. Identify the recovery point objective.","B. Identify how the archive data will be accessed and used.","C. Identify the data retention requirements","D. Identify the recovery time objective."],"answer":"B,C","title":"Question 1","explanation":""},{"content":"UC has millions of case records with case history and SLA data. UC's compliance team would like historical cases to be accessible for 10 years for Audit purpose.\nWhat solution should a data architect recommend?","options":["A. Use a custom object to store archived case data.","B. Use a custom Big object to store archived case data.","C. Purchase more data storage to support case object","D. Archive Case data using Salesforce Archiving process"],"answer":"B","title":"Question 2","explanation":""},{"content":"Northern Trail Outfitters (NTO) wants to implement backup and restore for Salesforce data, Currently, it has data backup processes that runs weekly, which back up all Salesforce data to an enterprise data warehouse (EDW). NTO wants to move to daily backups and provide restore capability to avoid any data loss in case of outage.\nWhat should a data architect recommend for a daily backup and restore solution?","options":["A. Change weekly backup process to daily backup, and implement a custom restore solution.","B. Use AppExchange package for backup and restore.","C. Use Bulk API to extract data on daily basis to EDW and REST API for restore.","D. Use ETL for backup and restore from EDW."],"answer":"B","title":"Question 3","explanation":""},{"content":"Universal Container (UC) has around 200,000 Customers (stored in Account object). They get 1 or 2 Orders every month from each Customer. Orders are stored in a custom object called \"Order c\"; this has about 50 fields. UC is expecting a growth of 10% year -over -year. What are two considerations an architect should consider to improve the performance of SOQL queries that retrieve data from the Order _c object? Choose 2 answers","options":["A. Reduce the number of triggers on Order _c object.","B. Work with Salesforce Support to enable Skinny Tables.","C. Use SOQL queries without WHERE conditions.","D. Make the queries more selective using indexed fields."],"answer":"B,D","title":"Question 4","explanation":""},{"content":"UC has one SF org (Org A) and recently acquired a secondary company with its own Salesforce org (Org B).\nUC has decided to keep the orgs running separately but would like to bidirectionally share opportunities between the orgs in near-real time.\nWhich 3 options should a data architect recommend to share data between Org A and Org B?\nChoose 3 answers.","options":["A. Use Salesforce Connect and the cross-org adapter to visualize Opportunities into external objects","B. Install a 3rd party AppExchange tool to handle the data sharing","C. Leverage Heroku Connect and Heroku Postgres to bidirectionally sync Opportunities.","D. Leverage middleware tools to bidirectionally send Opportunity data across orgs.","E. Develop an Apex class that pushes opportunity data between orgs daily via the Apex schedule."],"answer":"A,D,E","title":"Question 5","explanation":""},{"content":"DreamHouse Realty has a data model as shown in the image. The Project object has a private sharing model, and it has Roll-Up summary fields to calculate the number of resources assigned to the project, total hours for the project, and the number of work items associated to the project.\nThere will be a large amount of time entry records to be loaded regularly from an external system into Salesforce.\nWhat should the Architect consider in this situation?","options":["A. Load all data after deferring sharing calculations.","B. Calculate summary values instead of Roll-Up by using workflow.","C. Load all data using external IDs to link to parent records.","D. Calculate summary values instead of Roll-Up by using triggers."],"answer":"A","title":"Question 6","explanation":""},{"content":"NTO has implemented salesforce for its sales users. The opportunity management in salesforce is implemented as follows:\n1.Sales users enter their opportunities in salesforce for forecasting and reporting purposes.\n2.NTO has a product pricing system (PPS) that is used to update opportunity amount field on opportunities on a daily basis.\n3.PPS is the trusted source within the NTO for opportunity amount.\n4.NTO uses opportunity forecast for its sales planning and management.\nSales users have noticed that their updates to the opportunity amount field are overwritten when PPS updates their opportunities.\nHow should a data architect address this overriding issue?","options":["A. Create a custom field for opportunity amount that sales users update separating the fields that PPS updates.","B. Change opportunity amount field access to read only for sales users using field level security.","C. Change PPS integration to update only opportunity amount fields when values is NULL.","D. Create a custom field for opportunity amount that PPS updates separating the field that sales user updates."],"answer":"B","title":"Question 7","explanation":""},{"content":"Which two statements are accurate with respect to performance testing a Force.com application?","options":["A. A performance test plan must be created and submitted to Salesforce customer support.","B. Applications with highly customized code or large volumes should be performance tested.","C. Application performance benchmarked in a sandbox can also be expected in production.","D. All Force.com applications must be performance tested in a sandbox as well as production."],"answer":"A,B","title":"Question 8","explanation":""},{"content":"Universal Containers (UC) is expecting to have nearly 5 million shipments records in its Salesforce org. Each shipment record has up to 10 child shipment item records. The Shipment custom object has an Organization-wide Default (OWD) sharing model set to Private and the Shipment Item custom object has a Master-Detail relationship to Shipment. There are 25 sharing rules set on the Shipment custom object, which allow shipment records to be shared to each of UC's 25 business areas around the globe. These sharing rules use public groups, one for each business area plus a number of groups for management and support roles. UC has a high turnover of Sales Reps and often needs to move Sales Reps between business areas in order to meet local demand. What feature would ensure that performance, when moving Sales Reps between regions, remains adequate while meeting existing requirements?","options":["A. Implement data archiving for old Shipment records.","B. Configure shipment OWD to Public Read/Write.","C. Contact Salesforce to enable Defer Sharing Rules","D. Contact Salesforce to create Skinny tables on Shipment."],"answer":"C","title":"Question 9","explanation":""},{"content":"Universal Container has a Sales Cloud implementation for a sales team and an enterprise resource planning (ERP) as a customer master Sales team are complaining about duplicate account and data quality issues with account data.\nWhich two solution should a data architect recommend to resolve the complaints?","options":["A. Integrate Salesforce with ERP, and make ERP as system of truth.","B. Implement a de-dupe solution and establish account ownership in Salesforce","C. Build a nightly batch job to de-dupe data, and merge account records.","D. Build a nightly sync job from ERP to Salesforce."],"answer":"A,B","title":"Question 10","explanation":""},{"content":"Universal Containers (UC) is going thought major reorganization of their sales team. This would require changes to a large a number of group members and sharing rules. UCs administrator is concerned about long processing time and failure during the process.\nWhat should a Data architect implement to make changes efficiently?","options":["A. Enable Defer Sharing Calculation prior to making sharing rule changes.","B. Log out all users and make changes to sharing rules.","C. Delete old sharing rules and build new sharing rules","D. Log a case with salesforce to make sharing rule changes."],"answer":"A","title":"Question 11","explanation":""},{"content":"Universal Containers has a requirement to store more than 100 million records in salesforce and needs to create a custom big object to support this business requirement.\nWhich two tools should a data architect use to build custom object?","options":["A. Go to Big Object In setup select new to create big object.","B. Use DX to create big object.","C. Use Metadata API to create big object.","D. Go to Object manager In setup and select new to create big object."],"answer":"A,C","title":"Question 12","explanation":""},{"content":"What makes Skinny tables fast? Choose three answers.","options":["A. They avoid resource intensive joins","B. Their tables are kept in sync with their source tables when the source tables are modified","C. They do not include soft-deleted records","D. They can contain fields from other objects","E. They support up to a max of 100 of columns"],"answer":"A,B,C","title":"Question 13","explanation":""},{"content":"NTO would like to retrieve their SF orgs meta data programmatically for backup within a various external.\nWhich API is the best fit for accomplishing this task?","options":["A. Tooling API","B. SOAP API","C. Bulk API in serial mode","D. Metadata API"],"answer":"D","title":"Question 14","explanation":""},{"content":"Universal Containers (UC) has an open sharing model for its Salesforce users to allow all its Salesforce internal users to edit all contacts, regardless of who owns the contact. However, UC management wants to allow only the owner of a contact record to delete that contact. If a user does not own the contact, then the user should not be allowed to delete the record. How should the architect approach the project so that the requirements are met?","options":["A. Set the Sharing settings as Public Read Only for the Contact object.","B. Create a validation rule on the Contact object to check if the current user is not the owner.","C. Set the profile of the users to remove delete permission from the Contact object.","D. Create a \"before delete\" trigger to check if the current user is not the owner."],"answer":"D","title":"Question 15","explanation":""},{"content":"UC is migrating individual customers (B2C) data from legacy systems to SF. There are millions of customers stored as accounts and contacts in legacy database.\nWhich object model should a data architect configure within SF ?","options":["A. Leverage person account object in Salesforce","B. Leverage custom account and contact object in SF","C. Leverage standard account and contact object in SF","D. Leverage custom person account object in SF"],"answer":"A","title":"Question 16","explanation":""},{"content":"UC needs to load a large volume of leads into salesforce on a weekly basis. During this process the validation rules are disabled.\nWhat should a data architect recommend to ensure data quality is maintained in salesforce.","options":["A. Activate validation rules once the leads are loaded into salesforce to maintain quality.","B. Develop custom APEX batch process to improve quality once the load is completed.","C. Allow validation rules to be activated during the load of leads into salesforce.","D. Ensure the lead data is preprocessed for quality before loading into salesforce."],"answer":"B","title":"Question 17","explanation":""},{"content":"Cloud Kicks stores Invoice records in a custom object. Invoice records are being sent to the Accounting department with missing States and incorrectly formatted Postal Codes.\nWhich two actions should Cloud Kicks take to improve data quality? (Choose two.)","options":["A. Utilize a Validation Rule with a CONTAINS operator on address fields.","B. Write an Apex Trigger to require all fields to be populated.","C. Change each address field to required on the Page Layout.","D. Utilize a Validation Rule with a REGEX operator on Postal Code."],"answer":"A,D","title":"Question 18","explanation":""},{"content":"A health care provider wishes to use salesforce to track patient care. The following actions are in Salesforce\n1. Payment Providers: Orgas who pay for the care 2 patients.\n2. Doctors: They provide care plan for patients and need to support multiple patients, they are provided access to patient information.\n3. Patients: They are individuals who need care.\nA data architect needs to map the actor to Sf objects. What should be the optimal selection by the data architect?","options":["A. Patients as Contacts, Payment providers as Accounts, & Doctors as Accounts","B. Patients as Accounts, Payment providers as Accounts, & Doctors as Person Accounts","C. Patients as Person Accounts, Payment providers as Accounts, & Doctors as Person Account","D. Patients as Person Accounts, Payment providers as Accounts, & Doctors as Contacts"],"answer":"C","title":"Question 19","explanation":""},{"content":"During the implementation of Salesforce, a customer has the following requirements for Sales Orders:\n1. Sales Order information needs to be shown to users in Salesforce.\n2. Sales Orders are maintained in the on-premises enterprise resource planning (ERP).\n3. Sales Order information has more than 150 million records.\n4. Sales Orders will not be updated in Salesforce.\nWhat should a data architect recommend for maintaining Sales Orders in salesforce?","options":["A. Use external objects to maintain Sales Order in Salesforce.","B. Use Standard order object to maintain Sale Orders in Salesforce","C. Use custom big objects to maintain Sales Orders in Salesforce.","D. Us custom objects to maintain Sales Orders in Salesforce."],"answer":"A","title":"Question 20","explanation":""},{"content":"Universal Containers (UC) owns a complex Salesforce org with many Apex classes, triggers, and automated processes that will modify records if available. UC has identified that, in its current development state, UC runs change of encountering race condition on the same record.\nWhat should a data architect recommend to guarantee that records are not being updated at the same time?","options":["A. Disable classes or triggers that have the potential to obtain the same record.","B. Refactor or optimize classes and trigger for maximum CPU performance.","C. Embed the keywords FOR UPDATE after SOQL statements.","D. Migrate programmatic logic to processes and flows."],"answer":"C","title":"Question 21","explanation":""},{"content":"Universal Containers (UC) has a Salesforce instance with over 10.000 Account records. They have noticed similar, but not identical. Account names and addresses. What should UC do to ensure proper data quality?","options":["A. Make the Account Owner clean their Accounts' addresses, then merge Accounts with the same address.","B. Use a service to standardize Account addresses, then use a 3rd -party tool to merge Accounts based on rules.","C. Enable Account de -duplication by creating matching rules in Salesforce, which will mass merge duplicate Accounts.","D. Run a report, find Accounts whose name starts with the same five characters, then merge those Accounts."],"answer":"C","title":"Question 22","explanation":""},{"content":"Universal Containers (UC) is facing data quality issues where Sales Reps are creating duplicate customer accounts, contacts, and leads. UC wants to fix this issue immediately by prompting users about a record that possibly exists in Salesforce. UC wants a report regarding duplicate records. What would be the recommended approach to help UC start immediately?","options":["A. Create a before insert and update trigger on account, contact, and lead, and send an error if a duplicate is found using a custom matching criteria.","B. Create a duplicate rule for account, lead, and contact, use standard matching rules for these objects, and set the action to report and alert for both creates and edits.","C. Create a duplicate rule for account, lead, and contact, use standard matching rules for these objects, and set the action to block for both creates and edits.","D. Create an after insert and update trigger on the account, contact and lead, and send an error if a duplicate is found using a custom matching criteria."],"answer":"B","title":"Question 23","explanation":""},{"content":"Ursa Major Solar's legacy system has a quarterly accounts receivable report that compiles data from the following:\n- Accounts\n- Contacts\n- Opportunities\n- Orders\n- Order Line Items\nWhich issue will an architect have when implementing this in Salesforce?","options":["A. Salesforce does NOT allow more than four objects in a single report type.","B. Custom report types CANNOT contain Opportunity data.","C. Salesforce does NOT support Orders or Order Line Items.","D. A report CANNOT contain data from Accounts and Contacts."],"answer":"A","title":"Question 24","explanation":""},{"content":"Universal Container (US) is replacing a home grown CRM solution with Salesforce, UC has decided to migrate operational (Open and active) records to Salesforce, while keeping historical records in legacy system, UC would like historical records to be available in Salesforce on an as needed basis.\nWhich solution should a data architect recommend to meet business requirement?","options":["A. Leverage real-time integration to pull records into Salesforce.","B. Build a chair solution to go the legacy system and display records.","C. Leverage mashup to display historical records in Salesforce.","D. Bring all data Salesforce, and delete it after a year."],"answer":"C","title":"Question 25","explanation":""},{"content":"A data architect has been tasked with optimizing a data stewardship engagement for a Salesforce instance Which three areas of Salesforce should the architect review before proposing any design recommendation?\nChoose 3 answers","options":["A. Export the setup audit trail to review what fields are being used.","B. Review the sharing model to determine impact on duplicate records.","C. Review the metadata xml files for redundant fields to consolidate.","D. Determine if any integration points create records in Salesforce.","E. Run key reports to determine what fields should be required."],"answer":"B,C,E","title":"Question 26","explanation":""},{"content":"Universal Containers (UC) is concerned about the accuracy of their Customer information in Salesforce. They have recently created an enterprise-wide trusted source MDM for Customer data which they have certified to be accurate. UC has over 20 million unique customer records in the trusted source and Salesforce. What should an Architect recommend to ensure the data in Salesforce is identical to the MDM?","options":["A. Load the Trusted Source data into Salesforce and run an Apex Batch job to find difference.","B. Leave the data in Salesforce alone and assume that it will auto-correct itself over time.","C. Extract the Salesforce data into Excel and manually compare this against the trusted source.","D. Use an AppExchange package for Data Quality to match Salesforce data against the Trusted source."],"answer":"D","title":"Question 27","explanation":""},{"content":"Northern Trail Outfitters has these simple requirements for a data export process:\nFile format should be in CSV.\nProcess should be scheduled and run once per week.\nThe expert should be configurable through the Salesforce UI.\nWhich tool should a data architect leverage to accomplish these requirements?","options":["A. Third-party ETL tool","B. Data export wizard","C. Bulk API","D. Data loader"],"answer":"B","title":"Question 28","explanation":""},{"content":"Universal Containers is looking to use Salesforce to manage their sales organization. They will be migrating legacy account data from two aging systems into Salesforce. Which two design considerations should an architect take to minimize data duplication? Choose 2 answers","options":["A. Use Salesforce matching and duplicate rules.","B. Use a workflow to check and prevent duplicates.","C. Clean data before importing to Salesforce.","D. Import the data concurrently."],"answer":"A,C","title":"Question 29","explanation":""},{"content":"UC is implementing sales cloud for patient management and would like to encrypt sensitive patient records being stored in files.\nWhich solution should a data architect recommend to solve this requirement?","options":["A. Store files outside of salesforce and access them to real time.","B. Implement 3rd party App Exchange app to encrypt files.","C. Implement shield platform encryption to encrypt files.","D. Use classic encryption to encrypt files."],"answer":"C","title":"Question 30","explanation":""},{"content":"Universal Containers (UC) is concerned that data is being corrupted daily either through negligence or maliciousness. They want to implement a backup strategy to help recover any corrupted data or data mistakenly changed or even deleted. What should the data architect consider when designing a field -level audit and recovery plan?","options":["A. Schedule a weekly export file.","B. Review projected data storage needs.","C. Implement an AppExchange package.","D. Reduce data storage by purging old data."],"answer":"D","title":"Question 31","explanation":""},{"content":"The architect is planning a large data migration for Universal Containers from their legacy CRM system to Salesforce. What three things should the architect consider to optimize performance of the data migration?\nChoose 3 answers","options":["A. Deactivate approval processes and workflow rules.","B. Defer sharing calculations of the Salesforce Org.","C. Remove custom indexes on the data being loaded.","D. Determine if the legacy system is still in use.","E. Review the time zones of the User loading the data."],"answer":"A,B,C","title":"Question 32","explanation":""},{"content":"Get Cloudy Consulting uses an invoicing system that has specific requirements. One requirement is that attachments associated with the Invoice_c custom object be classified by Types (i.e., \"\"Purchase Order\"\",\n\"\"Receipt\"\", etc.) so that reporting can be performed on invoices showing the number of attachments grouped by Type.\nWhat should an Architect do to categorize the attachments to fulfill these requirements?","options":["A. Create a custom object related to the Invoice object with a picklist field for the Type.","B. Add a ContentType picklist field to the Attachment layout and create additional picklist options.","C. Add additional options to the standard ContentType picklist field for the Attachment object.","D. Create a custom picklist field for the Type on the standard Attachment object with the values."],"answer":"A","title":"Question 33","explanation":""},{"content":"The data architect for UC has written a SOQL query that will return all records from the Task object that do not have a value in the WhatId field:\nSelect id, description, Subject from Task where WhatId != NULL\nWhen the data architect usages the query to select values for a process a time out error occurs.\nWhat does the data architect need to change to make this query more performant?","options":["A. Change the where clause to filter by a deterministic defined value.","B. Remove description from the requested field set.","C. Add limit 100 to the query.","D. Change query to SOSL. ??"],"answer":"A","title":"Question 34","explanation":""},{"content":"Universal Containers (UC) has a requirement to create an Account plan object that is related to the Account object. Each Account plan needs to have an Account object, but the accessibility requirement of the Account plan is different from the Account object. What should an Architect recommend?","options":["A. Create an account plan object with a lookup relations to Account without any validation rules to enforce the Account association.","B. Create a custom account plan object as detail with Account as master with additional sharing rules to allow access.","C. Create an account plan object with a lookup relationship to Account with validation rules to enforce the Account association.","D. Create a custom account plan object as detail with Account as mater in a master-detail relationship."],"answer":"C","title":"Question 35","explanation":""},{"content":"Universal Containers (UC) is implementing a formal, cross -business -unit data governance program As part of the program, UC will implement a team to make decisions on enterprise -wide data governance. Which two roles are appropriate as members of this team? Choose 2 answers","options":["A. Salesforce Administrators","B. Operational Data Users","C. Data Domain Stewards","D. Analytics/BI Owners"],"answer":"C,D","title":"Question 36","explanation":""},{"content":"Universal Containers has two systems. Salesforce and an on -premise ERP system. An architect has been tasked with copying Opportunity records to the ERP once they reach a Closed/Won Stage. The Opportunity record in the ERP system will be read-only for all fields copied in from Salesforce. What is the optimal real-time approach that achieves this solution?","options":["A. Implement a workflow rule that sends Opportunity data through Outbound Messaging.","B. Have the ERP poll Salesforce nightly and bring in the desired Opportunities.","C. Implement an hourly integration to send Salesforce Opportunities to the ERP system.","D. Implement a Master Data Management system to determine system of record."],"answer":"A","title":"Question 37","explanation":""},{"content":"A customer wishes to migrate 700,000 Account records in a single migration into Salesforce. What is the recommended solution to migrate these records while minimizing migration time?","options":["A. Use Salesforce Bulk API in serial mode.","B. Use Salesforce Bulk API in parallel mode.","C. Use Salesforce Soap API in parallel mode.","D. Use Salesforce Soap API in serial mode."],"answer":"B","title":"Question 38","explanation":""},{"content":"Universal Containers (UC) wants to store product data in Salesforce, but the standard Product object does not support the more complex hierarchical structure which is currently being used in the product master system.\nHow can UC modify the standard Product object model to support a hierarchical data structure in order to synchronize product data from the source system to Salesforce?","options":["A. Create a custom lookup filed on the standard Product to reference the child record in the hierarchy.","B. Create a custom lookup field on the standard Product to reference the parent record in the hierarchy.","C. Create an Apex trigger to synchronize the Product Family standard picklist field on the Product object.","D. Create a custom master-detail field on the standard Product to reference the child record in the hierarchy."],"answer":"B","title":"Question 39","explanation":""},{"content":"NTO has decided to franchise its brand. Upon implementation, 1000 franchisees will be able to access BTO's product information and track large customer sales and opportunities through a portal. The Franchisees will also be able to run monthly and quarterly sales reports and projections as well as view the reports in dashboards.\nWhich licenses does NTO need to provide these features to the Franchisees?","options":["A. Customer Community license","B. Partner Community license","C. Lightning Platform license","D. Salesforce Sales Cloud license"],"answer":"B","title":"Question 40","explanation":""},{"content":"How can an architect find information about who is creating, changing, or deleting certain fields within the past two months?","options":["A. Export the metadata and search it for the fields in question.","B. Export the setup audit trail and find the fields in question.","C. Create a field history report for the fields in question.","D. Remove \"customize application\" permissions from everyone else."],"answer":"B","title":"Question 41","explanation":""},{"content":"Universal Containers (UC) provides shipping services to its customers. They use Opportunities to track customer shipments. At any given time, shipping status can be one of the 10 values. UC has 200,000 Opportunity records. When creating a new field to track shipping status on opportunity, what should the architect do to improve data quality and avoid data skew?","options":["A. Create a Master -Detail to custom object ShippingStatus c.","B. Create a picklist field, values sorted alphabetically.","C. Create a text field and make it an external ID.","D. Create a Lookup to custom object ShippingStatus c."],"answer":"B","title":"Question 42","explanation":""},{"content":"As part of addressing general data protection regulation (GDPR) requirements, UC plans to implement a data classification policy for all its internal systems that stores customer information including salesforce.\nWhat should a data architect recommend so that UC can easily classify consumer information maintained in salesforce under both standard and custom objects?","options":["A. Build reports for customer information and validate.","B. Create a custom picklist field to capture classification of information on customer.","C. Use App Exchange products to classify fields based on policy.","D. Use data classification metadata fields available in field definition."],"answer":"D","title":"Question 43","explanation":""},{"content":"Get Cloudy Consulting monitors 15,000 servers, and these servers automatically record their status every 10 minutes. Because of company policy, these status reports must be maintained for 5 years. Managers at Get Cloudy Consulting need access to up to one week's worth of these status reports with all of their details.\nAn Architect is recommending what data should be integrated into Salesforce and for how long it should be stored in Salesforce.\nWhich two limits should the Architect be aware of? (Choose two.)","options":["A. Webservice callout limits","B. API Request limits","C. Workflow rule limits","D. Data storage limits"],"answer":"B,D","title":"Question 44","explanation":""},{"content":"Universal Containers has defined a new Data Quality Plan for their Salesforce data and wants to know how they can enforce it throughout the organization. Which two approaches should an architect recommend to enforce this new plan?\nChoose 2 answers","options":["A. Schedule a weekly dashboard displaying records that are missing information to be sent to managers for review.","B. Schedule reports that will automatically catch duplicates and merge or delete the records every week.","C. Use Workflow, Validation Rules, and Force.com code (Apex) to enforce critical business processes.","D. Store all data in an external system and set up an integration to Salesforce for view -only access."],"answer":"A,C","title":"Question 45","explanation":""},{"content":"UC has the following system:\n* Billing system.\n* Customer support system.\n* CRM system.\nUS has been having trouble with business intelligence across the different systems. Recently US implemented a master data management (MDM) solution that will be the system of truth for the customer records.\nWhich MDM data element is needed to allow reporting across these systems?","options":["A. Full name.","B. Email address.","C. Phone number.","D. Global unique customer number."],"answer":"D","title":"Question 46","explanation":""},{"content":"A shipping and logistics company has created a large number of reports within Sales Cloud since Salesforce was introduced. Some of these reports analyze large amounts of data regarding the whereabouts of the company's containers, and they are starting to time out when users are trying to run the reports. What is a recommended approach to avoid these time-out issues?","options":["A. Improve reporting performance by creating a custom Visualforce report that is using a cache of the records in the report.","B. Improve reporting performance by creating a dashboard that is scheduled to run the reports only once per day.","C. Improve reporting performance by replacing the existing reports in Sales Cloud with new reports based on Analytics Cloud.","D. Improve reporting performance by creating an Apex trigger for the Report object that will pre-fetch data before the report is run."],"answer":"C","title":"Question 47","explanation":""},{"content":"For a production cutover, a large number of Account records will be loaded into Salesforce from a legacy system. The legacy system does not have enough information to determine the Ownership for these Accounts upon initial load. Which two recommended options assign Account ownership to mitigate potential performance problems?","options":["A. Let a \"system user\" own all the Account records and make this user part of the highest-level role in the Role Hierarchy.","B. Let a \"system user\" own all the Account records without assigning any role to this user in Role Hierarchy.","C. Let a \"system user\" own the Account records and assign this user to the lowest-level role in the Role Hierarchy.","D. Let the VP of the Sales department, who will report directly to the senior VP, own all the Account records."],"answer":"B,C","title":"Question 48","explanation":""},{"content":"Universal Containers is exporting 40 million Account records from Salesforce using Informatica Cloud. The ETL tool fails and the query log indicates a full table scan time-out failure. What is the recommended solution?","options":["A. Modify the export query with LIMIT clause with Batch size 10,000.","B. Modify the export job header to specify Export-in-Parallel.","C. Modify the export job header to specify Sforce-Enable-PKChunking.","D. Modify the export query that includes standard index fields(s)."],"answer":"C","title":"Question 49","explanation":""},{"content":"A large Automobile company has implemented SF for its Sales Associates. Leads flow from its website to SF using a batch integration in SF. The Batch job connects the leads to Accounts in SF. Customer visiting their retail stores are also created in SF as Accounts.\nThe company has noticed a large number of duplicate accounts in SF. On analysis, it was found that certain customers could interact with its website and also visit the store. The Sales associates use Global Search to search for customers in Salesforce before they create the customers.\nWhich scalable option should a data Architect choose to implement to avoid duplicates?","options":["A. Customize Account creation process to search if customer exists before creating an Account.","B. Create duplicate rules in SF to validate duplicates during the account creation process","C. Build Custom search based on fields on Accounts which can be matched with customer when they visit the store","D. Implement a MDM solution to validate the customer information before creating Accounts in SF."],"answer":"B","title":"Question 50","explanation":""},{"content":"Universal Containers has received complaints that customers are being called by multiple Sales Reps where the second Sales Rep that calls is unaware of the previous call by their coworker. What is a data quality problem that could cause this?","options":["A. Missing phone number on the Contact record.","B. Duplicate Activity records on a Contact.","C. Duplicate Contact records exist in the system.","D. Customer phone number has changed on the Contact record."],"answer":"C","title":"Question 51","explanation":""},{"content":"North Trail Outfitters (NTD) is in the process of evaluating big objects to store large amounts of asset data from an external system. NTO will need to report on this asset data weekly.\nWhich two native tools should a data architect recommend to achieve this reporting requirement?","options":["A. Standard SOQL queries","B. Async SOQL with a custom object","C. Standard reports and dashboards","D. Einstein Analytics"],"answer":"B,D","title":"Question 52","explanation":""},{"content":"Company S was recently acquired by Company T.\nAs part of the acquisition, all of the data for the Company S's Salesforce instance (source) must be migrated into the Company T's Salesforce instance (target). Company S has 6 million Case records.\nAn Architect has been tasked with optimizing the data load time.\nWhat should the Architect consider to achieve this goal?","options":["A. Load the data in multiple sets using Bulk API parallel processes.","B. Pre-process the data, then use Data Loader with SOAP API to upsert with zip compression enabled.","C. Utilize the Salesforce Org Migration Tool from the Setup Data Management menu.","D. Directly leverage Salesforce-to-Salesforce functionality to load Case data."],"answer":"B","title":"Question 53","explanation":""},{"content":"Universal Containers (UC) is implementing a Salesforce project with large volumes of data and daily transactions. The solution includes both real-time web service integrations and Visualforce mash -ups with back -end systems. The Salesforce Full sandbox used by the project integrates with full-scale back -end testing systems. What two types of performance testing are appropriate for this project?\nChoose 2 answers","options":["A. Pre -go -live unit testing in the Salesforce Full sandbox.","B. Stress testing against the web services hosted by the integration middleware.","C. Pre -go -live automated page -load testing against the Salesforce Full sandbox.","D. Post go -live automated page -load testing against the Salesforce Production org."],"answer":"B,C","title":"Question 54","explanation":""},{"content":"Universal Container has implemented Sales Cloud to manage patient and related health records. During a recent security audit of the system it was discovered that same standard and custom fields need to encrypted.\nWhich solution should a data architect recommend to encrypt existing fields?","options":["A. Use Apex Crypto Class encrypt customer and standard fields.","B. Expert data out of Salesforce and encrypt custom and standard fields.","C. Implement classic encryption to encrypt custom and standard fields.","D. Implement shield platform encryption to encrypt and standard fields"],"answer":"D","title":"Question 55","explanation":""},{"content":"Two million Opportunities need to be loaded in different batches into Salesforce using the Bulk API in parallel mode.\nWhat should an Architect consider when loading the Opportunity records?","options":["A. Use the Name field values to sort batches.","B. Order batches by Auto-number field.","C. Create indexes on Opportunity object text fields.","D. Group batches by the AccountId field."],"answer":"D","title":"Question 56","explanation":""},{"content":"Universal Containers (UC) uses Salesforce for tracking opportunities (Opportunity). UC uses an internal ERP system for tracking deliveries and invoicing. The ERP system supports SOAP API and OData for bi-directional integration between Salesforce and the ERP system. UC has about one million opportunities. For each opportunity, UC sends 12 invoices, one per month. UC sales reps have requirements to view current invoice status and invoice amount from the opportunity page. When creating an object to model invoices, what should the architect recommend, considering performance and data storage space?","options":["A. Create an external object Invoice _x with a Lookup relationship with Opportunity.","B. Create a custom object Invoice _c with a Lookup relationship with Opportunity.","C. Create a custom object Invoice _c with a master -detail relationship with Opportunity.","D. Use Streaming API to get the current status from the ERP and display on the Opportunity page."],"answer":"A","title":"Question 57","explanation":""},{"content":"Universal Containers keeps its Account data in Salesforce and its Invoice data in a third -party ERP system.\nThey have connected the Invoice data through a Salesforce external object. They want data from both Accounts and Invoices visible in one report in one place. What two approaches should an architect suggest for achieving this solution? Choose 2 answers","options":["A. Create a report in an external system combining Salesforce Account data and Invoice data from the ERP.","B. Create a report combining data from the Account standard object and the Invoices external object.","C. Create a separate Salesforce report for Accounts and Invoices and combine them in a dashboard.","D. Create a Visualforce page combining Salesforce Account data and Invoice external object data."],"answer":"A,D","title":"Question 58","explanation":""},{"content":"Northern trail Outfitters (NTO) uses Sales Cloud and service Cloud to manage sales and support processes.\nSome of NTOs team are complaining they see new fields on their page unsure of which values need be input.\nNTO is concerned about lack of governance in making changes to Salesforce.\nWhich governance measure should a data architect recommend to solve this issue?","options":["A. Create reports to identify which users are leaving blank, and use external data sources o agreement the missing data.","B. Add description fields to explain why the field is used, and mark the field as required.","C. Create and manage a data dictionary and ups a governance process for changes made to common objects.","D. Create validation rules with error messages to explain why the fields is used"],"answer":"C","title":"Question 59","explanation":""},{"content":"A large multinational B2C Salesforce customer is looking to implement their distributor management application is Salesforce. the application has the following capabilities:\n1.Distributor create sales order in salesforce\n2.Sales order are based on product prices applicable to their region\n3. Sales order are closed once they are fulfilled\n4. It is decided to maintain the order in opportunity object\nHow should the data architect model this requirement?","options":["A. Manually update Opportunities with Prices application to distributors.","B. Add custom fields in Opportunity and use triggers to update prices.","C. Create lookup to Custom Price object and share with distributors.","D. Configure price Books for each region and share with distributors."],"answer":"D","title":"Question 60","explanation":""},{"content":"Universal Containers (UC) has a very large and complex Salesforce org with hundreds of validation rules and triggers. The triggers are responsible for system updates and data manipulation as records are created or updates by users. A majority of the automation tool within UC'' org were not designed to run during a data load. UC is importing 100,000 records into Salesforce across several objects over the weekend.\nWhat should a data architect do to mitigate any unwanted results during the import?","options":["A. Ensure duplication and matching rules and defined.","B. Bulkily the trigger to handle import leads.","C. Ensure validation rules, triggers and other automation tools are disabled.","D. Import the data in smaller batches over a 24-hour period."],"answer":"C","title":"Question 61","explanation":""},{"content":"Universal Containers (UC) has an Application custom object, which has tens of millions of records created in the past 5 years. UC needs the last 5 years of data to exist in Salesforce at all times for reporting and queries.\nUC is currently encountering performance issues when reporting and running queries on this Object using date ranges as filters. Which two options can be used to improve report performance?","options":["A. Ask support to create a skinny table for Application with the necessary reporting fields.","B. Add custom indexes to the Date fields used for filtering the report.","C. Run multiple reports to get different pieces of the data and combine them.","D. Add custom indexes to all fields on Application without a standard index."],"answer":"A,B","title":"Question 62","explanation":""},{"content":"Universal Containers has a public website with several forms that create Lead records in Salesforce using the REST API. When designing these forms, which two techniques will help maintain a high level of data quality?","options":["A. Ensure the website visitor is browsing using an HTTPS connection.","B. Use cookies to track when visitors submit multiple forms.","C. Do client-side validation of phone number and email field formats.","D. Prefer picklist form fields over free text fields, where possible."],"answer":"C,D","title":"Question 63","explanation":""},{"content":"Universal Containers (UC) has a multi-level master-detail relationship for opportunities, a custom opportunity line item object, and a custom discount request. UC has opportunity as master and custom line item object as detail in master-detail relationship. UC also has a custom line item object as master and a custom discount request object as detail in another master-detail relationship. UC has a requirement to show all sums of discounts across line items at an opportunity level. What is the recommended solution to address these requirements?","options":["A. Roll-up discount request amount at the line-item-level and line-item-level summary discount at the opportunity level.","B. Use roll-up for the line-item-level summary and a trigger for the opportunity amount summary, as only one level roll-up is allowed.","C. Remove the master-detail relationships and rely completely on workflow/triggers to summarize the discount amount.","D. Update the master-detail relationships to lookup relationships in order to allow the discount amount to roll up."],"answer":"A","title":"Question 64","explanation":""},{"content":"UC has a variety of systems across its technology landscape, including SF, legacy enterprise resource planning (ERP) applications and homegrown CRM tools. UC has decided that they would like to consolidate all customer, opportunity and order data into Salesforce as part of its master data management (MDM) strategy.\nWhat are the 3 key steps that a data architect should take when merging data from multiple systems into Salesforce? Choose 3 answers:","options":["A. Work with Stakeholders to define record and field survivorship rules","B. Install a 3rd party AppExchange tool to handle the merger","C. Analyze each system's data model and perform gap analysis","D. Utilize an ETL tool to merge, transform and de-duplicate data.","E. Create new fields to store additional values from all the systems."],"answer":"A,C,D","title":"Question 65","explanation":""},{"content":"UC has millions of Cases and are running out of storage. Some user groups need to have access to historical cases for up to 7 years.\nWhich 2 solutions should a data architect recommend in order to minimize performance and storage issues?\nChoose 2 answers:","options":["A. Export data out of salesforce and store in Flat files on external system.","B. Leverage big object to archive case data and lightning components to show archived data.","C. Leverage on premise data archival and build integration to view archived data.","D. Create a custom object to store case history and run reports on it."],"answer":"B,C","title":"Question 66","explanation":""},{"content":"Cloud Kicks needs to purge detailed transactional records from Salesforce. The data should be aggregated at a summary level and available in Salesforce.\nWhat are two automated approaches to fulfill this goal? (Choose two.)","options":["A. Schedulable Batch Apex","B. Apex Triggers","C. Third-party Integration Tool (ETL)","D. Third-party Business Intelligence system"],"answer":"A,C","title":"Question 67","explanation":""},{"content":"Northern Trail outfitters in migrating to salesforce from a legacy CRM system that identifies the agent relationships in a look-up table.\nWhat should the data architect do in order to migrate the data to Salesfoce?","options":["A. Assign record owner based on relationship.","B. Create custom objects to store agent relationships.","C. Migrate to Salesforce without a record owner.","D. Migrate the data and assign to a non-person system user."],"answer":"B","title":"Question 68","explanation":""},{"content":"Universal Container is using Salesforce for Opportunity management and enterprise resource planning (ERP) for order management. Sales reps do not have access to the ERP and have no visibility into order status.\nWhat solution a data architect recommend to give the sales team visibility into order status?","options":["A. Build batch jobs to push order line items to salesforce.","B. Leverage Canvas to bring the order management UI in to the Salesforce tab.","C. Build real-time integration to pull order line items into Salesforce when viewing orders.","D. leverage Salesforce Connect top bring the order line item from the legacy system to Salesforce."],"answer":"D","title":"Question 69","explanation":""},{"content":"Universal Containers (UC) loads bulk leads and campaigns from third-party lead aggregators on a weekly and monthly basis. The expected lead record volume is 500K records per week, and the expected campaign records volume is 10K campaigns per week. After the upload, Lead records are shared with various sales agents via sharing rules and added as Campaign members via Apex triggers on Lead creation. UC agents work on leads for 6 months, but want to keep the records in the system for at least 1 year for reference. Compliance requires them to be stored for a minimum of 3 years. After that, data can be deleted. What statement is true with respect to a data archiving strategy for UC?","options":["A. UC can leverage the Salesforce Data Backup and Recovery feature for data archival needs.","B. UC can leverage a \"tier\"-based approach to classify the record storage need.","C. UC can leverage recycle bin capability, which guarantees record storage for 15 days after deletion.","D. UC can store long-term lead records in custom storage objects to avoid counting against storage limits."],"answer":"B","title":"Question 70","explanation":""},{"content":"UC is preparing to implement sales cloud and would like to its users to have read only access to an account record if they have access to its child opportunity record. How would a data architect implement this sharing requirement between objects?","options":["A. Implicit sharing will automatically handle with standard functionality.","B. Add appropriate users to the account team.","C. Create a criteria-based sharing rule.","D. Create an owner-based sharing rule."],"answer":"A","title":"Question 71","explanation":""},{"content":"Universal Containers (UC) has multi -level account hierarchies that represent departments within their major Accounts. Users are creating duplicate Contacts across multiple departments. UC wants to clean the data so as to have a single Contact across departments. What two solutions should UC implement to cleanse their data?\nChoose 2 answers","options":["A. Make use of the Merge Contacts feature of Salesforce to merge duplicates for an Account.","B. Use Data.com to standardize Contact address information to help identify duplicates.","C. Make use of a third -party tool to help merge duplicate Contacts across Accounts.","D. Use Workflow rules to standardize Contact information to identify and prevent duplicates."],"answer":"B,C","title":"Question 72","explanation":""},{"content":"Salesforce is being deployed in Ursa Major Solar's disparate, multi-system ERP environment. Ursa major Solar wants to maintain data synchronization between systems.\nWhich two techniques should be used to achieve this goal? (Choose two.)","options":["A. Integrate Salesforce with the ERP environment.","B. Utilize an MDM strategy to outline a single source of truth.","C. Utilize workbench to update files within systems.","D. Build synchronization reports and dashboards."],"answer":"A,B","title":"Question 73","explanation":""},{"content":"Universal Containers has deployed Salesforce for case management The company is having difficulty understanding what percentage of cases are resolved from the initial call to their support organization. What first step is recommended to implement a reporting solution to measure the support reps case closure rates?","options":["A. Create Contact and Opportunity Reports and Dashboards.","B. Install AppExchange packages for available reports.","C. Create a report on Case analytic snapshots.","D. Enable field history tracking on the Case object."],"answer":"D","title":"Question 74","explanation":""},{"content":"A custom pricing engine for a Salesforce customer has to be decided by factors with the following hierarchy:\nState in which the customer is located\nCity in which the customer is located if available\nZip code In which the customer is located if available\nChanges to this information should have minimum code changes\nWhat should a data architect recommend to maintain this information for the custom pricing engine that is to be built in Salesforce?","options":["A. Create a custom object to maintain the pricing criteria.","B. Configure the pricing criteria in price books.","C. Maintain require pricing criteria in custom metadata types.","D. Assign the pricing criteria within customer pricing engine."],"answer":"C","title":"Question 75","explanation":""}]