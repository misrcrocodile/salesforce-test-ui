[{"content":"Universal Containers (UC) has an open sharing model for its Salesforce users to allow all its Salesforce internal users to edit all contacts, regardless of who owns the contact. However, UC management wants to allow only the owner of a contact record to delete that contact. If a user does not own the contact, then the user should not be allowed to delete the record. How should the architect approach the project so that the requirements are met?","options":["A. Set the profile of the users to remove delete permission from the Contact object.","B. Create a \"before delete\" trigger to check if the current user is not the owner.","C. Create a validation rule on the Contact object to check if the current user is not the owner.","D. Set the Sharing settings as Public Read Only for the Contact object."],"answer":"B","title":"Question 1","explanation":""},{"content":"UC is planning a massive SF implementation with large volumes of data. As part of the org's implementation, several roles, territories, groups, and sharing rules have been configured. The data architect has been tasked with loading all of the required data, including user data, in a timely manner.\nWhat should a data architect do to minimize data load times due to system calculations?","options":["A. Enable defer sharing calculations, and suspend sharing rule calculations","B. Enable granular locking to avoid \"UNABLE _TO_LOCK_ROW\" error.","C. Leverage the Bulk API and concurrent processing with multiple batches","D. Load the data through data loader, and turn on parallel processing."],"answer":"A","title":"Question 2","explanation":""},{"content":"Universal Containers (UC) recently migrated 1 billion customer related records from a legacy datastore to Heroku Postgres. A subnet of the data needs to be synchronized with Salesforce so that service agents are able to support customers directly within the service console. The remaining non-synchronized set of data will need to be accessed by Salesforce at any point in time, but UC management is concerned about storage limitations.\nWhat should a data architect recommend to meet these requirements with minimal effort?","options":["A. Use Heroku Connect to bidirectionally sync all data between systems","B. As needed, make callouts into Heroku Postgres and persist the data in Salesforce","C. Virtualize the remaining set of data with Salesforce Connect and external objects","D. Migrate the data to big objects and leverage Async SOQL with custom objects"],"answer":"A","title":"Question 3","explanation":"Explanation/Reference: https://www.heroku.com/connect"},{"content":"Universal Containers wishes to send data from Salesforce to an external system to generate invoices from their Order Management System (OMS). They want a Salesforce administrator to be able to customize which fields be sent to the external system without modifying code. What two approaches should an architect recommend to deliver the desired solution? Choose 2 answers","options":["A. A set<sobjectFieldset> to determine which fields to send in an HTTP callout.","B. Enable the field -level security permissions for the fields to send.","C. An Outbound Message to determine which fields to send to the OMS.","D. A Field Set that determines which fields to send in an HTTP callout."],"answer":"C,D","title":"Question 4","explanation":""},{"content":"Universal Container require all customers to provide either a phone number of an email address when registering for an account.\nWhat should the data architect use to ensure this requirement is met?","options":["A. Process Builder","B. validation Rule","C. required Fields","D. Apex Class"],"answer":"B","title":"Question 5","explanation":""},{"content":"Universal Container (UC) has around 200,000 Customers (stored in Account object). They get 1 or 2 Orders every month from each Customer. Orders are stored in a custom object called \"Order c\"; this has about 50 fields. UC is expecting a growth of 10% year -over -year. What are two considerations an architect should consider to improve the performance of SOQL queries that retrieve data from the Order _c object? Choose 2 answers","options":["A. Use SOQL queries without WHERE conditions.","B. Make the queries more selective using indexed fields.","C. Work with Salesforce Support to enable Skinny Tables.","D. Reduce the number of triggers on Order _c object."],"answer":"B,C","title":"Question 6","explanation":""},{"content":"UC is using SF CRM. UC sales managers are complaining about data quality and would like to monitor and measure data quality.\nWhich 2 solutions should a data architect recommend to monitor and measure data quality?\nChoose 2 answers.","options":["A. Review data quality reports and dashboards.","B. Install and run data quality analysis dashboard app","C. Use custom objects and fields to identify issues.","D. Export data and check for data completeness outside of Salesforce."],"answer":"A,B","title":"Question 7","explanation":""},{"content":"UC has multiple SF orgs that are distributed across regional branches. Each branch stores local customer data inside its org's Account and Contact objects. This creates a scenario where UC is unable to view customers across all orgs.\nUC has an initiative to create a 360-degree view of the customer, as UC would like to see Account and Contact data from all orgs in one place.\nWhat should a data architect suggest to achieve this 360-degree view of the customer?","options":["A. Use an ETL tool to migrate gap Accounts and Contacts into each org.","B. Consolidate the data from each org into a centralized datastore","C. Use Salesforce Connect's cross-org adapter.","D. Build a bidirectional integration between all orgs."],"answer":"B","title":"Question 8","explanation":""},{"content":"UC is planning a massive SF implementation with large volumes of dat\na. As part of the org's implementation, several roles, territories, groups, and sharing rules have been configured. The data architect has been tasked with loading all of the required data, including user data, in a timely manner.\nWhat should a data architect do to minimize data load times due to system calculations?","options":["A. Leverage the Bulk API and concurrent processing with multiple batches","B. Enable defer sharing calculations, and suspend sharing rule calculations","C. Load the data through data loader, and turn on parallel processing.","D. Enable granular locking to avoid \"UNABLE _TO_LOCK_ROW\" error."],"answer":"B","title":"Question 9","explanation":""},{"content":"Northern Trail Outfitters has implemented Salesforce for its sales associates nationwide. Senior management is concerned that the executive dashboards are not reliable for their real-time decision-making. On analysis, the team found the following issues with data entered in Salesforce:\n1. Information in certain records is incomplete.\n2. Incorrect entry in certain fields causes records to be excluded in report filters.\n3. Duplicate entries cause incorrect counts.\nWhich three steps should a data architect recommend to address the issues? (Choose three.)","options":["A. Leverage Salesforce features, such as validation rules, to avoid incomplete and incorrect records.","B. Build a sales data warehouse with purpose-built data marts for dashboards and senior management reporting.","C. Periodically export data to cleanse data and import them back into Salesforce for executive reports.","D. Design and implement data-quality dashboard to monitor and act on records that are incomplete or incorrect.","E. Explore third-party data providers to enrich and augment information entered in Salesforce."],"answer":"A,B,E","title":"Question 10","explanation":""},{"content":"Universal Containers (UC) has an open sharing model for its Salesforce users to allow all its Salesforce internal users to edit all contacts, regardless of who owns the contact.\nHowever, UC management wants to allow only the owner of a contact record to delete that contact. If a user does not own the contact, then the user should not be allowed to delete the record. How should the architect approach the project so that the requirements are met?","options":["A. Set the profile of the users to remove delete permission from the Contact object.","B. Create a \"before delete\" trigger to check if the current user is not the owner.","C. Create a validation rule on the Contact object to check if the current user is not the owner.","D. Set the Sharing settings as Public Read Only for the Contact object."],"answer":"B","title":"Question 11","explanation":""},{"content":"UC has to built a B2C ecommerce site on Heroku that shares customer and order data with a Heroku Postgres database. UC is currently utilizing Postgres as the single source of truth for both customers and orders. UC has asked a data architect to replicate the data into salesforce so that salesforce can now act as the system of record.\nWhat are the 3 considerations that data architect should weigh before implementing this requirement? Choose\n23 answers:","options":["A. Ensure there is a tight relationship between order data and an enterprise resource plaining (ERP) application.","B. Ensure the data is CRM center and able to populate standard of custom objects.","C. - Heroku Connect is required but this is confusing","D. Determine if the data is driver of key process implemented within salesforce.","E. Consider whether the data is required for sales reports, dashboards and KPI's.","F. A selection of the tool required to replicate the data."],"answer":"B,D","title":"Question 12","explanation":""},{"content":"Universal Containers (UC) has a data model as shown in the image.\nThe Project object has a private sharing model, and it has Roll -Up summary fields to calculate the number of resources assigned to the project, total hours for the project, and the number of work items associated to the project. What should the architect consider, knowing there will be a large amount of time entry records to be loaded regularly from an external system into Salesforce.com?","options":["A. Load all data using external IDs to link to parent records.","B. Use workflow to calculate summary values instead of Roll -Up.","C. Use triggers to calculate summary values instead of Roll -Up.","D. Load all data after deferring sharing calculations."],"answer":"D","title":"Question 13","explanation":""},{"content":"Company S was recently acquired by Company T.\nAs part of the acquisition, all of the data for the Company S's Salesforce instance (source) must be migrated into the Company T's Salesforce instance (target). Company S has 6 million Case records.\nAn Architect has been tasked with optimizing the data load time.\nWhat should the Architect consider to achieve this goal?","options":["A. Pre-process the data, then use Data Loader with SOAP API to upsert with zip compression enabled.","B. Utilize the Salesforce Org Migration Tool from the Setup Data Management menu.","C. Load the data in multiple sets using Bulk API parallel processes.","D. Directly leverage Salesforce-to-Salesforce functionality to load Case data."],"answer":"A","title":"Question 14","explanation":""},{"content":"UC has been using SF for 10 years. Lately, users have noticed, that the pages load slowly when viewing Customer and Account list view.\nTo mitigate, UC will implement a data archive strategy to reduce the amount of data actively loaded.\nWhich 2 tasks are required to define the strategy? Choose 2 answers:","options":["A. Identify the recovery point objective.","B. Identify the recovery time objective.","C. Identify how the archive data will be accessed and used.","D. Identify the data retention requirements"],"answer":"C,D","title":"Question 15","explanation":""},{"content":"Universal Containers (UC) wants to store product data in Salesforce, but the standard Product object does not support the more complex hierarchical structure which is currently being used in the product master system.\nHow can UC modify the standard Product object model to support a hierarchical data structure in order to synchronize product data from the source system to Salesforce?","options":["A. Create an Apex trigger to synchronize the Product Family standard picklist field on the Product object.","B. Create a custom master-detail field on the standard Product to reference the child record in the hierarchy.","C. Create a custom lookup field on the standard Product to reference the parent record in the hierarchy.","D. Create a custom lookup filed on the standard Product to reference the child record in the hierarchy."],"answer":"C","title":"Question 16","explanation":""},{"content":"Universal Containers wants to implement a data -quality process to monitor the data that users are manually entering into the system through the Salesforce UI. Which approach should the architect recommend?","options":["A. Allow users to import their data using the Salesforce Import tools.","B. Utilize a 3rd -party solution from the AppExchange for data uploads.","C. Utilize an app from the AppExchange to create data -quality dashboards.","D. Use Apex to validate the format of phone numbers and postal codes."],"answer":"C","title":"Question 17","explanation":""},{"content":"A customer wants to maintain geographic location information including latitude and longitude in a custom object. What would a data architect recommend to satisfy this requirement?","options":["A. Create a geolocation custom field to maintain this requirement","B. Recommend app exchange packages to support this requirement.","C. Create formula fields with geolocation function for this requirement.","D. Create custom fields to maintain latitude and longitude information"],"answer":"A","title":"Question 18","explanation":""},{"content":"Ursa Major Solar's legacy system has a quarterly accounts receivable report that compiles data from the following:\n- Accounts\n- Contacts\n- Opportunities\n- Orders\n- Order Line Items\nWhich issue will an architect have when implementing this in Salesforce?","options":["A. A report CANNOT contain data from Accounts and Contacts.","B. Custom report types CANNOT contain Opportunity data.","C. Salesforce does NOT support Orders or Order Line Items.","D. Salesforce does NOT allow more than four objects in a single report type."],"answer":"D","title":"Question 19","explanation":""},{"content":"UC is building a salesforce application to track contacts and their respective conferences that they have attended with the following requirements:\n1. Contacts will be stored in the standard contact object.\n2. Conferences will be stored in a custom conference__c object.\n3. Each contact may attend multiple conferences and each conference may be related to multiple contacts.\nHow should a data architect model the relationship between the contact and conference objects?","options":["A. Create a lookup relationship field on contact object.","B. Create a master detail relationship field on the Conference object.","C. Create a master detail relationship field on the Contact object.","D. Implement a Contact Conference junction object with master detail relationship to both contact and conference__c."],"answer":"D","title":"Question 20","explanation":""},{"content":"Universal Containers is implementing Sales Cloud for patient management and would like to encrypt sensitive patient records being stored in files.\nWhich solution should a data architect recommend to solve this requirement?","options":["A. Store files outside of Salesforce and access them in real time","B. Implement Shield Platform Encryption to encrypt files","C. Use classic encryption to encrypt files","D. Implement third-party AppExchange app to encrypt files"],"answer":"B","title":"Question 21","explanation":"Explanation/Reference: https://www.salesforce.com/content/dam/web/en_us/www/documents/reports/wp-platform- encryption-architecture.pdf"},{"content":"Universal Containers is using Salesforce for Opportunity management and enterprise resource planning (ERP) for order management. Sales reps do not have access to the ERP and have no visibility into order status.\nWhat solution should a data architect recommend to give the sales team visibility into order status?","options":["A. Build real-time integration to pull order line items into Salesforce when viewing orders.","B. Build batch jobs to push order line items to Salesforce.","C. Leverage Salesforce Connect to bring the order line item from the legacy system to Salesforce.","D. Leverage Canvas to bring the order management UI in to the Salesforce tab."],"answer":"C","title":"Question 22","explanation":""},{"content":"Universal Containers (UC) wants to ensure their data on 100,000 Accounts pertaining mostly to US-based companies is enriched and cleansed on an ongoing basis. UC is looking for a solution that allows easy monitoring of key data quality metrics. What should be the recommended solution to meet this requirement?","options":["A. Use declarative approach by installing and configuring Data.com Prospector to monitor Account data quality.","B. Implement an Apex Trigger on Account that queries a third-party data quality API to monitor Account data quality.","C. Use a declarative approach by installing and configuring Data.com Clean to monitor Account data quality.","D. Implement Batch Apex that calls out a third-party data quality API in order to monitor Account data quality."],"answer":"C","title":"Question 23","explanation":""},{"content":"Get Cloudy Consulting needs to evaluate the completeness and consistency of contact information in Salesforce. Their sales reps often have incomplete information about their accounts and contacts. Additionally, they are not able to interpret the information in a consistent manner. Get Cloudy Consulting has identified certain \"\"key\"\" fields which are important to their sales reps.\nWhat are two actions Get Cloudy Consulting can take to review their data for completeness and consistency? (Choose two.)","options":["A. Run a report that shows the percentage of blanks for the important fields.","B. Run a process that can fill in default values for blank fields.","C. Run a report which shows the last time the key fields were updated.","D. Run one report per key field, grouped by that field, to understand its data variability."],"answer":"A,C","title":"Question 24","explanation":""},{"content":"Cloud Kicks often uses Data Loader to upsert Contact records into Salesforce to avoid creating duplicate Contacts.\nWhich is a common error to be aware of when using upsert?","options":["A. Errors with using the wrong external Id will cause the load to fail.","B. Errors with records being updated and inserted in the same CSV file.","C. Errors when a duplicate Contact name is found cause upsert to fail.","D. Errors with duplicate external Id values within the same CSV file."],"answer":"D","title":"Question 25","explanation":""},{"content":"Get Cloudy Consulting is migrating their legacy system's users and data to Salesforce. They will be creating\n15,000 users, 1.5 million Account records, and 15 million Invoice records. The visibility of these records is controlled by a 50 owner and criteria-based sharing rules.\nGet Cloudy Consulting needs to minimize data loading time during this migration to a new organization.\nWhich two approaches will accomplish this goal? (Choose two.)","options":["A. Contact Salesforce to activate indexing before uploading the data.","B. Defer sharing calculations until the data has finished uploading.","C. Create the users, upload all data, and then deploy the sharing rules.","D. First, load all account records, and then load all user records."],"answer":"B,C","title":"Question 26","explanation":""},{"content":"Universal Containers has a public website with several forms that create Lead records in Salesforce using the REST API. When designing these forms, which two techniques will help maintain a high level of data quality?","options":["A. Ensure the website visitor is browsing using an HTTPS connection.","B. Prefer picklist form fields over free text fields, where possible.","C. Do client-side validation of phone number and email field formats.","D. Use cookies to track when visitors submit multiple forms."],"answer":"B,C","title":"Question 27","explanation":""},{"content":"UC has the following system:\n* Billing system.\n* Customer support system.\n* CRM system.\nUS has been having trouble with business intelligence across the different systems. Recently US implemented a master data management (MDM) solution that will be the system of truth for the customer records.\nWhich MDM data element is needed to allow reporting across these systems?","options":["A. Phone number.","B. Full name.","C. Global unique customer number.","D. Email address."],"answer":"C","title":"Question 28","explanation":""},{"content":"Two million Opportunities need to be loaded in different batches into Salesforce using the Bulk API in parallel mode.\nWhat should an Architect consider when loading the Opportunity records?","options":["A. Group batches by the AccountId field.","B. Use the Name field values to sort batches.","C. Order batches by Auto-number field.","D. Create indexes on Opportunity object text fields."],"answer":"A","title":"Question 29","explanation":""},{"content":"What is an advantage of using Custom metadata type over Custom setting?","options":["A. Custom metadata records are deployable using packages.","B. Custom metadata types are available for reporting.","C. Custom metadata records are editable in Apex.","D. Custom metadata records are not copied from production to sandbox."],"answer":"A","title":"Question 30","explanation":""},{"content":"Universal Container (UC) has accumulated data over years and has never deleted data from its Salesforce org. UC is now exceeding the storage allocations in the org. UC is now looking for option to delete unused from the org.\nWhich three recommendations should a data architect make is order to reduce the number of records from the org?\nChoose 3 answers","options":["A. Use Rest API to permanently delete records from the Salesforce org.","B. Use hard delete in Bulk API to permanently delete records from Salesforce.","C. Archive the records in enterprise data warehouse (EDW) before deleting from Salesforce.","D. Identify records in objects that have not been modified or used In last 3 years.","E. Use hard delete in batch Apex to permanently delete records from Salesforce."],"answer":"B,C,D","title":"Question 31","explanation":""},{"content":"To avoid creating duplicate Contacts, a customer frequently uses Data Loader to upsert Contact records into Salesforce. What common error should the data architect be aware of when using upsert?","options":["A. Errors with duplicate external Id values within the same CSV file.","B. Errors with records being updated and inserted in the same CSV file.","C. Errors when a duplicate Contact name is found cause upsert to fail.","D. Errors with using the wrong external Id will cause the load to fail."],"answer":"A","title":"Question 32","explanation":""},{"content":"Universal Containers has a large volume of Contact data going into Salesforce.com. There are 100,000 existing contact records. 200,000 new contacts will be loaded. The Contact object has an external ID field that is unique and must be populated for all existing records. What should the architect recommend to reduce data load processing time?","options":["A. Delete all existing records, and then load all records together via the Insert operation.","B. Load Contact records together using the Streaming API via the Upsert operation.","C. Load all records via the Upsert operation to determine new records vs. existing records.","D. Load new records via the Insert operation and existing records via the Update operation."],"answer":"D","title":"Question 33","explanation":""},{"content":"Universal containers is implementing Salesforce lead management. UC Procure lead data from multiple sources and would like to make sure lead data as company profile and location information. Which solution should a data architect recommend to make sure lead data has both profile and location information? Option","options":["A. Export data out of Salesforce and send to another team to populate company profile and location data","B. Ask sales people to search for populating company profile and location data","C. Run reports to identify records which does not have company profile and location data","D. Leverage external data providers populate company profile and location data"],"answer":"C","title":"Question 34","explanation":""},{"content":"Universal Containers (UC) has a Salesforce org with multiple automated processes defined for group membership processing. UC also has multiple admins on staff that perform manual adjustments to the role hierarchy. The automated tasks and manual tasks overlap daily, and UC is experiencing \"lock errors\" consistently.\nWhat should a data architect recommend to mitigate these errors?","options":["A. Enable granular locking","B. Ask Salesforce support for additional CPU power","C. Remove SOQL statements from Apex Loops","D. Enable sharing recalculations"],"answer":"A","title":"Question 35","explanation":"Explanation/Reference: https://help.salesforce.com/articleView?id=000325942&language=en_US&type=1&mode=1"},{"content":"Universal Containers (UC) management has identified a total of ten text fields on the Contact object as important to capture any changes made to these fields, such as who made the change, when they made the change, what is the old value, and what is the new value. UC needs to be able to report on these field data changes within Salesforce for the past 3 months. What are two approaches that will meet this requirement?\nChoose 2 answers","options":["A. Create a Contact report including these ten fields and Salesforce Id, then schedule the report to run once a day and send email to the admin.","B. Write an Apex trigger on Contact after insert event and after update events and store the old values in another custom object.","C. Turn on field Contact object history tracking for these ten fields, then create reports on contact history.","D. Create a workflow to evaluate the rule when a record is created and use field update actions to store previous values for these ten fields in ten new fields."],"answer":"B,C","title":"Question 36","explanation":""},{"content":"DreamHouse Realty has a Salesforce deployment that manages Sales, Support, and Marketing efforts in a multi-system ERP environment. The company recently reached the limits of native reports and dashboards and needs options for providing more analytical insights.\nWhat are two approaches an Architect should recommend? (Choose two.)","options":["A. AppExchange Apps","B. Einstein Analytics","C. Weekly Snapshots","D. Setup Audit Trails"],"answer":"A,B","title":"Question 37","explanation":""},{"content":"What 2 data management policies does the data classification feature allow customers to classify in salesforce? Choose 2 answers:","options":["A. Data governance policy.","B. Compliance categorization policy.","C. Reference data policy.","D. Data sensitivity policy."],"answer":"B,D","title":"Question 38","explanation":""},{"content":"Universal Containers (UC) uses the following Salesforce products:\n* Sales Cloud for customer management.\n* Marketing Cloud for marketing.\n* Einstein Analytics for business reporting.\nUC occasionally gets a list of prospects from third-party sources as comma-separated values (CSV) files for marketing purposes. Historically, UC would load these contacts into Lead object in Salesforce and sync to Marketing Cloud to send marketing communications. The number of records in the Lead object has grown over time and has been consuming large amounts of storage in Sales Cloud. UC is looking for recommendations to reduce the storage and advice on how to optimize the marketing process.\nWhat should a data architect recommend to UC in order to immediately avoid storage issues in the future?","options":["A. Load the contacts directly to Marketing Cloud and have a reconciliation process to track prospects that are converted to customers.","B. Continue to use the existing process to use Lead object to sync with Marketing Cloud and delete Lead records from Sales Cloud after the sync is complete.","C. Load the CSV files in Einstein Analytics and sync with Marketing Cloud prior to sending marketing communications.","D. Load the CSV files in an external database and sync with Marketing Cloud prior to sending marketing communications."],"answer":"C","title":"Question 39","explanation":"Explanation"},{"content":"Universal Containers (UC) is in the process of selling half of its company. As part of this split, UC's main Salesforce org will be divided into two org:org A and org B, UC has delivered these requirements to its data architect\n1. The data model for Org B will drastically change with different objects, fields, and picklist values.\n2. Three million records will need to be migrated from org A to org B for compliance reasons.\n3. The migrate will need occur within the next two month, prior to be split.\nWhich migrate strategy should a data architect use to successfully migrate the date?","options":["A. Use the Salesforces CLI to query, export, and import","B. Use Data Loader for export and Data Import Wizard for import","C. use as ETL tool to orchestrate the migration.","D. Write a script to use the Bulk API"],"answer":"D","title":"Question 40","explanation":""},{"content":"DreamHouse Realty has an integration that creates records in a Salesforce Custom Object. The Custom Object has a field marked as required on the page layout.\nDreamHouse Realty has noticed that many of the records coming from the external system are missing data in this field.\nThe Architect needs to ensure this field always contains data coming from the source system.\nWhich two approaches should the Architect take? Choose 2 answers","options":["A. Mark the field required in setup at the field level.","B. Set up a Validation Rule to prevent blank values.","C. Create a Workflow to default a value into this field.","D. Blame the customer's external system for bad data."],"answer":"A,B","title":"Question 41","explanation":""},{"content":"NTO has multiple systems across its enterprise landscape including salesforce, with disparate version the customer records.\nIn salesforce, the customer is represented by the contact object.\nNTO utilizes an MDM solution with these attributes:\n1. The MDM solution keeps track of customer master with a master key.\n2. The master key is a map to the record ID's from each external system that customer data is stored within.\n3. The MDM solution provides de-duplication features, so it acts as the single source of truth.\nHow should a data architect implement the storage of master key within salesforce?","options":["A. Create a custom object to store the master key with a lookup field to contact.","B. Store the master key in Heroku postgres and use Heroku connect for synchronization.","C. Create an external object to store the master key with a lookup field to contact.","D. Store the master key on the contact object as an external ID (Field for referential imports)"],"answer":"D","title":"Question 42","explanation":""},{"content":"Universal Containers (UC) requires 2 years of customer related cases to be available on SF for operational reporting. Any cases older than 2 years and upto 7 years need to be available on demand to the Service agents. UC creates 5 million cases per yr.\nWhich 2 data archiving strategies should a data architect recommend? Choose 2 options:","options":["A. Sync cases older than 2 years to an external database, and provide access to Service agents to the database","B. Use Big objects for cases older than 2 years, and use nightly batch to move them.","C. Use custom objects for cases older than 2 years and use nightly batch to move them.","D. Use Heroku and external objects to display cases older than 2 years and bulk API to hard delete from Salesforce."],"answer":"B,D","title":"Question 43","explanation":""},{"content":"DreamHouse Realty uses Custom Metadata Types instead of Custom setting.\nWhat is an advantage of this decision?","options":["A. Custom metadata records are editable in Apex.","B. Report definitions can include references to Custom Metadata Types.","C. Custom metadata records are NOT copied from production to sandbox.","D. Packages can be used to deploy Custom metadata records."],"answer":"D","title":"Question 44","explanation":"Explanation/Reference:"},{"content":"DreamHouse Realty has a data model as shown in the image. The Project object has a private sharing model, and it has Roll-Up summary fields to calculate the number of resources assigned to the project, total hours for the project, and the number of work items associated to the project.\nThere will be a large amount of time entry records to be loaded regularly from an external system into Salesforce.\nWhat should the Architect consider in this situation?","options":["A. Calculate summary values instead of Roll-Up by using workflow.","B. Load all data after deferring sharing calculations.","C. Load all data using external IDs to link to parent records.","D. Calculate summary values instead of Roll-Up by using triggers."],"answer":"B","title":"Question 45","explanation":""},{"content":"Every year, Ursa Major Solar has more than 1 million orders. Each order contains an average of 10 line items. The Chief Executive Officer (CEO) needs the Sales Reps to see how much money each customer generates year-over-year. However, data storage is running low in Salesforce.\nWhich approach for data archiving is appropriate for this scenario?","options":["A. 1. Annually export and delete orders and order line items. 2. Store them in a zip file in case the data is needed later.","B. 1. Annually aggregate order amount data to store in a custom object. 2. Delete those orders and order line items.","C. 1. Annually delete orders and order line items. 2. Ensure the customer has order information in another system.","D. 1. Annually export and delete order line items. 2. Store them in a zip file in case the data is needed later."],"answer":"B","title":"Question 46","explanation":""},{"content":"NTO has implemented salesforce for its sales users. The opportunity management in salesforce is implemented as follows:\n1. Sales users enter their opportunities in salesforce for forecasting and reporting purposes.\n2. NTO has a product pricing system (PPS) that is used to update opportunity amount field on opportunities on a daily basis.\n3. PPS is the trusted source within the NTO for opportunity amount.\n4. NTO uses opportunity forecast for its sales planning and management.\nSales users have noticed that their updates to the opportunity amount field are overwritten when PPS updates their opportunities.\nHow should a data architect address this overriding issue?","options":["A. Change opportunity amount field access to read only for sales users using field level security.","B. Change PPS integration to update only opportunity amount fields when values is NULL.","C. Create a custom field for opportunity amount that PPS updates separating the field that sales user updates.","D. Create a custom field for opportunity amount that sales users update separating the fields that PPS updates."],"answer":"A","title":"Question 47","explanation":""},{"content":"Universal Containers (UC) has a complex system landscape and is implementing a data governance program for the first time Which two first steps would be appropriate for UC to initiate an assessment of data architecture? Choose 2 answers","options":["A. Engage with executive sponsorship to assess enterprise data strategy and goals.","B. Engage with IT program managers to assess current velocity of projects in the pipeline.","C. Engage with business units and IT to assess current operational systems and data models.","D. Engage with database administrators to assess current database performance metrics."],"answer":"A,C","title":"Question 48","explanation":""},{"content":"A health care provider wishes to use salesforce to track patient care. The following actions are in Salesforce\n1. Payment Providers: Orgas who pay for the care 2 patients.\n2. Doctors: They provide care plan for patients and need to support multiple patients, they are provided access to patient information.\n3. Patients: They are individuals who need care.\nA data architect needs to map the actor to Sf objects. What should be the optimal selection by the data architect?","options":["A. Patients as Contacts, Payment providers as Accounts, & Doctors as Accounts","B. Patients as Accounts, Payment providers as Accounts, & Doctors as Person Accounts","C. Patients as Person Accounts, Payment providers as Accounts, & Doctors as Person Account","D. Patients as Person Accounts, Payment providers as Accounts, & Doctors as Contacts"],"answer":"C","title":"Question 49","explanation":""},{"content":"US is implementing salesforce and will be using salesforce to track customer complaints, provide white papers on products and provide subscription (Fee) - based support.\nWhich license type will US users need to fulfil US's requirements?","options":["A. Lightning platform starter license.","B. Service cloud license.","C. Sales cloud license","D. Salesforce license."],"answer":"B","title":"Question 50","explanation":""},{"content":"Universal Containers has a large volume of Contact data going into Salesforce.com. There are 100,000 existing contact records. 200,000 new contacts will be loaded. The Contact object has an external ID field that is unique and must be populated for all existing records.\nWhat should the architect recommend to reduce data load processing time?","options":["A. Load all records via the Upsert operation to determine new records vs. existing records.","B. Delete all existing records, and then load all records together via the Insert operation.","C. Load Contact records together using the Streaming API via the Upsert operation.","D. Load new records via the Insert operation and existing records via the Update operation."],"answer":"D","title":"Question 51","explanation":""},{"content":"Universal Containers (UC) has implemented Salesforce, UC is running out of storage and needs to have an archiving solution, UC would like to maintain two years of data in Saleforce and archive older data out of Salesforce.\nWhich solution should a data architect recommend as an archiving solution?","options":["A. Build a batch join to move two-year-old records off platform, and delete records from Salesforce.","B. Use a third-party backup solution to backup all data off platform.","C. Build a batch join move all records off platform, and delete all records from Salesforce.","D. Build a batch job to move all restore off platform, and delete old records from Salesforce."],"answer":"B","title":"Question 52","explanation":""},{"content":"Cloud Kicks currently has a Public Read/Write sharing model for the company's Contacts. Cloud Kicks management team requests that only the owner of a contact record be allowed to delete that contact.\nWhat should an Architect do to meet these requirements?","options":["A. Check if the current user is NOT the owner by creating a \"before delete\" trigger.","B. Set the Sharing settings as Public Read Only for the Contact object.","C. Set the profile of the users to remove delete permission from the Contact object.","D. Check if the current user is NOT the owner by creating a validation rule on the Contact object."],"answer":"A","title":"Question 53","explanation":""},{"content":"Universal Containers has a legacy system that captures Conferences and Venues. These Conferences can occur at any Venue. They create hundreds of thousands of Conferences per year. Historically, they have only used\n20 Venues. Which two things should the data architect consider when de-normalizing this data model into a single Conference object with a Venue picklist? Choose 2 answers","options":["A. Bulk API limitations on picklist fields.","B. Limitations on master -detail relationships.","C. Org data storage limitations.","D. Standard list view in-line editing."],"answer":"A,C","title":"Question 54","explanation":""},{"content":"Universal Containers (UC) owns a complex Salesforce org with many Apex classes, triggers, and automated processes that will modify records if available. UC has identified that, in its current development state, UC runs change of encountering race condition on the same record.\nWhat should a data architect recommend to guarantee that records are not being updated at the same time?","options":["A. Disable classes or triggers that have the potential to obtain the same record.","B. Migrate programmatic logic to processes and flows.","C. Refactor or optimize classes and trigger for maximum CPU performance.","D. Embed the keywords FOR UPDATE after SOQL statements."],"answer":"D","title":"Question 55","explanation":""},{"content":"Universal Containers (UC) is facing data quality issues where Sales Reps are creating duplicate customer accounts, contacts, and leads. UC wants to fix this issue immediately by prompting users about a record that possibly exists in Salesforce. UC wants a report regarding duplicate records. What would be the recommended approach to help UC start immediately?","options":["A. Create a before insert and update trigger on account, contact, and lead, and send an error if a duplicate is found using a custom matching criteria.","B. Create a duplicate rule for account, lead, and contact, use standard matching rules for these objects, and set the action to block for both creates and edits.","C. Create an after insert and update trigger on the account, contact and lead, and send an error if a duplicate is found using a custom matching criteria.","D. Create a duplicate rule for account, lead, and contact, use standard matching rules for these objects, and set the action to report and alert for both creates and edits."],"answer":"D","title":"Question 56","explanation":""},{"content":"Universal Containers (UC) is implementing a new customer categorization process where customers should be assigned to a Gold, Silver, or Bronze category if they've purchased UC's new support service. Customers are expected to be evenly distributed across all three categories. Currently, UC has around 500,000 customers, and is expecting 1% of existing non-categorized customers to purchase UC's new support service every month over the next five years. What is the recommended solution to ensure long-term performance, bearing in mind the above requirements?","options":["A. Implement a new picklist custom field in the Account object with Gold, Silver, and Bronze values.","B. Implement a new Categories custom object and a master-detail relationship from Account to Category.","C. Implement a new global picklist custom field with Gold, Silver, and Bronze values and enable it in Account.","D. Implement a new Categories custom object and create a lookup field from Account to Category."],"answer":"A","title":"Question 57","explanation":""},{"content":"NTO has been using salesforce for sales and service for 10 years. For the past 2 years, the marketing group has noticed a raise from 0 to 35 % in returned mail when sending mail using the contact information stored in salesforce.\nWhich solution should the data architect use to reduce the amount of returned mails?","options":["A. Email all customer and asked them to verify their information and to call NTO if their address is incorrect.","B. Use a 3rd party data source to update contact information in salesforce.","C. Delete contacts when the mail is returned to save postal cost to NTO.","D. Have the sales team to call all existing customers and ask to verify the contact details."],"answer":"B","title":"Question 58","explanation":""},{"content":"The data architect for UC has written a SOQL query that will return all records from the Task object that do not have a value in the WhatId field:\nSelect id, description, Subject from Task where WhatId != NULL\nWhen the data architect usages the query to select values for a process a time out error occurs.\nWhat does the data architect need to change to make this query more performant?","options":["A. Remove description from the requested field set.","B. Change query to SOSL. ??","C. Add limit 100 to the query.","D. Change the where clause to filter by a deterministic defined value."],"answer":"D","title":"Question 59","explanation":""},{"content":"Universal Containers is migrating their legacy system's users and data to Salesforce. They will be creating 10,000 users,2 million Account records, and 10 million Invoice records. The visibility of these records is controlled by a few dozen owner and criteria -based sharing rules. What are two approaches that will minimize data loading time during this migration to a new organization? Choose 2 answers","options":["A. Defer sharing calculations until the data has finished uploading.","B. Create the users, upload all data, and then deploy the sharing rules.","C. Contact Salesforce to activate indexing before uploading the data.","D. First, load all account records, and then load all user records."],"answer":"A,B","title":"Question 60","explanation":""},{"content":"What are two key artifacts used to document the data architecture for a multi -system enterprise Salesforce implementation? Choose 2 answers","options":["A. Data model","B. Integration specification","C. Non-functional requirements","D. User stories"],"answer":"A,B","title":"Question 61","explanation":""},{"content":"Universal containers is implementing Salesforce lead management. UC Precure lead data from multiple sources and would like to make sure lead data as company profile and location information. Which solution should a data architect recommend to make sure lead data has both profile and location information? Option","options":["A. Ask sales people to search for populating company profile and location data","B. Run reports to identify records which does not have company profile and location data","C. Export data out of Salesforce and send to another team to populate company profile and location data","D. Leverage external data providers populate company profile and location data"],"answer":"D","title":"Question 62","explanation":""},{"content":"A large insurance provider is looking to implement Salesforce. The following exist.\n1. Multiple channel for lead acquisition\n2. Duplication leads across channels\n3. Poor customer experience and higher costs\nOn analysis, it found that there are duplicate leads that are resulting to mitigate the issues?","options":["A. Implement third-party solution to clean and event lead data.","B. Build process is manually search and merge duplicates.","C. Implement de-duplication strategy to prevent duplicate leads","D. Build a custom solution to identify and merge duplicate leads.","E. Standard lead information across all channels."],"answer":"A,C,E","title":"Question 63","explanation":""},{"content":"Universal Containers has more than 10 million records in the Order _c object. The query has timed out when running a bulk query. What should be considered to resolve query timeout?","options":["A. PK Chunking","B. Tooling API","C. Metadata API","D. Streaming API"],"answer":"A","title":"Question 64","explanation":""},{"content":"UC has a roll-up summary field on Account to calculate the count of contacts associated with an account. During the account load, SF is throwing an \"Unable to lock a row\" error.\nWhich solution should a data architect recommend, to resolve the error?","options":["A. Defer roll-up summary fields calculation during data migration.","B. Perform Batch job in serial mode and reduce batch size","C. Perform Batch job in parallel mode and reduce Batch size","D. Leverage data loader platform API to load data."],"answer":"B","title":"Question 65","explanation":""},{"content":"NTO (Northern Trail Outlets) has a complex Salesforce org which has been developed over past 5 years. Internal users are complaining abt multiple data issues, including incomplete and duplicate data in the org. NTO has decided to engage a data architect to analyze and define data quality standards.\nWhich 3 key factors should a data architect consider while defining data quality standards? Choose 3 answers:","options":["A. Measure data completeness and accuracy","B. Finalize an extract transform load (ETL) tool for data migration","C. Define key fields in staging database for data cleansing","D. Define data duplication standards and rules","E. Measure data timeliness and consistency"],"answer":"A,C,D","title":"Question 66","explanation":""},{"content":"UC migrating 100,000 Accounts from an enterprise resource planning (ERP) to salesforce and is concerned about ownership skew and performance.\nWhich 3 recommendations should a data architect provide to prevent ownership skew?\nChoose 3 answers:","options":["A. Keep users out of public groups that can be used as the source for sharing rules.","B. Assign \"view all\" permission on profile to give access to account.","C. Assigned a default user as owner of accounts, and assign role in hierarchy.","D. Assign a default user as owner of accounts and assigned top most role in hierarchy.","E. Assign a default user as owner of account and do not assign any role to default user."],"answer":"A,D,E","title":"Question 67","explanation":""},{"content":"Universal Containers wants to automatically archive all inactive Account data that is older than 3 years. The information does not need to remain accessible within the application.\nWhich two methods should be recommended to meet this requirement? Choose 2 answers","options":["A. Schedule jobs to export and delete using the Data Loader.","B. Use the Force.com Workbench to export the data.","C. Schedule a weekly export file from the Salesforce UI.","D. Schedule jobs to export and delete using an ETL tool."],"answer":"A,D","title":"Question 68","explanation":""},{"content":"A data architect has been tasked with optimizing a data stewardship engagement for a Salesforce instance Which three areas of Salesforce should the architect review before proposing any design recommendation? Choose 3 answers","options":["A. Determine if any integration points create records in Salesforce.","B. Run key reports to determine what fields should be required.","C. Review the sharing model to determine impact on duplicate records.","D. Review the metadata xml files for redundant fields to consolidate.","E. Export the setup audit trail to review what fields are being used."],"answer":"B,C,D","title":"Question 69","explanation":""},{"content":"A customer has an integration that creates records in a Salesforce Custom Object. The Custom Object has a field marked as required on the page layout. The customer has noticed that many of the records coming from the external system are missing data in this field. What two things should the architect do to ensure this field always contains data coming from the source system? Choose 2 answers","options":["A. Mark the field required in setup at the field level.","B. Set up a Validation Rule to prevent blank values.","C. Blame the customer's external system for bad data.","D. Create a Workflow to default a value into this field."],"answer":"A,B","title":"Question 70","explanation":""},{"content":"US has released a new disaster recovery (DR)policy that states that cloud solutions need a business continuity plan in place separate from the cloud providers built in data recovery solution.\nWhich solution should a data architect use to comply with the DR policy?","options":["A. Leverage salesforce weekly exports, and store data in Flat files on a protected system.","B. Leverage a 3rd party tool that extract salesforce data/metadata and stores the information in an external protected system.","C. Write a custom batch job to extract data changes nightly, and store in an external protected system.","D. Utilize an ETL tool to migrate data to an on-premise archive solution."],"answer":"B","title":"Question 71","explanation":""},{"content":"UC needs to load a large volume of leads into salesforce on a weekly basis. During this process the validation rules are disabled.\nWhat should a data architect recommend to ensure data quality is maintained in salesforce.","options":["A. Develop custom APEX batch process to improve quality once the load is completed.","B. Ensure the lead data is preprocessed for quality before loading into salesforce.","C. Activate validation rules once the leads are loaded into salesforce to maintain quality.","D. Allow validation rules to be activated during the load of leads into salesforce."],"answer":"A","title":"Question 72","explanation":""},{"content":"Company S was recently acquired by Company\nT. As part of the acquisition, all of the data for the Company S's Salesforce instance (source) must be migrated into the Company T's Salesforce instance (target). Company S has 6 million Case records.\nAn Architect has been tasked with optimizing the data load time.\nWhat should the Architect consider to achieve this goal?","options":["A. Load the data in multiple sets using Bulk API parallel processes.","B. Pre-process the data, then use Data Loader with SOAP API to upsert with zip compression enabled.","C. Directly leverage Salesforce-to-Salesforce functionality to load Case data.","D. Utilize the Salesforce Org Migration Tool from the Setup Data Management menu."],"answer":"B","title":"Question 73","explanation":""},{"content":"A large Automobile company has implemented SF for its Sales Associates. Leads flow from its website to SF using a batch integration in SF. The Batch job connects the leads to Accounts in SF. Customer visiting their retail stores are also created in SF as Accounts.\nThe company has noticed a large number of duplicate accounts in SF. On analysis, it was found that certain customers could interact with its website and also visit the store. The Sales associates use Global Search to search for customers in Salesforce before they create the customers.\nWhich scalable option should a data Architect choose to implement to avoid duplicates?","options":["A. Customize Account creation process to search if customer exists before creating an Account.","B. Implement a MDM solution to validate the customer information before creating Accounts in SF.","C. Create duplicate rules in SF to validate duplicates during the account creation process","D. Build Custom search based on fields on Accounts which can be matched with customer when they visit the store"],"answer":"C","title":"Question 74","explanation":""},{"content":"DreamHouse Realty has a legacy system that captures Branch Offices and Transactions. DreamHouse Realty has 15 Branch Offices. Transactions can relate to any Branch Office. DreamHouse Realty has created hundreds of thousands of Transactions per year.\nA Data Architect needs to denormalize this data model into a single Transaction object with a Branch Office picklist.\nWhat are two important considerations for the Data Architect in this scenario? (Choose two.)","options":["A. Limitations on Org data storage.","B. Limitations on master-detail relationships.","C. Bulk API limitations on picklist fields.","D. Standard list view in-line editing."],"answer":"A,C","title":"Question 75","explanation":""},{"content":"An Architect needs to document the data architecture for a multi-system, enterprise Salesforce implementation.\nWhich two key artifacts should the Architect use? (Choose two.)","options":["A. Data model","B. User stories","C. Non-functional requirements","D. Integration specification"],"answer":"A,D","title":"Question 76","explanation":""},{"content":"UC has a requirement to migrate 100 million order records from a legacy ERP application into the salesforce platform. UC does not have any requirements around reporting on the migrated data.\nWhat should a data architect recommend to reduce the performance degradation of the platform?","options":["A. Use a standard big object defined by salesforce.","B. Use the standard \"Order\" object to store the data.","C. Create a custom object to store the data.","D. Implement a custom big object to store the data."],"answer":"D","title":"Question 77","explanation":""},{"content":"A business that works directly with individual consumers (B2C) currently has a home-grown CRM system, but they are moving to Salesforce. The business has 1.2 million consumer records and wants assistance with achieving optimal use of Salesforce functionality while also avoiding data loading issues.\nWhat should an Architect recommend?","options":["A. Load all individual consumers as Account records and avoid using the Contact object.","B. Create a Custom object IndividualConsumer_c to load all individual consumers.","C. Load one Account record and one Contact record for each individual consumer.","D. Create one Account and load individual consumers as Contacts linked to that one Account."],"answer":"C","title":"Question 78","explanation":""},{"content":"How can an architect find information about who is creating, changing, or deleting certain fields within the past two months?","options":["A. Create a field history report for the fields in question.","B. Remove \"customize application\" permissions from everyone else.","C. Export the metadata and search it for the fields in question.","D. Export the setup audit trail and find the fields in question."],"answer":"D","title":"Question 79","explanation":""},{"content":"Northern Trail Outfitters (NTO) has implemented Salesforce for its sales users. The opportunity management in Saiesforce Is implemented as follows:\n1. Sales users enter their opportunities in Salesforce for forecasting and reporting purposes.\n2. NTO has a product pricing system (PPS) that is used to update the Opportunity Amount field on opportunities on a daily basis.\n3. PPS is the trusted source within NTO for Opportunity Amount.\n4. NTO uses Opportunity Forecast for its sales planning and management.\nSales users have noticed that their updates to the Opportunity Amount field are overwritten when PPS updates their opportunities.\nHow should a data architect address this overwriting issue?","options":["A. Create a custom field for Opportunity amount that PSS updates separating the field sales user updates.","B. Change PSS integration to update only Opportunity Amount field when the value is null.","C. Change Opportunity Amount field access to Read Only for sales users field-level security.","D. Create a custom field for Opportunity amount that sales users update separating the field that PPS updates."],"answer":"C","title":"Question 80","explanation":""},{"content":"An architect is planning on having different batches to load one million Opportunities into Salesforce using the Bulk API in parallel mode. What should be considered when loading the Opportunity records?","options":["A. Order batches by Auto -number field.","B. Sort batches by Name field values.","C. Create indexes on Opportunity object text fields.","D. Group batches by the AccountId field."],"answer":"A","title":"Question 81","explanation":""},{"content":"UC has one SF org (Org A) and recently acquired a secondary company with its own Salesforce org (Org B). UC has decided to keep the orgs running separately but would like to bidirectionally share opportunities between the orgs in near-real time.\nWhich 3 options should a data architect recommend to share data between Org A and Org B?\nChoose 3 answers.","options":["A. Leverage Heroku Connect and Heroku Postgres to bidirectionally sync Opportunities.","B. Install a 3rd party AppExchange tool to handle the data sharing","C. Develop an Apex class that pushes opportunity data between orgs daily via the Apex schedule.","D. Use Salesforce Connect and the cross-org adapter to visualize Opportunities into external objects","E. Leverage middleware tools to bidirectionally send Opportunity data across orgs."],"answer":"C,D,E","title":"Question 82","explanation":""},{"content":"In a Salesforce org used to manage Contacts, what two options should be considered to maintain data quality? Choose 2 answers","options":["A. Use Salesforce duplicate management.","B. Use validation rules on new record create and edit.","C. Use the private sharing model.","D. Use workflow to delete duplicate records."],"answer":"A,B","title":"Question 83","explanation":""},{"content":"A custom pricing engine for a Salesforce customer has to be decided by factors with the following hierarchy:\n1. State in which the customer is located\n2. City in which the customer is located if available\n3. Zip code in which the customer is located if available\n4. Changes to this information should have minimum code change\nWhat should a data architect recommend to maintain this information for the custom pricing engine that is to be built in Salesforce?","options":["A. Maintain required pricing criteria in custom metadata types.","B. Configure the pricing criteria in price books.","C. Create a custom object to maintain the pricing criteria.","D. Assign the pricing criteria within custom pricing engine."],"answer":"A","title":"Question 84","explanation":""},{"content":"DreamHouse Realty has a data model as shown in the image. The Project object has a private sharing model, and it has Roll-Up summary fields to calculate the number of resources assigned to the project, total hours for the project, and the number of work items associated to the project.\nThere will be a large amount of time entry records to be loaded regularly from an external system into Salesforce.","options":["A. Calculate summary values instead of Roll-Up by using triggers.","B. Calculate summary values instead of Roll-Up by using workflow.","C. Load all data using external IDs to link to parent records.","D. Load all data after deferring sharing calculations."],"answer":"D","title":"Question 85","explanation":""},{"content":"United Containers (UC) has released a new disaster recovery (DR) policy that states that cloud solutions need a business continuity plan in place separate from the cloud provider's built-in data recovery solution.\nWhich solution should a data architect use to comply with the DR policy?","options":["A. Utilize an ETL tool to migrate data to an on-premise archive solution","B. Write a custom batch job to extract data changes nightly, and store on an external protected system","C. Leverage a third-party tool that extracts Salesforce data/metadata, and stores the information in an external protected system","D. Leverage Salesforce weekly exports, and store data in flat files on a protected system"],"answer":"B","title":"Question 86","explanation":""},{"content":"Universal Containers (UC) is launching an RFP to acquire a new accounting product available on AppExchange. UC is expecting to issue 5 million invoices per year, with each invoice containing an average of 10 line items. What should UC's Data Architect recommend to ensure scalability?","options":["A. Ensure invoice line items simply reference existing Opportunity line items.","B. Ensure the account product vendor provides a sound data archiving strategy.","C. Ensure the accounting product runs 100% natively on the Salesforce platform.","D. Ensure the account product vendor includes Wave Analytics in their offering."],"answer":"B","title":"Question 87","explanation":""},{"content":"Get Cloudy Consulting monitors 15,000 servers, and these servers automatically record their status every 10 minutes. Because of company policy, these status reports must be maintained for 5 years. Managers at Get Cloudy Consulting need access to up to one week's worth of these status reports with all of their details.\nAn Architect is recommending what data should be integrated into Salesforce and for how long it should be stored in Salesforce.\nWhich two limits should the Architect be aware of? (Choose two.)","options":["A. Webservice callout limits","B. API Request limits","C. Data storage limits","D. Workflow rule limits"],"answer":"B,C","title":"Question 88","explanation":""},{"content":"Northern Trail Outfitters is migrating to Salesforce from a legacy CRM system that identifies the agent relationships in a look-up table.\nWhat should the data architect do in order to migrate the data to Salesforce?","options":["A. Migrate the data and assign to a non-person system user.","B. Assign record owners based on relationship.","C. Migrate to Salesforce without a record owner.","D. Create custom object to store agent relationships."],"answer":"D","title":"Question 89","explanation":""},{"content":"Cloud Kicks has a Salesforce instance with 12,000 Account records. Managers at the company have noticed similar, but not identical, Account names and addresses.\nThe Chief Technology Officer (CTO) at Cloud Kicks is concerned about proper data quality.\nWhich steps should the CTO take to address this issue?","options":["A. 1. Enable Account de-duplication by creating matching rules in Salesforce.\n         2. The system will then mass merge duplicate Accounts.","B. 1. Run a report.\n         2. Find Accounts whose name starts with the same five characters, and merge those Accounts.","C. 1. Have the Account Owner clean their Accounts' addresses.\n         2. Merge Accounts with the same address.","D. 1. Use a service to standardize Account addresses.\n         2. Use a 3rd-party tool to merge Accounts based on rules."],"answer":"A","title":"Question 90","explanation":""},{"content":"NTO has outgrown its current salesforce org and will be migrating to new org shortly. As part of this process NTO will be migrating all of its metadata and dat a. NTO's data model in the source org has a complex relationship hierarchy with several master detail and lookup relationships across objects, which should be maintained in target org.\nWhat 3 things should a data architect do to maintain the relationship hierarchy during migration?\nChoose 3 answers:","options":["A. Create a external id field for each object in the target org and map source record ID's to this field.","B. Use data loader to export the data from source org and then import or Upsert into the target org in sequential order.","C. Replace source record ID's with new record ID's from the target org in the import file.","D. Redefine the master detail relationship fields to lookup relationship fields in the target org.","E. Keep the relationship fields populated with the source record ID's in the import file."],"answer":"A,B,C","title":"Question 91","explanation":""},{"content":"Universal Containers (UC) is implementing its new Internet of Things technology, which consists of smart containers that provide information on container temperature and humidity updated every 10 minutes back to UC. There are roughly 10,000 containers equipped with this technology with the number expected to increase to 50,000 across the next five years. It is essential that Salesforce user have access to current and historical temperature and humidity data for each container. What is the recommended solution?","options":["A. Create a new Container Reading custom object, which is created when a new measure is received for a specific container. The Container Reading custom object has a master-detail relationship to the container object.","B. Create a new Lightning Component that displays last humidity and temperature data for a specific container and can also display historical trends obtaining relevant data from UC's existing data warehouse.","C. Create new custom fields for temperature and humidity in the existing Container custom object, as well as an external ID field that is unique for each container. These custom fields are updated when a new measure is received.","D. Create a new Container Reading custom object with a master-detail relationship to Container which is created when a new measure is received for a specific container. Implement an archiving process that runs every hour."],"answer":"D","title":"Question 92","explanation":""},{"content":"Universal Containers is integrating a new Opportunity engagement system with Salesforce.\nAccording to their Master Data Management strategy, Salesforce is the system of record for Account, Contact, and Opportunity data. However, there does seem to be valuable Opportunity data in the new system that potentially conflicts with what is stored in Salesforce. What is the recommended course of action to appropriately integrate this new system?","options":["A. The Opportunity engagement system should become the system of record for Opportunity records.","B. A policy should be adopted so that the system whose record was most recently updated should prevail in conflicts.","C. Stakeholders should be brought together to discuss the appropriate data strategy moving forward.","D. The MDM strategy defines Salesforce as the system of record, so Salesforce Opportunity values prevail in all conflicts."],"answer":"C","title":"Question 93","explanation":""},{"content":"NTO (Northern Trail Outlets) has a complex Salesforce org which has been developed over past 5 years.\nInternal users are complaining abt multiple data issues, including incomplete and duplicate data in the org.\nNTO has decided to engage a data architect to analyze and define data quality standards.\nWhich 3 key factors should a data architect consider while defining data quality standards? Choose 3 answers:","options":["A. Measure data timeliness and consistency","B. Define key fields in staging database for data cleansing","C. Measure data completeness and accuracy","D. Finalize an extract transform load (ETL) tool for data migration","E. Define data duplication standards and rules"],"answer":"A,C,E","title":"Question 94","explanation":""},{"content":"What should a data architect do to provide additional guidance for users when they enter information in a standard field?","options":["A. Add custom help text in default value for the field.","B. Create a custom page with help text for user guidance.","C. Provide custom help text under field properties.","D. Add a label field with help text adjacent to the custom field."],"answer":"C","title":"Question 95","explanation":""},{"content":"Northern Trail Outfitters (NTO) has implemented Salesforce for its sales users. The opportunity management in Salesforce is implemented as follows:\n1. Sales users enter their opportunities in Salesforce for forecasting and reporting purposes.\n2. NTO has a product pricing system (PPS) that is used to update Opportunity Amount field on opportunities on a daily basis.\n3. PPS is the trusted source within NTO for Opportunity Amount.\n4. NTO uses Opportunity Forecast for its sales planning and management.\nSales users have noticed that their updates to the Opportunity Amount field are overwritten when PPS updates their opportunities.\nHow should a data architect address this overwriting issue?","options":["A. Create a custom field for Opportunity amount that PPS updates separating the field sales user updates.","B. Change PPS integration to update only Opportunity Amount field when the value is null.","C. Create a custom field for Opportunity Amount that sales users update separating the field that PPS updates.","D. Change Opportunity Amount field access to Read Only for sales users using field-level security."],"answer":"C","title":"Question 96","explanation":""},{"content":"A customer is operating in a highly reputated industry and is planning to implement SF. The customer information maintained in SF, includes the following:\nPersonally, identifiable information (PII)\nIP restrictions on profiles organized by Geographic location\nFinancial records that need to be private and accessible only by the assigned Sales associate.\nUser should not be allowed to export information from Salesforce.\nEnterprise security has mandate access to be restricted to users within a specific geography and detail monitoring of user activity. Which 3 Salesforce shield capabilities should a data architect recommend? Choose 3 answers:","options":["A. Transaction security policies to prevent export of SF Data.","B. Encrypt Sensitive Customer information maintained in SF.","C. Restrict access to SF from users outside specific geography","D. Event monitoring to monitor all user activities","E. Prevent Sales users access to customer PII information"],"answer":"A,B,C","title":"Question 97","explanation":""},{"content":"Developers at Universal Containers need to build a report for the business which displays Accounts opened in the past year grouped by industry. This report will also include information from contacts, opportunities, and orders. There are several million Accounts in the system. Which two options should be recommended to make this report perform well and satisfy the business need?","options":["A. Use triggers to populate denormalized related fields on the Account.","B. Use an indexed data field with bounded data filters.","C. Use unbounded date ranges to filter the report.","D. Use Formula fields to surface information I related entities on the report."],"answer":"B,C","title":"Question 98","explanation":""},{"content":"A large retail B2C customer wants to build a 360-degree view of its customers for its call center agents. The customer information is currently maintained in the following systems:\n1. Salesforce CRM\n2. Custom billing solution\n3. Customer master data management (MDM)\n4. Contract management system\n5. Marketing solution\nWhat should a data architect recommend that would help uniquely identify the customer across multiple systems?","options":["A. Create a custom object that will serve as a cross-reference for the customer ID","B. Store the Salesforce ID in all the solutions to identify the customer","C. Create a customer database, and use this ID in all systems","D. Create a custom field as external ID to maintain the customer ID from the MDM solution"],"answer":"B","title":"Question 99","explanation":""},{"content":"Cloud Kicks has a system environment that is complex, and they plan on creating a data governance program for the first time.\nWhat are two initial actions Cloud Kicks should take to initiate an assessment of data architecture?\n(Choose two.)","options":["A. Work with executive sponsorship to assess enterprise data strategy and goals.","B. Work with database administrators to assess current database performance metrics.","C. Work with IT program managers to assess current velocity of projects in the pipeline.","D. Work with business units and IT to assess current operational systems and data models."],"answer":"A,D","title":"Question 100","explanation":""},{"content":"Managers at Universal Containers (UC) have noticed that shipment records (a custom object) are being sent to the shipping department with bad address data Specifically, addresses have missing data like City and poorly formatted Postal codes. Which two approaches will solve this issue? Choose 2 answers","options":["A. Edit each of the page layouts to require that each address field contains data.","B. Use a Validation Rule using REGEX to ensure proper Postal Code formatting.","C. Write an Apex Trigger to require all of the fields on the page layouts.","D. Use a Validation Rule using CONTAINS to ensure address fields contain data."],"answer":"B,D","title":"Question 101","explanation":""},{"content":"Cloud Kicks needs to optimize data stewardship engagement for a Salesforce instance.\nBefore proposing design recommendations, the Data Architect is first assessing relevant areas of Salesforce.\nWhich three areas are appropriate to assess? (Choose three.)","options":["A. Assess the metadata xml files for redundant fields to consolidate.","B. Determine if any integration points create records in Salesforce.","C. Export the setup audit trail to review what fields are being used.","D. Run key reports to determine what fields should be required.","E. Assess the sharing model to determine impact on duplicate records."],"answer":"A,D,E","title":"Question 102","explanation":"Explanation/Reference:"},{"content":"UC has millions of Cases and are running out of storage. Some user groups need to have access to historical cases for up to 7 years.\nWhich 2 solutions should a data architect recommend in order to minimize performance and storage issues?\nChoose 2 answers:","options":["A. Leverage on premise data archival and build integration to view archived data.","B. Leverage big object to archive case data and lightning components to show archived data.","C. Export data out of salesforce and store in Flat files on external system.","D. Create a custom object to store case history and run reports on it."],"answer":"A,B","title":"Question 103","explanation":""},{"content":"A customer wants to maintain geographic location information including latitude and longitude in a custom object. What would a data architect recommend to satisfy this requirement?","options":["A. Create a geolocation custom field to maintain this requirement","B. Create custom fields to maintain latitude and longitude information","C. Create formula fields with geolocation function for this requirement.","D. Recommend app exchange packages to support this requirement."],"answer":"B","title":"Question 104","explanation":""},{"content":"Universal Containers (UC) has implemented Sales Cloud for its entire sales organization. UC has built a custom object called Projects_c that stores customer project details and employee billable hours.\nThe following requirements are needed:\n1. A subset of individuals from the finance team will need access to the Projects object for reporting and adjusting employee utilization.\n2. The finance users will not need access to any sales objects, but they will need to interact with the custom object.\nWhich license type should a data architect recommend for the finance team that best meets the requirements?","options":["A. Service Cloud","B. Sales Cloud","C. Lightning Platform Plus","D. Lightning Platform Starter"],"answer":"C","title":"Question 105","explanation":""},{"content":"Universal container (UC) would like to build a Human resources application on Salesforce to manage employee details, payroll, and hiring efforts. To adequately and store the relevant data, the application will need to leverage 45 custom objects. In addition to this, UC expects roughly 20,00 API calls into Salesfoce from an n-premises application daily.\nWhich license type should a data architect recommend that best fits these requirements?","options":["A. Service Cloud","B. Lightning External Apps Starts","C. Lightning Platform plus","D. Lightning platform Start"],"answer":"C","title":"Question 106","explanation":""},{"content":"Get Cloudy Consulting is migrating their legacy system's users and data to Salesforce. They will be creating 15,000 users, 1.5 million Account records, and 15 million Invoice records. The visibility of these records is controlled by a 50 owner and criteria-based sharing rules.\nGet Cloudy Consulting needs to minimize data loading time during this migration to a new organization.\nWhich two approaches will accomplish this goal? (Choose two.)","options":["A. Contact Salesforce to activate indexing before uploading the data.","B. Defer sharing calculations until the data has finished uploading.","C. Load all account records, and then load all user records.","D. Create the users, upload all data, and then deploy the sharing rules."],"answer":"B,D","title":"Question 107","explanation":""},{"content":"Global Containers (GC) just acquired Universal Containers (UC). Both companies use Salesforce. and as part of the acquisition, all of the data for the UC Salesforce instance (source) must be migrated into the GC Salesforce instance (target). Universal Containers has over 5 million Case records. What should the architect consider when trying to optimize the data load time?","options":["A. Pre-process the data, then use Data Loader with SOAP API to upsert with zip compression enabled.","B. Use the Salesforce Org Migration Tool from the Setup Data Management menu.","C. Load Case data directly leveraging Salesforce-to-Salesforce functionality.","D. Break the load into multiple sets of data to be loaded using Bulk API parallel processes."],"answer":"A","title":"Question 108","explanation":""},{"content":"Northern Trail outfitters in migrating to salesforce from a legacy CRM system that identifies the agent relationships in a look-up table.\nWhat should the data architect do in order to migrate the data to Salesfoce?","options":["A. Create custom objects to store agent relationships.","B. Migrate the data and assign to a non-person system user.","C. Migrate to Salesforce without a record owner.","D. Assign record owner based on relationship."],"answer":"A","title":"Question 109","explanation":""},{"content":"","options":[],"answer":"","title":"Question ","explanation":""},{"content":"Universal Containers (UC) is planning to launch its Customer Community. The community will allow user to register shipment requests which are then processed by UC employees. Shipment requests contain header information, and then a list of no more than 5 items being shipped. UC will initially roll out its community to\n5,000 customers in Europe, and will ultimately roll out to 20,000 customers worldwide within the next two years. UC expects an average of 10 shipment requests per week per customer. UC wants customers to be able to view up to three years of shipment requests and use Saleforce reports. What is the recommended solution for UC's Data Architect to address the requirements?","options":["A. Create a custom object to track shipment requests with five lookup custom fields for each item being shipped Implement an archiving process that moves data off-platform after three years.","B. Create an external custom object to track shipment requests and a child external object to track shipment items. External objects are stored off-platform in Heroku's Postgres database.","C. Create a custom object to track shipment requests and a child custom object to track shipment items.\n         Implement an archiving process that moves data off-platform after three years.","D. Create an external custom object to track shipment requests with five lookup custom fields for each item being shipped. External objects are stored off-platform in Heroku's Postgres database."],"answer":"C","title":"Question 111","explanation":""},{"content":"Universal Containers (UC) wants to assess the completeness and consistency of contact information in Salesforce. They are finding that their sales reps in many caes do not have enough information about their accounts and contacts. Also, in many cases they are not able to interpret the information in a consistent manner. They have identified certain \"key\" fields which are important to their sales reps. Which two steps can UC implement to assess their data for completeness and consistency?","options":["A. Run one report per key field, grouped by that field, to understand its data variability.","B. Run a report which shows the last time the key fields were updated.","C. Run a report that shows the percentage of blanks for the important fields.","D. Run a process that can fill in default values for blank fields."],"answer":"B,C","title":"Question 112","explanation":""},{"content":"Universal Containers (UC) is implementing its new Internet of Things technology, which consists of smart containers that provide information on container temperature and humidity updated every 10 minutes back to UC. There are roughly 10,000 containers equipped with this technology with the number expected to increase to 50,000 across the next five years. It is essential that Salesforce user have access to current and historical temperature and humidity data for each container. What is the recommended solution?","options":["A. Create a new Container Reading custom object with a master-detail relationship to Container which is created when a new measure is received for a specific container.\n         Implement an archiving process that runs every hour.","B. Create new custom fields for temperature and humidity in the existing Container custom object, as well as an external ID field that is unique for each container. These custom fields are updated when a new measure is received.","C. Create a new Container Reading custom object, which is created when a new measure is received for a specific container. The Container Reading custom object has a master- detail relationship to the container object.","D. Create a new Lightning Component that displays last humidity and temperature data for a specific container and can also display historical trends obtaining relevant data from UC's existing data warehouse."],"answer":"A","title":"Question 113","explanation":""},{"content":"DreamHouse Realty has a data model as shown in the image. The Project object has a private sharing model, and it has Roll-Up summary fields to calculate the number of resources assigned to the project, total hours for the project, and the number of work items associated to the project.\nThere will be a large amount of time entry records to be loaded regularly from an external system into Salesforce.","options":["A. Load all data using external IDs to link to parent records.","B. Calculate summary values instead of Roll-Up by using workflow.","C. Load all data after deferring sharing calculations.","D. Calculate summary values instead of Roll-Up by using triggers."],"answer":"C","title":"Question 114","explanation":""},{"content":"UC has a variety of systems across its technology landscape, including SF, legacy enterprise resource planning (ERP) applications and homegrown CRM tools. UC has decided that they would like to consolidate all customer, opportunity and order data into Salesforce as part of its master data management (MDM) strategy.\nWhat are the 3 key steps that a data architect should take when merging data from multiple systems into Salesforce? Choose 3 answers:","options":["A. Work with Stakeholders to define record and field survivorship rules","B. Install a 3rd party AppExchange tool to handle the merger","C. Create new fields to store additional values from all the systems.","D. Analyze each system's data model and perform gap analysis","E. Utilize an ETL tool to merge, transform and de-duplicate data."],"answer":"B,D,E","title":"Question 115","explanation":""},{"content":"UC has a roll-up summary field on Account to calculate the count of contacts associated with an account. During the account load, SF is throwing an \"Unable to lock a row\" error.\nWhich solution should a data architect recommend, to resolve the error?","options":["A. Defer roll-up summary fields calculation during data migration.","B. Perform Batch job in parallel mode and reduce Batch size","C. Perform Batch job in serial mode and reduce batch size","D. Leverage data loader platform API to load data."],"answer":"B","title":"Question 116","explanation":""},{"content":"Universal Containers (UC) is migrating from a legacy system to Salesforce CRM, UC is concerned about the quality of data being entered by users and through external integrations.\nWhich two solution should a data architect recommend to mitigate data quality issues?","options":["A. Leverage picklist and lookup fields where possible","B. Leverage third-party- AppExchange tools","C. Leverage Apex to validate the format of data being entered via a mobile device.","D. Leverage validation rules and workflows."],"answer":"A,D","title":"Question 117","explanation":""},{"content":"Salesforce is being deployed in Ursa Major Solar's disparate, multi-system ERP environment. Ursa major Solar wants to maintain data synchronization between systems.\nWhich two techniques should be used to achieve this goal? (Choose two.)","options":["A. Build synchronization reports and dashboards.","B. Utilize an MDM strategy to outline a single source of truth.","C. Utilize workbench to update files within systems.","D. Integrate Salesforce with the ERP environment."],"answer":"B,D","title":"Question 118","explanation":""},{"content":"Universal Containers (CU) is in the process of implementing an enterprise data warehouse (EDW). UC needs to extract 100 million records from Salesforce for migration to the EDW.\nWhat data extraction strategy should a data architect use for maximum performance?","options":["A. Use the Bulk API in parallel mode.","B. Utilize PK Chunking with the Bulk API.","C. Install a third-party AppExchange tool.","D. Call the REST API in successive queries."],"answer":"B","title":"Question 119","explanation":""},{"content":"Universal Containers (UC) is expecting to have nearly 5 million shipments records in its Salesforce org. Each shipment record has up to 10 child shipment item records. The Shipment custom object has an Organization-wide Default (OWD) sharing model set to Private and the Shipment Item custom object has a Master-Detail relationship to Shipment. There are 25 sharing rules set on the Shipment custom object, which allow shipment records to be shared to each of UC's 25 business areas around the globe. These sharing rules use public groups, one for each business area plus a number of groups for management and support roles. UC has a high turnover of Sales Reps and often needs to move Sales Reps between business areas in order to meet local demand. What feature would ensure that performance, when moving Sales Reps between regions, remains adequate while meeting existing requirements?","options":["A. Configure shipment OWD to Public Read/Write.","B. Implement data archiving for old Shipment records.","C. Contact Salesforce to create Skinny tables on Shipment.","D. Contact Salesforce to enable Defer Sharing Rules"],"answer":"D","title":"Question 120","explanation":""},{"content":"Universal Containers uses Salesforce to track its sales opportunities The Sales VP would like to better understand key relevant performance figures and help the Sales Managers take corrective actions where appropriate. What reporting option should be considered?","options":["A. Opportunity analytic snapshot","B. Lead conversion rate report","C. Sales KPI Dashboard","D. Case SLA performance report"],"answer":"C","title":"Question 121","explanation":""},{"content":"Ursa Major Solar is performance testing a Lightning Platform application.\nWhich two statements are true about this testing? (Choose two.)","options":["A. A performance test plan must be created and submitted to Salesforce customer support.","B. Every Lightning Platform application must be performance tested in a sandbox as well as production.","C. Application performance benchmarked in a sandbox can also be expected in production.","D. Applications with highly customized code or large volumes should be performance tested."],"answer":"A,D","title":"Question 122","explanation":""},{"content":"Get Cloudy Consulting is migrating their legacy system's users and data to Salesforce. They will be creating\n15,000 users, 1.5 million Account records, and 15 million Invoice records. The visibility of these records is controlled by a 50 owner and criteria-based sharing rules.\nGet Cloudy Consulting needs to minimize data loading time during this migration to a new organization.\nWhich two approaches will accomplish this goal? (Choose two.)","options":["A. Contact Salesforce to activate indexing before uploading the data.","B. Defer sharing calculations until the data has finished uploading.","C. Create the users, upload all data, and then deploy the sharing rules.","D. Load all account records, and then load all user records."],"answer":"B,C","title":"Question 123","explanation":""},{"content":"Get Cloud Consulting needs to integrate two different systems with customer records into the Salesforce Account object. So that no duplicate records are created in Salesforce, Master Data Management will be used.\nAn Architect needs to determine which system is the system of record on a field level.\nWhat should the Architect do to achieve this goal?","options":["A. The database schema for each external system should be reviewed, and fields with different names should always be separate fields in Salesforce.","B. Any field that is an input field in either external system will be overwritten by the last record integrated and can never have a system of record.","C. Master Data Management systems determine system of record, and the Architect doesn't have to think about what data is controlled by what system.","D. Key stakeholders should review any fields that share the same purpose between systems to see how they will be used in Salesforce."],"answer":"A","title":"Question 124","explanation":""},{"content":"Universal Container has implemented Sales Cloud to manage patient and related health records. During a recent security audit of the system it was discovered that same standard and custom fields need to encrypted.\nWhich solution should a data architect recommend to encrypt existing fields?","options":["A. Implement shield platform encryption to encrypt and standard fields","B. Expert data out of Salesforce and encrypt custom and standard fields.","C. Use Apex Crypto Class encrypt customer and standard fields.","D. Implement classic encryption to encrypt custom and standard fields."],"answer":"A","title":"Question 125","explanation":""},{"content":"Universal Containers has a custom object with millions of rows of data.\nWhen executing SOQL queries, which three options prevent a query from being selective? (Choose three.)","options":["A. Using a custom index on a deterministic formula field.","B. Performing large loads and deletions.","C. Using NOT and != operators.","D. Using trailing % wildcards.","E. Using leading % wildcards."],"answer":"A,C,E","title":"Question 126","explanation":""},{"content":"Universal Containers (UC) has over 10 million accounts with an average of 20 opportunities with each account. A Sales Executive at UC needs to generate a daily report for all opportunities in a specific opportunity stage.\nWhich two key considerations should be made to make sure the performance of the report is not degraded due to large data volume?","options":["A. Number of queries running at a time.","B. Number of characters in report query.","C. Number of joins used in report query.","D. Number of records returned by report query."],"answer":"C,D","title":"Question 127","explanation":""},{"content":"UC has a salesforce org with multiple automated processes defined for group membership process. UC also have multiple admins on staff that perform manual adjustments to the role hierarchy. The automated task and manual task overlap daily and UC is experiencing \"Lock errors\" consistently.\nWhat should a data architect recommend mitigate these errors?","options":["A. Ask salesforce support for addition CPU power.","B. Remove SOQL statements from APEX loops.","C. Enable granular locking.","D. Enable sharing recalculations"],"answer":"C","title":"Question 128","explanation":""},{"content":"Universal Containers (UC) is planning to move away from legacy CRM to Salesforce. As part of one-time data migration, UC will need to keep the original date when a contact was created in the legacy system. How should an Architect design the data migration solution to meet this requirement?","options":["A. Write an Apex trigger on the Contact object, before insert event to set the original value in a standard CreatedDate field.","B. After the data is migrated, perform an update on all records to set the original date in a standard CreatedDate field.","C. Create a new field on Contact object to capture the Created Date. Hide the standard CreatedDate field using Field -Level Security.","D. Enable \"Set Audit Fields\" and assign the permission to the user loading the data for the duration of the migration."],"answer":"D","title":"Question 129","explanation":""},{"content":"Universal Containers (UC) needs to run monthly and yearly reports on opportunities and orders for sales reporting. There are 5 million opportunities and 10 million orders. Sales users are complaining that the report will regularly timeout.\nWhat is the fastest and most effective way for a data architect to solve the time-out issue?","options":["A. Create custom fields on opportunity, and copy data from order into those custom fields and run all reports on Opportunity object.","B. Create a skinny table in Salesforce, and copy order and opportunity fields into the skinny table and create the required reports on It.","C. Extract opportunity and order data from Salesforce, and use a third-party reporting tool to run reports outside of Salesforce.","D. Create an aggregate custom object that summarizes the monthly and yearly values into the required format for the required reports."],"answer":"D","title":"Question 130","explanation":""},{"content":"Universal Containers is creating a new B2C service offering for consumers to ship goods across continents. This is in addition to their well-established B2B offering. Their current Salesforce org uses the standard Account object to track B2B customers. They are expecting to have over 50,000,000 consumers over the next five years across their 50 business regions. B2C customers will be individuals. Household data is not required to be stored. What is the recommended data model for consumer account data to be stored in Salesforce?","options":["A. Use the Account object with Person Accounts and a new B2C page layout.","B. Use the Account object with a newly created Record Type for B2C customers.","C. Use 50 umbrella Accounts for each region, with customers as associated Contacts.","D. Create a new picklist value for B2C customers on the Account Type field."],"answer":"A","title":"Question 131","explanation":""},{"content":"Universal Containers (UC) is a business that works directly with individual consumers (B2C). They are moving from a current home-grown CRM system to Salesforce. UC has about one million consumer records.\nWhat should the architect recommend for optimal use of Salesforce functionality and also to avoid data loading issues?","options":["A. Create a Custom Object Individual Consumer c to load all individual consumers.","B. Load one Account record and one Contact record for each individual consumer.","C. Load all individual consumers as Account records and avoid using the Contact object.","D. Create one Account and load individual consumers as Contacts linked to that one Account."],"answer":"B","title":"Question 132","explanation":""},{"content":"A company has 12 million records, and a nightly integration queries these records.\nWhich two areas should a Data Architect investigate during troubleshooting if queries are timing out?\n(Choose two.)","options":["A. Modify the integration users' profile to have View All Data.","B. Create a formula field instead of having multiple filter criteria.","C. Make sure the query doesn't contain NULL in any filter criteria.","D. Create custom indexes on the fields used in the filter criteria."],"answer":"C,D","title":"Question 133","explanation":""},{"content":"Universal Containers (UC) is using Salesforce Sales & Service Cloud for B2C sales and customer service but they are experiencing a lot of duplicate customers in the system.\nWhich are two recommended approaches for UC to avoid duplicate data and increase the level of data quality?","options":["A. Use Duplicate Management.","B. Use an Enterprise Service Bus.","C. Use Data.com Clean","D. Use a data wharehouse."],"answer":"A,C","title":"Question 134","explanation":""},{"content":"DreamHouse Realty has a Salesforce org that is used to manage Contacts.\nWhat are two things an Architect should consider using to maintain data quality in this situation? (Choose two.)","options":["A. Use workflow to delete duplicate records.","B. Use the private sharing model.","C. Use validation rules on new record create and edit.","D. Use Salesforce duplicate management."],"answer":"C,D","title":"Question 135","explanation":""},{"content":"Universal Containers (UC) loads bulk leads and campaigns from third-party lead aggregators on a weekly and monthly basis. The expected lead record volume is 500K records per week, and the expected campaign records volume is 10K campaigns per week.\nAfter the upload, Lead records are shared with various sales agents via sharing rules and added as Campaign members via Apex triggers on Lead creation. UC agents work on leads for 6 months, but want to keep the records in the system for at least 1 year for reference. Compliance requires them to be stored for a minimum of 3 years. After that, data can be deleted. What statement is true with respect to a data archiving strategy for UC?","options":["A. UC can leverage the Salesforce Data Backup and Recovery feature for data archival needs.","B. UC can store long-term lead records in custom storage objects to avoid counting against storage limits.","C. UC can leverage recycle bin capability, which guarantees record storage for 15 days after deletion.","D. UC can leverage a \"tier\"-based approach to classify the record storage need."],"answer":"D","title":"Question 136","explanation":""},{"content":"Cloud Kicks has the following requirements:\n- Data needs to be sent from Salesforce to an external system to generate invoices from their Order Management System (OMS).\n- A Salesforce administrator must be able to customize which fields will be sent to the external system without changing code.\nWhat are two approaches for fulfilling these requirements? (Choose two.)","options":["A. A Field Set that determines which fields to send in an HTTP callout.","B. A set<sobjectFieldset> to determine which fields to send in an HTTP callout.","C. Enable the field -level security permissions for the fields to send.","D. An Outbound Message to determine which fields to send to the OMS."],"answer":"A,D","title":"Question 137","explanation":""},{"content":"Which two best practices should be followed when using SOSL for searching?","options":["A. Use Find in \"ALL FIELDS\" for faster searches.","B. Use SOSL option to ignore custom indexes as search fields are pre-indexed.","C. Keep searches specific and avoid wildcards where possible.","D. Use searches against single Objects for greater speed and accuracy."],"answer":"A,C","title":"Question 138","explanation":""}]