[{"content":"Universal Containers (UC) has an open sharing model for its Salesforce users to allow all its Salesforce internal users to edit all contacts, regardless of who owns the contact. However, UC management wants to allow only the owner of a contact record to delete that contact. If a user does not own the contact, then the user should not be allowed to delete the record. How should the architect approach the project so that the requirements are met?","options":["A. Create a validation rule on the Contact object to check if the current user is not the owner.","B. Set the Sharing settings as Public Read Only for the Contact object.","C. Set the profile of the users to remove delete permission from the Contact object.","D. Create a \"before delete\" trigger to check if the current user is not the owner."],"answer":"D","title":"Question 1","explanation":""},{"content":"Universal Containers keeps its Account data in Salesforce and its Invoice data in a third - party ERP system. They have connected the Invoice data through a Salesforce external object. They want data from both Accounts and Invoices visible in one report in one place.\nWhat two approaches should an architect suggest for achieving this solution? Choose 2 answers","options":["A. Create a report combining data from the Account standard object and the Invoices external object.","B. Create a Visualforce page combining Salesforce Account data and Invoice external object data.","C. Create a report in an external system combining Salesforce Account data and Invoice data from the ERP.","D. Create a separate Salesforce report for Accounts and Invoices and combine them in a dashboard."],"answer":"B,C","title":"Question 2","explanation":""},{"content":"NTO has implemented salesforce for its sales users. The opportunity management in salesforce is implemented as follows:\n1. Sales users enter their opportunities in salesforce for forecasting and reporting purposes.\n2. NTO has a product pricing system (PPS) that is used to update opportunity amount field on opportunities on a daily basis.\n3. PPS is the trusted source within the NTO for opportunity amount.\n4. NTO uses opportunity forecast for its sales planning and management.\nSales users have noticed that their updates to the opportunity amount field are overwritten when PPS updates their opportunities.\nHow should a data architect address this overriding issue?","options":["A. Create a custom field for opportunity amount that PPS updates separating the field that sales user updates.","B. Change PPS integration to update only opportunity amount fields when values is NULL.","C. Create a custom field for opportunity amount that sales users update separating the fields that PPS updates.","D. Change opportunity amount field access to read only for sales users using field level security."],"answer":"D","title":"Question 3","explanation":""},{"content":"An architect has been asked to provide error messages when a future date is detected in a custom Birthdate _c field on the Contact object. The client wants the ability to translate the error messages. What are two approaches the architect should use to achieve this solution? Choose 2 answers","options":["A. Create a trigger on Contact and add an error to the record with a custom label.","B. Implement a third -party validation process with translate functionality.","C. Create a workflow field update to set the standard ErrorMessage field.","D. Create a validation rule and translate the error message with translation workbench."],"answer":"A,D","title":"Question 4","explanation":""},{"content":"Universal Container require all customers to provide either a phone number of an email address when registering for an account.\nWhat should the data architect use to ensure this requirement is met?","options":["A. required Fields","B. validation Rule","C. Apex Class","D. Process Builder"],"answer":"B","title":"Question 5","explanation":""},{"content":"Which two aspects of data does an Enterprise data governance program aim to improve?","options":["A. Data usability","B. Data integrity","C. Data distribution","D. Data modeling"],"answer":"A,B","title":"Question 6","explanation":""},{"content":"UC is planning a massive SF implementation with large volumes of data. As part of the org's implementation, several roles, territories, groups, and sharing rules have been configured. The data architect has been tasked with loading all of the required data, including user data, in a timely manner.\nWhat should a data architect do to minimize data load times due to system calculations?","options":["A. Leverage the Bulk API and concurrent processing with multiple batches","B. Load the data through data loader, and turn on parallel processing.","C. Enable granular locking to avoid \"UNABLE _TO_LOCK_ROW\" error.","D. Enable defer sharing calculations, and suspend sharing rule calculations"],"answer":"D","title":"Question 7","explanation":""},{"content":"Managers at Universal Containers (UC) have noticed that shipment records (a custom object) are being sent to the shipping department with bad address data Specifically, addresses have missing data like City and poorly formatted Postal codes. Which two approaches will solve this issue? Choose 2 answers","options":["A. Use a Validation Rule using CONTAINS to ensure address fields contain data.","B. Use a Validation Rule using REGEX to ensure proper Postal Code formatting.","C. Write an Apex Trigger to require all of the fields on the page layouts.","D. Edit each of the page layouts to require that each address field contains data."],"answer":"A,B","title":"Question 8","explanation":""},{"content":"Which two statements are accurate with respect to performance testing a Force.com application?","options":["A. Application performance benchmarked in a sandbox can also be expected in production.","B. Applications with highly customized code or large volumes should be performance tested.","C. A performance test plan must be created and submitted to Salesforce customer support.","D. All Force.com applications must be performance tested in a sandbox as well as production."],"answer":"B,C","title":"Question 9","explanation":""},{"content":"Northern Trail Outfitters is migrating to Salesforce from a legacy CRM system that identifies the agent relationships in a look-up table.\nWhat should the data architect do in order to migrate the data to Salesforce?","options":["A. Migrate to Salesforce without a record owner.","B. Assign record owners based on relationship.","C. Migrate the data and assign to a non-person system user.","D. Create custom object to store agent relationships."],"answer":"D","title":"Question 10","explanation":""},{"content":"Universal Containers (UC) uses the following Salesforce products:\nSales Cloud for customer management.\nMarketing Cloud for marketing.\nEinstein Analytics for business reporting.\nUC occasionally gets a list of prospects from third-party source as comma-separated values (CSV) files for marketing purposes. Historically, UC would load contact Lead object in Salesforce and sync to Marketing Cloud to send marketing communications. The number of records in the Lead object has grown over time and has been consuming large amounts of storage in Sales Cloud, UC is looking for recommendations to reduce the storage and advice on how to optimize the marketing Cloud to send marketing communications. The number of records in the Lead object has grown over time and has been consuming large amounts of storage in Sales Cloud, UC is looking for recommendations to reduce the storage and advice on how to optimize the marketing process.\nWhat should a data architect recommend to UC in order to immediately avoid storage issues in the future?","options":["A. Load the CSV files in Einstein Analytics and sync with Marketing Cloud prior to sending marketing communications ;","B. Continue to use the existing process to use Lead object to sync with Marketing Cloud and delete Lead records from Sales after the sync is complete.","C. Load the CSV files in an external database and sync with Marketing Cloud prior to sending marketing communications.","D. Load the contacts directly to Marketing Cloud and have a reconciliation process to track prospects that are converted to customers."],"answer":"A","title":"Question 11","explanation":""},{"content":"How can an architect find information about who is creating, changing, or deleting certain fields within the past two months?","options":["A. Export the setup audit trail and find the fields in question.","B. Export the metadata and search it for the fields in question.","C. Remove \"customize application\" permissions from everyone else.","D. Create a field history report for the fields in question."],"answer":"A","title":"Question 12","explanation":""},{"content":"Universal Container is using Salesforce for Opportunity management and enterprise resource planning (ERP) for order management. Sales reps do not have access to the ERP and have no visibility into order status.\nWhat solution a data architect recommend to give the sales team visibility into order status?","options":["A. Build batch jobs to push order line items to salesforce.","B. Leverage Canvas to bring the order management UI in to the Salesforce tab.","C. leverage Salesforce Connect top bring the order line item from the legacy system to Salesforce.","D. Build real-time integration to pull order line items into Salesforce when viewing orders."],"answer":"C","title":"Question 13","explanation":""},{"content":"UC is rolling out Sales App globally to bring sales teams together on one platform. UC expects millions of opportunities and accounts to be creates and is concerned about the performance of the application.\nWhich 3 recommendations should the data architect make to avoid the data skew? Choose 3 answers.","options":["A. Assign 10000 opportunities to one account.","B. Limit associating 10000 records looking up to same records.","C. Limit assigning one user 10000 records ownership.","D. Use picklist fields rather than lookup to custom object.","E. Limit associating 10000 opportunities to one account."],"answer":"C,E","title":"Question 14","explanation":""},{"content":"Universal Container has implemented Sales Cloud to manage patient and related health records. During a recent security audit of the system it was discovered that same standard and custom fields need to encrypted.\nWhich solution should a data architect recommend to encrypt existing fields?","options":["A. Use Apex Crypto Class encrypt customer and standard fields.","B. Expert data out of Salesforce and encrypt custom and standard fields.","C. Implement classic encryption to encrypt custom and standard fields.","D. Implement shield platform encryption to encrypt and standard fields"],"answer":"D","title":"Question 15","explanation":""},{"content":"Universal Containers has a legacy system that captures Conferences and Venues. These Conferences can occur at any Venue. They create hundreds of thousands of Conferences per year. Historically, they have only used\n20 Venues. Which two things should the data architect consider when denormalizing this data model into a single Conference object with a Venue picklist? Choose 2 answers","options":["A. Standard list view in -line editing.","B. Org data storage limitations.","C. Limitations on master -detail relationships.","D. Bulk API limitations on picklist fields."],"answer":"A,D","title":"Question 16","explanation":""},{"content":"Northern trail Outfitters (NTO) uses Sales Cloud and service Cloud to manage sales and support processes. Some of NTOs team are complaining they see new fields on their page unsure of which values need be input. NTO is concerned about lack of governance in making changes to Salesforce.\nWhich governance measure should a data architect recommend to solve this issue?","options":["A. Create validation rules with error messages to explain why the fields is used","B. Add description fields to explain why the field is used, and mark the field as required.","C. Create reports to identify which users are leaving blank, and use external data sources o agreement the missing data.","D. Create and manage a data dictionary and ups a governance process for changes made to common objects."],"answer":"D","title":"Question 17","explanation":""},{"content":"Northern Trail Outfitters (NTO) has multiple systems across its enterprise landscape, including Salesforce, with disparate versions of the customer record. In Salesforce, the customer is represented by the Contact object.\nNTO utilizes a master data management (MDM) solution with these attributes:\n1. The MDM solution keeps track of the Customer Master with a Master Key.\n2. The Master Key is a map to the record IDs from each external system that customer data is stored within.\n3. The MDM solution provides deduplication features, so it acts as the Single Source of Truth.\nHow should a Data Architect implement the storage of the Master Key within Salesforce?","options":["A. Store the Master Key on the Contact object as an External ID field for referential integrity","B. Store the Master Key in Heroku Postgres and use Heroku Connect for synchronization","C. Create an external object to store the Master Key with a lookup field to Contact","D. Сreate a custom object to store the Master Key with a lookup field to Contact"],"answer":"B","title":"Question 18","explanation":""},{"content":"Get Cloudy Consulting is migrating their legacy system's users and data to Salesforce. They will be creating 15,000 users, 1.5 million Account records, and 15 million Invoice records. The visibility of these records is controlled by a 50 owner and criteria-based sharing rules.\nGet Cloudy Consulting needs to minimize data loading time during this migration to a new organization.\nWhich two approaches will accomplish this goal? (Choose two.)","options":["A. Create the users, upload all data, and then deploy the sharing rules.","B. Contact Salesforce to activate indexing before uploading the data.","C. First, load all account records, and then load all user records.","D. Defer sharing calculations until the data has finished uploading."],"answer":"A,D","title":"Question 19","explanation":""},{"content":"In their legacy system. Universal Containers has a monthly accounts receivable report that compiles data from Accounts, Contacts, Opportunities, Orders. and Order Line Items. What difficulty will an architect run into when implementing this in Salesforce?","options":["A. Salesforce allows up to four objects in a single report type.","B. Salesforce does not support Orders or Order Line Items.","C. Custom report types cannot contain Opportunity data.","D. A report cannot contain data from Accounts and Contacts."],"answer":"A","title":"Question 20","explanation":""},{"content":"Universal Containers (UC) management has identified a total of ten text fields on the Contact object as important to capture any changes made to these fields, such as who made the change, when they made the change, what is the old value, and what is the new value. UC needs to be able to report on these field data changes within Salesforce for the past 3 months. What are two approaches that will meet this requirement? Choose 2 answers","options":["A. Create a workflow to evaluate the rule when a record is created and use field update actions to store previous values for these ten fields in ten new fields.","B. LII Turn on field Contact object history tracking for these ten fields, then create reports on contact history.","C. Write an Apex trigger on Contact after insert event and after update events and store the old values in another custom object.","D. Create a Contact report including these ten fields and Salesforce Id, then schedule the report to run once a day and send email to the admin."],"answer":"B,C","title":"Question 21","explanation":""},{"content":"Ursa Major Solar has 4 million rows of data in Salesforce that are used in reports to assess historical trends. Both performance and data storage limits have become an issue.\nWhich two strategies are appropriate when discussing the issue with stakeholders? (Choose two.)","options":["A. Utilize Data Loader to extract data, aggregate it, and write it back to a custom object, then delete the original records.","B. Utilize scheduled batch Apex to copy aggregate information into a custom object and delete the original records.","C. Combine Analytics Snapshots with a purging plan by reporting on the snapshot data and deleting the original records.","D. Configure the Salesforce Archiving feature to archive older records and remove them from the data storage limits."],"answer":"B,D","title":"Question 22","explanation":""},{"content":"Universal Containers (UC) is planning to launch its Customer Community. The community will allow user to register shipment requests which are then processed by UC employees. Shipment requests contain header information, and then a list of no more than 5 items being shipped. UC will initially roll out its community to\n5,000 customers in Europe, and will ultimately roll out to 20,000 customers worldwide within the next two years. UC expects an average of 10 shipment requests per week per customer. UC wants customers to be able to view up to three years of shipment requests and use Saleforce reports. What is the recommended solution for UC's Data Architect to address the requirements?","options":["A. Create a custom object to track shipment requests and a child custom object to track shipment items.\n         Implement an archiving process that moves data off-platform after three years.","B. Create an external custom object to track shipment requests with five lookup custom fields for each item being shipped. External objects are stored off-platform in Heroku's Postgres database.","C. Create an external custom object to track shipment requests and a child external object to track shipment items. External objects are stored off-platform in Heroku's Postgres database.","D. Create a custom object to track shipment requests with five lookup custom fields for each item being shipped Implement an archiving process that moves data off-platform after three years."],"answer":"A","title":"Question 23","explanation":""},{"content":"Northern Trail Outfitters (NTO) is in the process of evaluating big objects to store large amounts of asset data from an external system. NTO will need to report on this asset data weekly.\nWhich two native tools should a data architect recommend to achieve this reporting requirement? (Choose two.)","options":["A. Standard reports and dashboards","B. Einstein Analytics","C. Async SOQL with a custom object","D. Standard SOQL queries"],"answer":"A,B","title":"Question 24","explanation":""},{"content":"A large insurance provider is looking to implement Salesforce. The following exist.\n1. Multiple channel for lead acquisition\n2. Duplication leads across channels\n3. Poor customer experience and higher costs\nOn analysis, it found that there are duplicate leads that are resulting to mitigate the issues?","options":["A. Implement de-duplication strategy to prevent duplicate leads","B. Build a custom solution to identify and merge duplicate leads.","C. Standard lead information across all channels.","D. Build process is manually search and merge duplicates.","E. Implement third-party solution to clean and event lead data."],"answer":"A,C,E","title":"Question 25","explanation":""},{"content":"Universal Containers is using Salesforce for Opportunity management and enterprise resource planning (ERP) for order management. Sales reps do not have access to the ERP and have no visibility into order status.\nWhat solution should a data architect recommend to give the sales team visibility into order status?","options":["A. Leverage Salesforce Connect to bring the order line item from the legacy system to Salesforce.","B. Build batch jobs to push order line items to Salesforce.","C. Build real-time integration to pull order line items into Salesforce when viewing orders.","D. Leverage Canvas to bring the order management UI in to the Salesforce tab."],"answer":"A","title":"Question 26","explanation":""},{"content":"Northern Trail Outfitters has these simple requirements for a data export process:\n1. File format should be in CSV.\n2. Process should be scheduled and run once per week.\n3. The export should be configurable through the Salesforce UI.\nWhich tool should a data architect leverage to accomplish these requirements?","options":["A. Data loader","B. Bulk API","C. Data export wizard","D. Third-party ETL tool"],"answer":"C","title":"Question 27","explanation":"Explanation/Reference: https://hevodata.com/learn/automate-salesforce-data-export-4-easy-methods/"},{"content":"Universal Containers has a large number of Opportunity fields (100) that they want to track field history on. Which two actions should an architect perform in order to meet this requirement? Choose 2 answers","options":["A. Create a custom object to store a copy of the record when changed.","B. Select the 100 fields in the Opportunity Set History Tracking page.","C. Create a custom object to store the previous and new field values.","D. Use Analytic Snapshots to store a copy of the record when changed."],"answer":"A,C","title":"Question 28","explanation":""},{"content":"To address different compliance requirements, such as general data protection regulation (GDPR), personally identifiable information (PII), of health insurance Portability and Accountability Act (HIPPA) and others, a SF customer decided to categorize each data element in SF with the following:\nData owner\nSecurity Level, such as confidential\nCompliance types such as GDPR, PII, HIPPA\nA compliance audit would require SF admins to generate reports to manage compliance.\nWhat should a data architect recommend to address this requirement?","options":["A. Use metadata API, to extract field attribute information and use the extract to classify and build reports","B. Build reports for field information, then export the information to classify and report for Audits.","C. Use field metadata attributes for compliance categorization, data owner, and data sensitivity level.","D. Create a custom object and field to capture necessary compliance information and build custom reports."],"answer":"C","title":"Question 29","explanation":""},{"content":"Ursa Major Solar has defined a new Data Quality Plan for their Salesforce data.\nWhich two approaches should an Architect recommend to enforce the plan throughout the organization? (Choose two.)","options":["A. Schedule a weekly dashboard displaying records that are missing information to be sent to managers for review.","B. Enforce critical business processes by using Workflow, Validation Rules, and Apex code.","C. Ensure all data is stored in an external system and set up an integration to Salesforce for view-only access.","D. Schedule reports that will automatically catch duplicates and merge or delete the records every week."],"answer":"A,B","title":"Question 30","explanation":""},{"content":"Northern Trail Outfitters (NTO) wants to implement backup and restore for Salesforce data, Currently, it has data backup processes that runs weekly, which back up all Salesforce data to an enterprise data warehouse (EDW). NTO wants to move to daily backups and provide restore capability to avoid any data loss in case of outage.\nWhat should a data architect recommend for a daily backup and restore solution?","options":["A. Use Bulk API to extract data on daily basis to EDW and REST API for restore.","B. Use AppExchange package for backup and restore.","C. Change weekly backup process to daily backup, and implement a custom restore solution.","D. Use ETL for backup and restore from EDW."],"answer":"B","title":"Question 31","explanation":""},{"content":"Northern Trail outfitters in migrating to salesforce from a legacy CRM system that identifies the agent relationships in a look-up table.\nWhat should the data architect do in order to migrate the data to Salesfoce?","options":["A. Migrate the data and assign to a non-person system user.","B. Assign record owner based on relationship.","C. Migrate to Salesforce without a record owner.","D. Create custom objects to store agent relationships."],"answer":"D","title":"Question 32","explanation":""},{"content":"DreamHouse Realty has a Salesforce org that is used to manage Contacts.\nWhat are two things an Architect should consider using to maintain data quality in this situation? (Choose two.)","options":["A. Use Salesforce duplicate management.","B. Use the private sharing model.","C. Use workflow to delete duplicate records.","D. Use validation rules on new record create and edit."],"answer":"A,D","title":"Question 33","explanation":""},{"content":"Universal Containers uses Salesforce to track its sales opportunities The Sales VP would like to better understand key relevant performance figures and help the Sales Managers take corrective actions where appropriate. What reporting option should be considered?","options":["A. Sales KPI Dashboard","B. Opportunity analytic snapshot","C. Lead conversion rate report","D. Case SLA performance report"],"answer":"A","title":"Question 34","explanation":""},{"content":"Which three options can prevent your SOQL queries from being selective?","options":["A. Performing large loads and deletions.","B. Using trailing % wildcards.","C. Using leading % wildcards.","D. Using a custom index on a deterministic formula field.","E. Using NOT and != operators."],"answer":"C,D,E","title":"Question 35","explanation":""},{"content":"DreamHouse Realty has a data model as shown in the image. The Project object has a private sharing model, and it has Roll-Up summary fields to calculate the number of resources assigned to the project, total hours for the project, and the number of work items associated to the project.\nThere will be a large amount of time entry records to be loaded regularly from an external system into Salesforce.","options":["A. Calculate summary values instead of Roll-Up by using workflow.","B. Load all data after deferring sharing calculations.","C. Calculate summary values instead of Roll-Up by using triggers.","D. Load all data using external IDs to link to parent records."],"answer":"B","title":"Question 36","explanation":""},{"content":"A large retail company has recently chosen Salesforce as its CRM solution. They have the following record counts:\n* 2,500,000 Accounts\n* 25,000,000 Contacts\nWhen doing an initial performance test, the data architect noticed an extremely slow response for reports and list views.\nWhat should a data architect do to solve the performance issues?","options":["A. Load only data that the user is permitted to access","B. Add Custom Indexes on frequently searched Account and Contact objects fields","C. Create a Skinny Table to represent Account and Contact objects","D. Limit data loading to the 2,000 most recently created records"],"answer":"D","title":"Question 37","explanation":""},{"content":"Northern trail Outfitters (NTO) uses Sales Cloud and service Cloud to manage sales and support processes.\nSome of NTOs team are complaining they see new fields on their page unsure of which values need be input.\nNTO is concerned about lack of governance in making changes to Salesforce.\nWhich governance measure should a data architect recommend to solve this issue?","options":["A. Create validation rules with error messages to explain why the fields is used","B. Add description fields to explain why the field is used, and mark the field as required.","C. Create reports to identify which users are leaving blank, and use external data sources o agreement the missing data.","D. Create and manage a data dictionary and ups a governance process for changes made to common objects."],"answer":"D","title":"Question 38","explanation":""},{"content":"Universal Containers (UC) has three systems: Salesforce, a cloud -based ERP system, and an on -premise Order Management System (OMS). An architect has been tasked with creating a solution that uses Salesforce as the system of record for Leads and the OMS as the system of record for Account and Contacts. UC wants Accounts and Contacts to be able to maintain their names in each system (i.e., \"John Doe\" in the OMS and \"Johnny Doe\" in Salesforce), but wants to have a consolidated data store which links referenced records across the systems. What approach should an architect suggest so the requirements are met?","options":["A. Have Salesforce poll the OMS nightly and bring in the desired Accounts and Contacts.","B. Implement a Master Data Management strategy to reconcile Leads, Accounts, and Contacts.","C. Implement an integration tool to send OMS Accounts and Contacts to Salesforce.","D. Use the Streaming API to send Account and Contact data from Salesforce to the OMS."],"answer":"B","title":"Question 39","explanation":""},{"content":"DreamHouse Realty uses Custom Metadata Types instead of Custom setting.\nWhat is an advantage of this decision?","options":["A. Custom metadata records are editable in Apex.","B. Report definitions can include references to Custom Metadata Types.","C. Custom metadata records are NOT copied from production to sandbox.","D. Packages can be used to deploy Custom metadata records."],"answer":"D","title":"Question 40","explanation":""},{"content":"UC has the following system:\n* Billing system.\n* Customer support system.\n* CRM system.\nUS has been having trouble with business intelligence across the different systems.\nRecently US implemented a master data management (MDM) solution that will be the system of truth for the customer records.\nWhich MDM data element is needed to allow reporting across these systems?","options":["A. Phone number.","B. Full name.","C. Global unique customer number.","D. Email address."],"answer":"C","title":"Question 41","explanation":""},{"content":"UC recently migrated 1 Billion customer related records from a legacy data store to Heroku Postgres. A subset of the data need to be synchronized with salesforce so that service agents are able to support customers directly within the service console. The remaining non- synchronized set of data will need to be accessed by salesforce at any point in time, but UC management is concerned about storage limitations.\nWhat should a data architect recommend to meet these requirements with minimal effort?","options":["A. Virtualize the remaining set of data with salesforce connect and external objects.","B. As needed, make call outs into Heroku postgres and persist the data in salesforce.","C. Migrate the data to big objects and leverage async SOQL with custom objects.","D. Use Heroku connect to bi-directional, sync all data between systems."],"answer":"A","title":"Question 42","explanation":""},{"content":"Northern Trail Outfitter has implemented Salesforce for its associates nationwide, Senior management is concerned that the executive dashboard are not reliable for their real-time decision-making. On analysis , the team the following issues with data entered in Salesforce.\nInformation in certain records is incomplete.\nIncorrect entry in certain fields causes records to be excluded in report fitters.\nDuplicate entries cause incorrect counts.\nWhich three steps should a data architect recommend to address the issues?","options":["A. Explore third-party data providers to enrich and augment information entered in salesforce.","B. Leverage Salesforce features, such as validate rules, to avoid incomplete and incorrect records.","C. design and implement data-quality dashboard to monitor and act on records that are incomplete or incorrect","D. Periodically export data to cleanse data and import them back into Salesforce for executive reports.","E. Build a sales data warehouse with purpose-build data marts for dashboards and senior management reporting."],"answer":"A,B,E","title":"Question 43","explanation":""},{"content":"Universal Containers has a public website with several forms that create Lead records in Salesforce using the REST API. When designing these forms, which two techniques will help maintain a high level of data quality?","options":["A. Prefer picklist form fields over free text fields, where possible.","B. Do client-side validation of phone number and email field formats.","C. Ensure the website visitor is browsing using an HTTPS connection.","D. Use cookies to track when visitors submit multiple forms."],"answer":"A,B","title":"Question 44","explanation":""},{"content":"","options":[],"answer":"","title":"Question ","explanation":""},{"content":"Universal Containers (UC) wants to store product data in Salesforce, but the standard Product object does not support the more complex hierarchical structure which is currently being used in the product master system. How can UC modify the standard Product object model to support a hierarchical data structure in order to synchronize product data from the source system to Salesforce?","options":["A. Create a custom master-detail field on the standard Product to reference the child record in the hierarchy.","B. Create an Apex trigger to synchronize the Product Family standard picklist field on the Product object.","C. Create a custom lookup field on the standard Product to reference the parent record in the hierarchy.","D. Create a custom lookup filed on the standard Product to reference the child record in the hierarchy."],"answer":"C","title":"Question 46","explanation":""},{"content":"For a production cutover, a large number of Account records will be loaded into Salesforce from a legacy system. The legacy system does not have enough information to determine the Ownership for these Accounts upon initial load. Which two recommended options assign Account ownership to mitigate potential performance problems?","options":["A. Let a \"system user\" own the Account records and assign this user to the lowest-level role in the Role Hierarchy.","B. Let the VP of the Sales department, who will report directly to the senior VP, own all the Account records.","C. Let a \"system user\" own all the Account records without assigning any role to this user in Role Hierarchy.","D. Let a \"system user\" own all the Account records and make this user part of the highest- level role in the Role Hierarchy."],"answer":"A,C","title":"Question 47","explanation":""},{"content":"UC has a requirement to migrate 100 million order records from a legacy ERP application into the salesforce platform. UC does not have any requirements around reporting on the migrated data.\nWhat should a data architect recommend to reduce the performance degradation of the platform?","options":["A. Use the standard \"Order\" object to store the data.","B. Implement a custom big object to store the data.","C. Create a custom object to store the data.","D. Use a standard big object defined by salesforce."],"answer":"B","title":"Question 48","explanation":""},{"content":"What is an advantage of using Custom metadata type over Custom setting?","options":["A. Custom metadata records are deployable using packages.","B. Custom metadata records are editable in Apex.","C. Custom metadata types are available for reporting.","D. Custom metadata records are not copied from production to sandbox."],"answer":"A","title":"Question 49","explanation":""},{"content":"Salesforce is being deployed in Ursa Major Solar's disparate, multi-system ERP environment. Ursa major Solar wants to maintain data synchronization between systems.\nWhich two techniques should be used to achieve this goal? (Choose two.)","options":["A. Utilize workbench to update files within systems.","B. Integrate Salesforce with the ERP environment.","C. Utilize an MDM strategy to outline a single source of truth.","D. Build synchronization reports and dashboards."],"answer":"B,C","title":"Question 50","explanation":""},{"content":"Ursa Major Solar has the following two systems:\n- Salesforce\n- On-premise ERP system\nOpportunity records need to be copied to the ERP once they reach a Closed/Won Stage. The Opportunity record in the ERP system will be read-only for all fields copied in from Salesforce.\nAn Architect needs to recommend a real-time approach that fulfills these requirements.\nWhich recommendation is appropriate?","options":["A. Have an ERP poll Salesforce nightly and bring in the desired Opportunities.","B. Create a workflow rule with Outbound Messaging that sends Opportunity data.","C. Implement a Master Data Management system to determine system of record.","D. Implement an hourly integration to send Salesforce Opportunities to the ERP system."],"answer":"B","title":"Question 51","explanation":""},{"content":"UC has to built a B2C ecommerce site on Heroku that shares customer and order data with a Heroku Postgres database. UC is currently utilizing Postgres as the single source of truth for both customers and orders. UC has asked a data architect to replicate the data into salesforce so that salesforce can now act as the system of record.\nWhat are the 3 considerations that data architect should weigh before implementing this requirement? Choose\n23 answers:","options":["A. Determine if the data is driver of key process implemented within salesforce.","B. - Heroku Connect is required but this is confusing","C. Ensure the data is CRM center and able to populate standard of custom objects.","D. Consider whether the data is required for sales reports, dashboards and KPI's.","E. Ensure there is a tight relationship between order data and an enterprise resource plaining (ERP) application.","F. A selection of the tool required to replicate the data."],"answer":"A,C","title":"Question 52","explanation":""},{"content":"UC has been using SF for 10 years. Lately, users have noticed, that the pages load slowly when viewing Customer and Account list view.\nTo mitigate, UC will implement a data archive strategy to reduce the amount of data actively loaded.\nWhich 2 tasks are required to define the strategy? Choose 2 answers:","options":["A. Identify how the archive data will be accessed and used.","B. Identify the recovery time objective.","C. Identify the recovery point objective.","D. Identify the data retention requirements"],"answer":"A,D","title":"Question 53","explanation":""},{"content":"DreamHouse Realty uses Custom Metadata Types instead of Custom setting.\nWhat is an advantage of this decision?","options":["A. Custom metadata records are editable in Apex.","B. Report definitions can include references to Custom Metadata Types.","C. Custom metadata records are NOT copied from production to sandbox.","D. Packages can be used to deploy Custom metadata records."],"answer":"D","title":"Question 54","explanation":"Explanation/Reference:"},{"content":"DreamHouse Realty has a Salesforce org that is used to manage Contacts.\nWhat are two things an Architect should consider using to maintain data quality in this situation? (Choose two.)","options":["A. Use workflow to delete duplicate records.","B. Utilize the private sharing model.","C. Utilize Salesforce duplicate management.","D. Use validation rules on new record create and edit."],"answer":"C,D","title":"Question 55","explanation":""},{"content":"Universal Containers (UC) has a multi-level master-detail relationship for opportunities, a custom opportunity line item object, and a custom discount request. UC has opportunity as master and custom line item object as detail in master-detail relationship. UC also has a custom line item object as master and a custom discount request object as detail in another master-detail relationship. UC has a requirement to show all sums of discounts across line items at an opportunity level. What is the recommended solution to address these requirements?","options":["A. Update the master-detail relationships to lookup relationships in order to allow the discount amount to roll up.","B. Roll-up discount request amount at the line-item-level and line-item-level summary discount at the opportunity level.","C. Use roll-up for the line-item-level summary and a trigger for the opportunity amount summary, as only one level roll-up is allowed.","D. Remove the master-detail relationships and rely completely on workflow/triggers to summarize the discount amount."],"answer":"B","title":"Question 56","explanation":""},{"content":"NTO has outgrown its current salesforce org and will be migrating to new org shortly. As part of this process NTO will be migrating all of its metadata and dat a. NTO's data model in the source org has a complex relationship hierarchy with several master detail and lookup relationships across objects, which should be maintained in target org.\nWhat 3 things should a data architect do to maintain the relationship hierarchy during migration?\nChoose 3 answers:","options":["A. Use data loader to export the data from source org and then import or Upsert into the target org in sequential order.","B. Keep the relationship fields populated with the source record ID's in the import file.","C. Replace source record ID's with new record ID's from the target org in the import file.","D. Redefine the master detail relationship fields to lookup relationship fields in the target org.","E. Create a external id field for each object in the target org and map source record ID's to this field."],"answer":"A,C,E","title":"Question 57","explanation":""},{"content":"Universal Containers (UC) has multi -level account hierarchies that represent departments within their major Accounts. Users are creating duplicate Contacts across multiple departments. UC wants to clean the data so as to have a single Contact across departments. What two solutions should UC implement to cleanse their data? Choose 2 answers","options":["A. Use Data.com to standardize Contact address information to help identify duplicates.","B. Make use of the Merge Contacts feature of Salesforce to merge duplicates for an Account.","C. Use Workflow rules to standardize Contact information to identify and prevent duplicates.","D. Make use of a third -party tool to help merge duplicate Contacts across Accounts."],"answer":"A,D","title":"Question 58","explanation":""},{"content":"Universal Containers (UC) has a custom discount request object set as a detail object with a custom product object as the master. There is a requirement to allow the creation of generic discount requests without the custom product object as its master record. What solution should an Architect recommend to UC?","options":["A. Remove the master-detail relationship and keep the objects separate.","B. Create a placeholder product record for the generic discount request.","C. Change the master-detail relationship to a lookup relationship.","D. Mandate the selection of a custom product for each discount request."],"answer":"C","title":"Question 59","explanation":""},{"content":"Universal Containers (UC) is launching an RFP to acquire a new accounting product available on AppExchange. UC is expecting to issue 5 million invoices per year, with each invoice containing an average of 10 line items. What should UC's Data Architect recommend to ensure scalability?","options":["A. Ensure invoice line items simply reference existing Opportunity line items.","B. Ensure the account product vendor provides a sound data archiving strategy.","C. Ensure the accounting product runs 100% natively on the Salesforce platform.","D. Ensure the account product vendor includes Wave Analytics in their offering."],"answer":"B","title":"Question 60","explanation":""},{"content":"Which two automated approaches should an architect recommend to purge old data out of Salesforce and aggregate that data in Salesforce? Choose 2 answers","options":["A. Third -party Business Intelligence system","B. Apex Triggers","C. Third -party Integration Tool (ETL)","D. Schedulable Batch Apex"],"answer":"C,D","title":"Question 61","explanation":""},{"content":"Cloud Kicks has the following requirements:\n- Data needs to be sent from Salesforce to an external system to generate invoices from their Order Management System (OMS).\n- A Salesforce administrator must be able to customize which fields will be sent to the external system without changing code.\nWhat are two approaches for fulfilling these requirements? (Choose two.)","options":["A. Turn on the field-level security permissions for the fields to send.","B. An ObjectField to determine which fields to send in an HTTP callout.","C. An Outbound Message to determine which fields to send to the OMS.","D. A Field Set that determines which fields to send in an HTTP callout."],"answer":"C,D","title":"Question 62","explanation":""},{"content":"Universal Containers has defined a new Data Quality Plan for their Salesforce data and wants to know how they can enforce it throughout the organization. Which two approaches should an architect recommend to enforce this new plan?\nChoose 2 answers","options":["A. Use Workflow, Validation Rules, and Force.com code (Apex) to enforce critical business processes.","B. Store all data in an external system and set up an integration to Salesforce for view - only access.","C. Schedule a weekly dashboard displaying records that are missing information to be sent to managers for review.","D. Schedule reports that will automatically catch duplicates and merge or delete the records every week."],"answer":"A,C","title":"Question 63","explanation":""},{"content":"Universal Container (UC) is migrating data from legacy system to Salesforce. UC would like to preserve the following information on records being migrated:\n1. Date time stamps for created date and last modified date.\n2. Ownership of records belonging to inactive users being migrated to Salesforce.\nWhich two solutions should a data architect recommend to preserve date timestamps and ownership on records? (Choose two.)","options":["A. Enable Update Records with Inactive Owners Permission","B. Enable modify all and view all permission","C. Enable Set Audit Fields upon Record Creation Permission","D. Log a case with Salesforce to allow updating these fields"],"answer":"A,C","title":"Question 64","explanation":"Explanation/Reference:"},{"content":"Universal Container (UC) has accumulated data over years and has never deleted data from its Salesforce org.\nUC is now exceeding the storage allocations in the org. UC is now looking for option to delete unused from the org.\nWhich three recommendations should a data architect make is order to reduce the number of records from the org?\nChoose 3 answers","options":["A. Archive the records in enterprise data warehouse (EDW) before deleting from Salesforce.","B. Use Rest API to permanently delete records from the Salesforce org.","C. Identify records in objects that have not been modified or used In last 3 years.","D. Use hard delete in Bulk API to permanently delete records from Salesforce.","E. Use hard delete in batch Apex to permanently delete records from Salesforce."],"answer":"A,C,D","title":"Question 65","explanation":""},{"content":"A health care provider wishes to use salesforce to track patient care. The following actions are in Salesforce\n1. Payment Providers: Orgas who pay for the care 2 patients.\n2. Doctors: They provide care plan for patients and need to support multiple patients, they are provided access to patient information.\n3. Patients: They are individuals who need care.\nA data architect needs to map the actor to Sf objects. What should be the optimal selection by the data architect?","options":["A. Patients as Person Accounts, Payment providers as Accounts, & Doctors as Contacts","B. Patients as Contacts, Payment providers as Accounts, & Doctors as Accounts","C. Patients as Person Accounts, Payment providers as Accounts, & Doctors as Person Account","D. Patients as Accounts, Payment providers as Accounts, & Doctors as Person Accounts"],"answer":"C","title":"Question 66","explanation":""},{"content":"Universal Containers (UC) is implementing a formal, cross -business -unit data governance program As part of the program, UC will implement a team to make decisions on enterprise\n-wide data governance. Which two roles are appropriate as members of this team? Choose\n2 answers","options":["A. Data Domain Stewards","B. Analytics/BI Owners","C. Salesforce Administrators","D. Operational Data Users"],"answer":"A,B","title":"Question 67","explanation":""},{"content":"What should a data architect do to provide additional guidance for users when they enter information in a standard field?","options":["A. Create a custom page with help text for user guidance.","B. Add custom help text in default value for the field.","C. Add a label field with help text adjacent to the custom field.","D. Provide custom help text under field properties."],"answer":"D","title":"Question 68","explanation":""},{"content":"Universal Containers (UC) is implementing Salesforce Sales Cloud and Service Cloud. As part of their implementation, they are planning to create a new custom object (Shipments), which will have a lookup relationship to Opportunities. When creating shipment records, Salesforce users need to manually input a customer reference, which is provided by customers, and will be stored in the Customer_Reference__c text custom field. Support agents will likely use this customer reference to search for Shipment records when resolving shipping issues. UC is expecting to have around 5 million shipment records created per year. What is the recommended solution to ensure that support agents using global search and reports can quickly find shipment records?","options":["A. Set Customer-Reference_c as an External ID (unique).","B. Implement an archiving process for shipment records created after five years.","C. Set Customer-Reference_c as an External ID (non-unique).","D. Implement an archiving process for shipment records created after three years."],"answer":"A","title":"Question 69","explanation":""},{"content":"During the implementation of Salesforce, a customer has the following requirements for Sales Orders:\n1. Sales Order information needs to be shown to users in Salesforce.\n2. Sales Orders are maintained in the on-premises enterprise resource planning (ERP).\n3. Sales Order information has more than 150 million records.\n4. Sales Orders will not be updated in Salesforce.\nWhat should a data architect recommend for maintaining Sales Orders in salesforce?","options":["A. Use Standard order object to maintain Sale Orders in Salesforce","B. Us custom objects to maintain Sales Orders in Salesforce.","C. Use external objects to maintain Sales Order in Salesforce.","D. Use custom big objects to maintain Sales Orders in Salesforce."],"answer":"C","title":"Question 70","explanation":""},{"content":"Northern Trail Outfitters (NTO) has the following systems:\nCustomer master-source of truth for customer information\nService cloud-customer support\nMarketing cloud-marketing support\nEnterprise data warehouse-business reporting\nThe customer data is duplicated across all these system and are not kept in sync. Customers are also complaining that they get repeated marketing emails and have to call into update their information.\nNTO is planning to implement master data management (MDM) solution across the enterprise.\nWhich three data will an MDM tool solve?\nChoose 3 answers","options":["A. Data standardization","B. Data completeness","C. Data accuracy and quality","D. Data loss and recovery","E. Data duplication"],"answer":"A,C,E","title":"Question 71","explanation":""},{"content":"A company has 12 million records, and a nightly integration queries these records.\nWhich two areas should a Data Architect investigate during troubleshooting if queries are timing out? (Choose two.)","options":["A. Make sure the query doesn't contain NULL in any filter criteria.","B. Create a formula field instead of having multiple filter criteria.","C. Create custom indexes on the fields used in the filter criteria.","D. Modify the integration users' profile to have View All Data."],"answer":"A,C","title":"Question 72","explanation":"Explanation/Reference:"},{"content":"Universal Containers (UC) is planning to move away from legacy CRM to Salesforce. As part of one-time data migration, UC will need to keep the original date when a contact was created in the legacy system. How should an Architect design the data migration solution to meet this requirement?","options":["A. Enable \"Set Audit Fields\" and assign the permission to the user loading the data for the duration of the migration.","B. After the data is migrated, perform an update on all records to set the original date in a standard CreatedDate field.","C. Create a new field on Contact object to capture the Created Date. Hide the standard CreatedDate field using Field -Level Security.","D. Write an Apex trigger on the Contact object, before insert event to set the original value in a standard CreatedDate field."],"answer":"A","title":"Question 73","explanation":""},{"content":"Universal Containers (UC) wants to assess the completeness and consistency of contact information in Salesforce. They are finding that their sales reps in many caes do not have enough information about their accounts and contacts. Also, in many cases they are not able to interpret the information in a consistent manner. They have identified certain \"key\" fields which are important to their sales reps. Which two steps can UC implement to assess their data for completeness and consistency?","options":["A. Run a report which shows the last time the key fields were updated.","B. Run one report per key field, grouped by that field, to understand its data variability.","C. Run a report that shows the percentage of blanks for the important fields.","D. Run a process that can fill in default values for blank fields."],"answer":"A,C","title":"Question 74","explanation":""},{"content":"Northern Trail Outfitters (NTO) uses Sales Cloud and Service Cloud to manage their sales and support processes. Some of NTOs teams are complaining they see new fields on their page and are unsure of which values need be input. NTO is concerned about lack of governance in making changes to Salesforce.\nWhich governance measure should a data architect recommend to solve this issue?","options":["A. Create reports to identify which fields users are leaving blank, and use external data sources to augment the missing data.","B. Create validation rules with error messages to explain why the field is used.","C. Create and manage a data dictionary, and use a governance process for changes made to common objects.","D. Add description fields to explain why the field is used, and mark the fields as Required."],"answer":"C","title":"Question 75","explanation":""},{"content":"A casino is implementing Salesforce and is planning to build a customer 360 degree view for a customer who visits its resorts. The casino currently maintains the following systems that record customer activity: L Point-of-sale system: All purchases for a customer\n2. Salesforce; All customer service activity and sales activities for a customer\n3. Mobile app: All bookings, preferences, and browser activity for a customer\n4. Marketing: All email, SMS, and social campaigns for a customer\nCustomer service agents using Salesforee would like to view the activities from all four systems to provide support to customers. The information has to be current and real time.\nWhat strategy should the data architect implement to satisfy this requirement?","options":["A. Use a customer data mart to create the 360 degree view of the customer.","B. Migrate customer activities fro, all four system into Salesforce.","C. Explore external data sources in Salesforce to build a 360 degree view of the customer.","D. Periodically upload summary information in Salesforce to build a 360 degree view."],"answer":"C","title":"Question 76","explanation":""},{"content":"NTO need to extract 50 million records from a custom object everyday from its Salesforce org. NTO is facing query timeout issues while extracting these records.\nWhat should a data architect recommend in order to get around the time out issue?","options":["A. Use ETL tool for extraction of records.","B. Use a custom auto number and formula field and use that to chunk records while extracting data.","C. The REST API to extract data as it automatically chunks records by 200.","D. Ask SF support to increase the query timeout value."],"answer":"B","title":"Question 77","explanation":""},{"content":"Universal Containers has a legacy system that captures Conferences and Venues. These Conferences can occur at any Venue. They create hundreds of thousands of Conferences per year. Historically, they have only used 20 Venues. Which two things should the data architect consider when denormalizing this data model into a single Conference object with a Venue picklist? Choose 2 answers","options":["A. Limitations on master -detail relationships.","B. Bulk API limitations on picklist fields.","C. Org data storage limitations.","D. Standard list view in -line editing."],"answer":"B,D","title":"Question 78","explanation":""},{"content":"A business that works directly with individual consumers (B2C) currently has a home-grown CRM system, but they are moving to Salesforce. The business has 1.2 million consumer records and wants assistance with achieving optimal use of Salesforce functionality while also avoiding data loading issues.\nWhat should an Architect recommend?","options":["A. Load all individual consumers as Account records and avoid using the Contact object.","B. Create a Custom object IndividualConsumer_c to load all individual consumers.","C. Load one Account record and one Contact record for each individual consumer.","D. Create one Account and load individual consumers as Contacts linked to that one Account."],"answer":"C","title":"Question 79","explanation":""},{"content":"Universal Container (US) is replacing a home grown CRM solution with Salesforce, UC has decided to migrate operational (Open and active) records to Salesforce, while keeping historical records in legacy system, UC would like historical records to be available in Salesforce on an as needed basis.\nWhich solution should a data architect recommend to meet business requirement?","options":["A. Bring all data Salesforce, and delete it after a year.","B. Leverage real-time integration to pull records into Salesforce.","C. Build a chair solution to go the legacy system and display records.","D. Leverage mashup to display historical records in Salesforce."],"answer":"D","title":"Question 80","explanation":""},{"content":"NTO (Northern Trail Outlets) has a complex Salesforce org which has been developed over past 5 years.\nInternal users are complaining abt multiple data issues, including incomplete and duplicate data in the org.\nNTO has decided to engage a data architect to analyze and define data quality standards.\nWhich 3 key factors should a data architect consider while defining data quality standards? Choose 3 answers:","options":["A. Define data duplication standards and rules","B. Define key fields in staging database for data cleansing","C. Finalize an extract transform load (ETL) tool for data migration","D. Measure data timeliness and consistency","E. Measure data completeness and accuracy"],"answer":"A,D,E","title":"Question 81","explanation":""},{"content":"UC has millions of Cases and are running out of storage. Some user groups need to have access to historical cases for up to 7 years.\nWhich 2 solutions should a data architect recommend in order to minimize performance and storage issues?\nChoose 2 answers:","options":["A. Leverage on premise data archival and build integration to view archived data.","B. Leverage big object to archive case data and lightning components to show archived data.","C. Export data out of salesforce and store in Flat files on external system.","D. Create a custom object to store case history and run reports on it."],"answer":"A,B","title":"Question 82","explanation":""},{"content":"UC has a salesforce org with multiple automated processes defined for group membership process. UC also have multiple admins on staff that perform manual adjustments to the role hierarchy. The automated task and manual task overlap daily and UC is experiencing \"Lock errors\" consistently.\nWhat should a data architect recommend mitigate these errors?","options":["A. Enable granular locking.","B. Ask salesforce support for addition CPU power.","C. Remove SOQL statements from APEX loops.","D. Enable sharing recalculations"],"answer":"C","title":"Question 83","explanation":""},{"content":"Universal Containers (UC) has deployed Salesforce to manage Marketing. Sales, and Support efforts in a multi -system ERP environment After reaching the limits of native reports & dashboards. UC leadership is looking to understand what options can be used to provide more analytical insights. What two approaches should an architect recommend?\nChoose 2 answers","options":["A. Setup Audit Trails","B. Wave Analytics","C. AppExchange Apps","D. Weekly Snapshots"],"answer":"B,C","title":"Question 84","explanation":""},{"content":"DreamHouse Realty needs an Architect to develop a solution that will integrate data and resolve duplicates and discrepancies between Salesforce and one or more external systems.\nWhat are two important questions the Architect should answer when determining whether to use Master Data Management in the solution? (Choose two.)","options":["A. How many systems are integrating with each other?","B. Will Salesforce replace a legacy system?","C. Does the system of record change for different tables?","D. Are the systems cloud-based or on-premise?"],"answer":"A,C","title":"Question 85","explanation":""},{"content":"Universal Containers (UC) wants to ensure their data on 100,000 Accounts pertaining mostly to US-based companies is enriched and cleansed on an ongoing basis. UC is looking for a solution that allows easy monitoring of key data quality metrics. What should be the recommended solution to meet this requirement?","options":["A. Implement Batch Apex that calls out a third-party data quality API in order to monitor Account data quality.","B. Use declarative approach by installing and configuring Data.com Prospector to monitor Account data quality.","C. Use a declarative approach by installing and configuring Data.com Clean to monitor Account data quality.","D. Implement an Apex Trigger on Account that queries a third-party data quality API to monitor Account data quality."],"answer":"C","title":"Question 86","explanation":""},{"content":"NTO uses salesforce to manage relationships and track sales opportunities. It has 10 million customers and 100 million opportunities. The CEO has been complaining 10 minutes to run and sometimes failed to load, throwing a time out error.\nWhich 3 options should help improve the dashboard performance?\nChoose 3 answers:","options":["A. Run the dashboard for CEO and send it via email.","B. De-normalize the data by reducing the number of joins.","C. Remove widgets from the dashboard to reduce the number of graphics loaded.","D. Use selective queries to reduce the amount of data being returned.","E. Reduce the amount of data queried by archiving unused opportunity records."],"answer":"B,D,E","title":"Question 87","explanation":""},{"content":"UC has one SF org (Org A) and recently acquired a secondary company with its own Salesforce org (Org B). UC has decided to keep the orgs running separately but would like to bidirectionally share opportunities between the orgs in near-real time.\nWhich 3 options should a data architect recommend to share data between Org A and Org B?\nChoose 3 answers.","options":["A. Develop an Apex class that pushes opportunity data between orgs daily via the Apex schedule.","B. Leverage Heroku Connect and Heroku Postgres to bidirectionally sync Opportunities.","C. Leverage middleware tools to bidirectionally send Opportunity data across orgs.","D. Install a 3rd party AppExchange tool to handle the data sharing","E. Use Salesforce Connect and the cross-org adapter to visualize Opportunities into external objects"],"answer":"A,C,E","title":"Question 88","explanation":""},{"content":"A large retail company has recently chosen SF as its CRM solution. They have the following record counts:\n2500000 accounts\n25000000 contacts\nWhen doing an initial performance test, the data architect noticed an extremely slow response for reports and list views.\nWhat should a data architect do to solve the performance issue?","options":["A. Limit data loading to the 2000 most recently created records.","B. Load only the data that the users is permitted to access","C. Create a skinny table to represent account and contact objects.","D. Add custom indexes on frequently searched account and contact objects fields"],"answer":"C","title":"Question 89","explanation":""},{"content":"Universal Containers (UC) maintains a collection of several million Account records that represent business in the United Sates. As a logistics company, this list is one of the most valuable and important components of UC's business, and the accuracy of shipping addresses is paramount. Recently it has been noticed that too many of the addresses of these businesses are inaccurate, or the businesses don't exist. Which two scalable strategies should UC consider to improve the quality of their Account addresses?","options":["A. Integrate with a third-party database or services for address validation and enrichment.","B. Build a team of employees that validate Accounts by searching the web and making phone calls.","C. Leverage Data.com Clean to clean up Account address fields with the D&B database.","D. Contact each business on the list and ask them to review and update their address information."],"answer":"A,C","title":"Question 90","explanation":""},{"content":"Universal Containers (UC) is implementing Salesforce and will be using Salesforce to track customer complaints, provide white papers on products, and provide subscription (fee)-based support.\nWhich license type will UC users need to fulfill UC's requirements?","options":["A. Salesforce License","B. Lightning Platform Starter License","C. Service Cloud License","D. Sales Cloud License"],"answer":"C","title":"Question 91","explanation":"Explanation/Reference: https://www.salesforce.com/products/service-cloud/pricing/"},{"content":"Universal Containers has received complaints that customers are being called by multiple Sales Reps where the second Sales Rep that calls is unaware of the previous call by their coworker. What is a data quality problem that could cause this?","options":["A. Duplicate Contact records exist in the system.","B. Missing phone number on the Contact record.","C. Duplicate Activity records on a Contact.","D. Customer phone number has changed on the Contact record."],"answer":"A","title":"Question 92","explanation":""},{"content":"Universal Containers (UC) has 1,000 accounts and 50,000 opportunities. UC has an enterprise security requirement to export all sales data outside of Salesforce on a weekly basis. The security requirement also calls for exporting key operational data that includes events such as file downloads, logins, logouts, etc. Which two recommended approaches would address the above requirement?","options":["A. Use Weekly Export to extract transactional data to on-premise systems.","B. Use Event Monitoring to extract event data to on-premise systems.","C. Use a custom built extract job to extract operational data to on-premise systems.","D. Use Field Audit History to capture operational data and extract it to on-premise systems."],"answer":"C","title":"Question 93","explanation":""},{"content":"DreamHouse Realty has a data model as shown in the image. The Project object has a private sharing model, and it has Roll-Up summary fields to calculate the number of resources assigned to the project, total hours for the project, and the number of work items associated to the project.\nThere will be a large amount of time entry records to be loaded regularly from an external system into Salesforce.\nWhat should the Architect consider in this situation?","options":["A. Load all data after deferring sharing calculations.","B. Calculate summary values instead of Roll-Up by using workflow.","C. Calculate summary values instead of Roll-Up by using triggers.","D. Load all data using external IDs to link to parent records."],"answer":"A","title":"Question 94","explanation":"Explanation"},{"content":"Universal Containers wishes to send data from Salesforce to an external system to generate invoices from their Order Management System (OMS). They want a Salesforce administrator to be able to customize which fields be sent to the external system without modifying code. What two approaches should an architect recommend to deliver the desired solution? Choose 2 answers","options":["A. An Outbound Message to determine which fields to send to the OMS.","B. A set<sobjectFieldset> to determine which fields to send in an HTTP callout.","C. Enable the field -level security permissions for the fields to send.","D. A Field Set that determines which fields to send in an HTTP callout."],"answer":"A,D","title":"Question 95","explanation":""},{"content":"UC has millions of case records with case history and SLA dat\na. UC's compliance team would like historical cases to be accessible for 10 years for Audit purpose.\nWhat solution should a data architect recommend?","options":["A. Use a custom Big object to store archived case data.","B. Purchase more data storage to support case object","C. Archive Case data using Salesforce Archiving process","D. Use a custom object to store archived case data."],"answer":"A","title":"Question 96","explanation":""},{"content":"During the implementation of Salesforce a customer has the following requirements for Sales Order:\n1. Sales Order information needs to be shown to users in Salesforce.\n2. Sales Orders are maintained in the on-premise enterprise resource planning (ERP).\n3. Sales Order information has more than 150 million records.\n4. Sales Orders will not be updated in Salesforce.\nWhat should a data architect recommend for maintaining Sales Orders in Salesforce?","options":["A. Use external objects to maintain Sales Orders in Salesforce.","B. Use custom big objects to maintain Sales Orders in Salesforce.","C. Use Standard Order object to maintain Sales Orders in Salesforce.","D. Use custom objects to maintain Sales Orders in Salesforce."],"answer":"A","title":"Question 97","explanation":"Order object with external systems to maintain a real-time order system and increase the productivity of your organization.\n Reference:\n https://www.mstsolutions.com/technical/standard-order-object-in-salesforce/"},{"content":"DreamHouse Realty has a data model as shown in the image. The Project object has a private sharing model, and it has Roll-Up summary fields to calculate the number of resources assigned to the project, total hours for the project, and the number of work items associated to the project.\nThere will be a large amount of time entry records to be loaded regularly from an external system into Salesforce.","options":["A. Calculate summary values instead of Roll-Up by using triggers.","B. Load all data after deferring sharing calculations.","C. Load all data using external IDs to link to parent records.","D. Calculate summary values instead of Roll-Up by using workflow."],"answer":"B","title":"Question 98","explanation":""},{"content":"Universal Containers (UC) has over 10 million accounts with an average of 20 opportunities with each account. A Sales Executive at UC needs to generate a daily report for all opportunities in a specific opportunity stage.\nWhich two key considerations should be made to make sure the performance of the report is not degraded due to large data volume?","options":["A. Number of records returned by report query.","B. Number of characters in report query.","C. Number of queries running at a time.","D. Number of joins used in report query."],"answer":"A,D","title":"Question 99","explanation":""},{"content":"Universal Containers has a rollup summary field on account to calculate the count of contacts associated with an account. During the account load, Salesforce is throwing an \"Unable to lock a row\" error.\nWhich solution should a data architect recommend to resolve the error?","options":["A. Perform batch job in parallel mode, and reduce batch size","B. Defer rollup summary fields calculation during data migration","C. Leverage data loader platform API to load data","D. Perform batch job in serial mode, and reduce batch size"],"answer":"D","title":"Question 100","explanation":"Explanation/Reference: https://salesforce.stackexchange.com/questions/181798/roll-up-summary-implications-and-behind- the-scenes-calculations"},{"content":"Cloud Kicks has a system environment that is complex, and they plan on creating a data governance program for the first time.\nWhat are two initial actions Cloud Kicks should take to initiate an assessment of data architecture? (Choose two.)","options":["A. Work with business units and IT to assess current operational systems and data models.","B. Work with database administrators to assess current database performance metrics.","C. Work with IT program managers to assess current velocity of projects in the pipeline.","D. Work with executive sponsorship to assess enterprise data strategy and goals."],"answer":"A,D","title":"Question 101","explanation":""},{"content":"Universal Containers (UC) is migrating from an on-premise homegrown customer relationship management (CRM) system- During analysis, UC users highlight a pain point that there are multiple versions of many customers.\nWhat should the data architect do for a successful migration to mitigate the pain point?","options":["A. Store the data in a staging database, and de-duplicate identical records.","B. Migrate the data as is, and use Salesforce's de-duplicating feature.","C. Hire an intern manually de-duplicate the records after migrating to Salesforce.","D. Have the users manually clean the data in the old system prior to migration."],"answer":"A","title":"Question 102","explanation":""},{"content":"Universal Containers (UC) is in the process of selling half of its company. As part of this split, UC's main Salesforce org will be divided into two orgs: Org A and Org\nB. UC has delivered these requirements to its data architect:\n1. The data model for Org B will drastically change with different objects, fields, and picklist values.\n2. Three million records will need to be migrated from Org A to Org B for compliance reasons.\n3. The migration will need occur within the next two months, prior to the spilt.\nWhich migration strategy should a data architect use to successfully migrate the data?","options":["A. Use an ETL tool to orchestrate the migration.","B. Write a script to use the Bulk API.","C. Use Data Loader for export and Data Import Wizard for import.","D. Use the Salesforce CLI to query, export, and import."],"answer":"D","title":"Question 103","explanation":""},{"content":"Ursa Major Solar plans to use Salesforce to manage their sales organization. However, the company has legacy account data from two aging systems that must be migrated into Salesforce. The Chief Technology Officer (CTO) at Ursa Major Solar is concerned about data duplication and needs it minimized.\nWhat are two design considerations an Architect should take in this scenario? (Choose two.)","options":["A. Before importing into Salesforce, clean the data.","B. Check and prevent duplicates by using a workflow.","C. Import the data concurrently.","D. Use Salesforce matching and duplicate rules."],"answer":"A,D","title":"Question 104","explanation":""},{"content":"Universal Container has a Sales Cloud implementation for a sales team and an enterprise resource planning (ERP) as a customer master Sales team are complaining about duplicate account and data quality issues with account data.\nWhich two solution should a data architect recommend to resolve the complaints?","options":["A. Integrate Salesforce with ERP, and make ERP as system of truth.","B. Implement a de-dupe solution and establish account ownership in Salesforce","C. Build a nightly sync job from ERP to Salesforce.","D. Build a nightly batch job to de-dupe data, and merge account records."],"answer":"A,B","title":"Question 105","explanation":""},{"content":"Universal Containers is exporting 40 million Account records from Salesforce using Informatica Cloud. The ETL tool fails and the query log indicates a full table scan time-out failure. What is the recommended solution?","options":["A. Modify the export query that includes standard index fields(s).","B. Modify the export job header to specify Sforce-Enable-PKChunking.","C. Modify the export job header to specify Export-in-Parallel.","D. Modify the export query with LIMIT clause with Batch size 10,000."],"answer":"B","title":"Question 106","explanation":""},{"content":"UC is migrating data from legacy system to SF. UC would like to preserve the following information on records being migrated:\nDate time stamps for created date and last modified date.\nOwnership of records belonging to inactive users being migrated to Salesforce.\nWhich 2 solutions should a data architect recommends to preserve the date timestamps and ownership on records? Choose 2 answers.","options":["A. Enable modify all and view all permission.","B. Enable update records with Inactive Owners Permission","C. Log a case with SF to update these fields","D. Enable Set Audit fields upon Record Creation Permission"],"answer":"B,D","title":"Question 107","explanation":""},{"content":"Universal Containers (UC) has over 10 million records. They have a nightly integration that queries these records The queries are timing out What should the data architect do or look for when troubleshooting the queries?\nChoose 2 answers","options":["A. Create custom indexes on the fields used in the filter criteria.","B. Ensure the query doesn't contain NULL in any filter criteria.","C. Change the integration users' profile to have View All Data.","D. Create a formula field instead of having multiple filter criteria."],"answer":"B,C","title":"Question 108","explanation":""},{"content":"Universal Containers (UC) has a Salesforce org with multiple automated processes defined for group membership processing, UC also has multiple admins on staff that perform manual adjustments to the role hierarchy. The automated tasks and manual tasks overlap daily, and UC is experiencing \"lock errors\" consistently.\nWhat should a data architect recommend to mitigate these errors?","options":["A. Ask Salesforce support for additional CPU power.","B. Enable sharing recalculations.","C. Remove SOQL statements from Apex Loops.","D. Enable granular locking."],"answer":"C","title":"Question 109","explanation":""},{"content":"Universal Containers is setting up an external Business Intelligence (BI) system and wants to extract 1,000,000 Contact records. What should be recommended to avoid timeouts during the export process?","options":["A. Use the SOAP API to export data.","B. Schedule a Batch Apex job to export the data.","C. Use GZIP compression to export the data.","D. Utilize the Bulk API to export the data."],"answer":"C","title":"Question 110","explanation":""},{"content":"A data architect has been tasked with optimizing a data stewardship engagement for a Salesforce instance Which three areas of Salesforce should the architect review before proposing any design recommendation?\nChoose 3 answers","options":["A. Review the sharing model to determine impact on duplicate records.","B. Determine if any integration points create records in Salesforce.","C. Export the setup audit trail to review what fields are being used.","D. Run key reports to determine what fields should be required.","E. Review the metadata xml files for redundant fields to consolidate."],"answer":"A,D,E","title":"Question 111","explanation":""},{"content":"Cloud Kicks has the following requirements:\n- Data needs to be sent from Salesforce to an external system to generate invoices from their Order Management System (OMS).\n- A Salesforce administrator must be able to customize which fields will be sent to the external system without changing code.\nWhat are two approaches for fulfilling these requirements? (Choose two.)","options":["A. A Field Set that determines which fields to send in an HTTP callout.","B. A set<sobjectFieldset> to determine which fields to send in an HTTP callout.","C. An Outbound Message to determine which fields to send to the OMS.","D. Enable the field -level security permissions for the fields to send."],"answer":"A,C","title":"Question 112","explanation":""}]