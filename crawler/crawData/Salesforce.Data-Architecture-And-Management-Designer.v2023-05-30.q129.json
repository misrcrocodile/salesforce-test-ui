[{"content":"Universal Container is using Salesforce for Opportunity management and enterprise resource planning (ERP) for order management. Sales reps do not have access to the ERP and have no visibility into order status.\nWhat solution a data architect recommend to give the sales team visibility into order status?","options":["A. Build real-time integration to pull order line items into Salesforce when viewing orders.","B. leverage Salesforce Connect top bring the order line item from the legacy system to Salesforce.","C. Build batch jobs to push order line items to salesforce.","D. Leverage Canvas to bring the order management UI in to the Salesforce tab."],"answer":"B","title":"Question 1","explanation":""},{"content":"What is an advantage of using Custom metadata type over Custom setting?","options":["A. Custom metadata records are editable in Apex.","B. Custom metadata records are deployable using packages.","C. Custom metadata types are available for reporting.","D. Custom metadata records are not copied from production to sandbox."],"answer":"B","title":"Question 2","explanation":""},{"content":"US is implementing salesforce and will be using salesforce to track customer complaints, provide white papers on products and provide subscription (Fee) - based support.\nWhich license type will US users need to fulfil US's requirements?","options":["A. Sales cloud license","B. Salesforce license.","C. Lightning platform starter license.","D. Service cloud license."],"answer":"D","title":"Question 3","explanation":""},{"content":"UC is trying to switch from legacy CRM to salesforce and wants to keep legacy CRM and salesforce in place till all the functionality is deployed in salesforce. The want to keep data in synch b/w Salesforce, legacy CRM and SAP. What is the recommendation.","options":["A. Integrate SAP with Salesforce, SAP to legacy CRM but not legacy CRM to Salesforce","B. Suggest MDM solution and link MDM to salesforce and SAP","C. Integrate legacy CRM to salesforce and keep data in synch till new functionality is in place","D. Do not integrate legacy CRM to Salesforce, but integrate salesforce to SAP"],"answer":"A,B","title":"Question 4","explanation":""},{"content":"Universal Containers is planning out their archiving and purging plans going forward for their custom objects Topic__c and Comment__c. Several options are being considered, including analytics snapshots, offsite storage, scheduled purges, etc. Which three questions should be considered when designing an appropriate archiving strategy?","options":["A. If reporting is necessary, can the information be aggregated into fewer, summary records?","B. Are there any regulatory restrictions that will influence the archiving and purging plans?","C. How many fields are defined on the custom objects that need to be archived?","D. Which profiles and users currently have access to these custom object records?","E. Will the data being archived need to be reported on or accessed in any way in the future?"],"answer":"A,B,E","title":"Question 5","explanation":""},{"content":"Universal Containers (UC) is a major supplier of office supplies. Some products are produced by UC and some by other manufacturers. Recently, a number of customers have complained that product descriptions on the invoices do not match the descriptions in the online catalog and on some of the order confirmations (e.g.,\n\"ballpoint pen\" in the catalog and \"pen\" on the invoice, and item color labels are inconsistent: \"what vs.\n\"White\" or \"blk\" vs. \"Black\"). All product data is consolidated in the company data warehouse and pushed to Salesforce to generate quotes and invoices. The online catalog and webshop is a Salesforce Customer Community solution. What is a correct technique UC should use to solve the data inconsistency?","options":["A. Build Apex Triggers in Salesforce that ensure products have the correct names and labels after data is loaded into salesforce.","B. Change integration to let product master systems update product data directly in Salesforce via the Salesforce API.","C. Add custom fields to the Product standard object in Salesforce to store data from the different source systems.","D. Define a data taxonomy for product data and apply the taxonomy to the product data in the data warehouse."],"answer":"D","title":"Question 6","explanation":""},{"content":"The architect is planning a large data migration for Universal Containers from their legacy CRM system to Salesforce. What three things should the architect consider to optimize performance of the data migration?\nChoose 3 answers","options":["A. Review the time zones of the User loading the data.","B. Deactivate approval processes and workflow rules.","C. Remove custom indexes on the data being loaded.","D. Defer sharing calculations of the Salesforce Org.","E. Determine if the legacy system is still in use."],"answer":"B,C,D","title":"Question 7","explanation":""},{"content":"Northern Trail Outfitters (NTO) has the following systems:\nCustomer master-source of truth for customer information\nService cloud-customer support\nMarketing cloud-marketing support\nEnterprise data warehouse-business reporting\nThe customer data is duplicated across all these system and are not kept in sync. Customers are also complaining that they get repeated marketing emails and have to call into update their information.\nNTO is planning to implement master data management (MDM) solution across the enterprise.\nWhich three data will an MDM tool solve?\nChoose 3 answers","options":["A. Data completeness","B. Data accuracy and quality","C. Data duplication","D. Data loss and recovery","E. Data standardization"],"answer":"B,C,E","title":"Question 8","explanation":""},{"content":"A company uses Salesforce, a cloud-based ERP system, and an on-premise Order Management System (OMS). This company requires a solution that uses Salesforce as the system of record for Leads and the OMS as the system of record for Account and Contacts.\nAdditionally, the company wants Accounts and Contacts to be able to maintain their names in each system (i.e., \"\"Jane Doe\"\"; in the OMS and \"\"Jannie Doe\"\"' in Salesforce), but wants to have a consolidated data store which links referenced records across the systems.\nWhich suggestion should the Architect provide to the company to meet this goal?","options":["A. Use a Master Data Management strategy to reconcile Leads, Accounts, and Contacts.","B. Have Salesforce poll the OMS nightly and bring in the desired Accounts and Contacts.","C. Utilize the Streaming API to send Account and Contact data from Salesforce to the OMS.","D. Use an integration tool to send OMS Accounts and Contacts to Salesforce."],"answer":"A","title":"Question 9","explanation":""},{"content":"DreamHouse Realty has a Salesforce org that is used to manage Contacts.\nWhat are two things an Architect should consider using to maintain data quality in this situation? (Choose two.)","options":["A. Use Salesforce duplicate management.","B. Use validation rules on new record create and edit.","C. Use workflow to delete duplicate records.","D. Use the private sharing model."],"answer":"A,B","title":"Question 10","explanation":""},{"content":"Universal Containers (CU) is in the process of implementing an enterprise data warehouse (EDW). UC needs to extract 100 million records from Salesforce for migration to the EDW.\nWhat data extraction strategy should a data architect use for maximum performance?","options":["A. Utilize PK Chunking with the Bulk API.","B. Use the Bulk API in parallel mode.","C. Call the REST API in successive queries.","D. Install a third-party AppExchange tool."],"answer":"A","title":"Question 11","explanation":""},{"content":"NTO has 1 million customer records spanning 25 years. As part of its new SF project, NTO would like to create a master data management strategy to help preserve the history and relevance of its customer data.\nWhich 3 activities will be required to identify a successful master data management strategy? Choose 3 answers:","options":["A. Install a data warehouse","B. Choose a Business Intelligence tool.","C. Create a data archive strategy","D. Identify data to be replicated","E. Define the systems of record for critical data"],"answer":"C,E","title":"Question 12","explanation":""},{"content":"Universal Containers (UC) is implementing a formal, cross -business -unit data governance program As part of the program, UC will implement a team to make decisions on enterprise -wide data governance. Which two roles are appropriate as members of this team? Choose 2 answers","options":["A. Salesforce Administrators","B. Analytics/BI Owners","C. Operational Data Users","D. Data Domain Stewards"],"answer":"B,D","title":"Question 13","explanation":""},{"content":"Universal Containers (UC) is in the process of selling half of its company. As part of this split, UC's main Salesforce org will be divided into two org:org A and org B, UC has delivered these requirements to its data architect\n1. The data model for Org B will drastically change with different objects, fields, and picklist values.\n2. Three million records will need to be migrated from org A to org B for compliance reasons.\n3. The migrate will need occur within the next two month, prior to be split.\nWhich migrate strategy should a data architect use to successfully migrate the date?","options":["A. Write a script to use the Bulk API","B. Use Data Loader for export and Data Import Wizard for import","C. use as ETL tool to orchestrate the migration.","D. Use the Salesforces CLI to query, export, and import"],"answer":"A","title":"Question 14","explanation":""},{"content":"Universal Containers has a large volume of Contact data going into Salesforce.com. There are 100,000 existing contact records. 200,000 new contacts will be loaded. The Contact object has an external ID field that is unique and must be populated for all existing records.\nWhat should the architect recommend to reduce data load processing time?","options":["A. Load Contact records together using the Streaming API via the Upsert operation.","B. Load all records via the Upsert operation to determine new records vs. existing records.","C. Load new records via the Insert operation and existing records via the Update operation.","D. Delete all existing records, and then load all records together via the Insert operation."],"answer":"C","title":"Question 15","explanation":""},{"content":"A customer wants to maintain geographic location information including latitude and longitude in a custom object.\nWhat would a data architect recommend to satisfy this requirement?","options":["A. Recommend AppExchange packages to support this requirement","B. Create formula fields with geolocation function for this requirement","C. Create a geolocation custom field to maintain this requirement","D. Create custom fields to maintain latitude and longitude information"],"answer":"C","title":"Question 16","explanation":"Explanation/Reference: https://help.salesforce.com/articleView?id=custom_field_geolocate_overview.htm&type=5"},{"content":"Northern trail Outfitters (NTO) uses Sales Cloud and service Cloud to manage sales and support processes.\nSome of NTOs team are complaining they see new fields on their page unsure of which values need be input.\nNTO is concerned about lack of governance in making changes to Salesforce.\nWhich governance measure should a data architect recommend to solve this issue?","options":["A. Add description fields to explain why the field is used, and mark the field as required.","B. Create validation rules with error messages to explain why the fields is used","C. Create reports to identify which users are leaving blank, and use external data sources o agreement the missing data.","D. Create and manage a data dictionary and ups a governance process for changes made to common objects."],"answer":"D","title":"Question 17","explanation":""},{"content":"Universal containers is implementing Salesforce lead management. UC Procure lead data from multiple sources and would like to make sure lead data as company profile and location information. Which solution should a data architect recommend to make sure lead data has both profile and location information? Option","options":["A. Run reports to identify records which does not have company profile and location data","B. Ask sales people to search for populating company profile and location data","C. Leverage external data providers populate company profile and location data","D. Export data out of Salesforce and send to another team to populate company profile and location data"],"answer":"A","title":"Question 18","explanation":""},{"content":"Universal Containers (UC) management has identified a total of ten text fields on the Contact object as important to capture any changes made to these fields, such as who made the change, when they made the change, what is the old value, and what is the new value. UC needs to be able to report on these field data changes within Salesforce for the past 3 months. What are two approaches that will meet this requirement? Choose 2 answers","options":["A. Create a workflow to evaluate the rule when a record is created and use field update actions to store previous values for these ten fields in ten new fields.","B. Turn on field Contact object history tracking for these ten fields, then create reports on contact history.","C. Create a Contact report including these ten fields and Salesforce Id, then schedule the report to run once a day and send email to the admin.","D. Write an Apex trigger on Contact after insert event and after update events and store the old values in another custom object."],"answer":"B,D","title":"Question 19","explanation":""},{"content":"A customer wants to maintain geographic location information including latitude and longitude in a custom object. What would a data architect recommend to satisfy this requirement?","options":["A. Create a geolocation custom field to maintain this requirement","B. Recommend app exchange packages to support this requirement.","C. Create formula fields with geolocation function for this requirement.","D. Create custom fields to maintain latitude and longitude information"],"answer":"A","title":"Question 20","explanation":""},{"content":"Universal Containers (UC) wants to store product data in Salesforce, but the standard Product object does not support the more complex hierarchical structure which is currently being used in the product master system. How can UC modify the standard Product object model to support a hierarchical data structure in order to synchronize product data from the source system to Salesforce?","options":["A. Create a custom lookup filed on the standard Product to reference the child record in the hierarchy.","B. Create a custom lookup field on the standard Product to reference the parent record in the hierarchy.","C. Create an Apex trigger to synchronize the Product Family standard picklist field on the Product object.","D. Create a custom master-detail field on the standard Product to reference the child record in the hierarchy."],"answer":"B","title":"Question 21","explanation":""},{"content":"Ursa Major Solar has defined a new Data Quality Plan for their Salesforce data.\nWhich two approaches should an Architect recommend to enforce the plan throughout the organization?\n(Choose two.)","options":["A. Enforce critical business processes by using Workflow, Validation Rules, and Apex code.","B. Schedule a weekly dashboard displaying records that are missing information to be sent to managers for review.","C. Ensure all data is stored in an external system and set up an integration to Salesforce for view-only access.","D. Schedule reports that will automatically catch duplicates and merge or delete the records every week."],"answer":"A,B","title":"Question 22","explanation":""},{"content":"Universal Containers has a large number of Opportunity fields (100) that they want to track field history on. Which two actions should an architect perform in order to meet this requirement? Choose 2 answers","options":["A. Create a custom object to store the previous and new field values.","B. Use Analytic Snapshots to store a copy of the record when changed.","C. Create a custom object to store a copy of the record when changed.","D. Select the 100 fields in the Opportunity Set History Tracking page."],"answer":"A,C","title":"Question 23","explanation":""},{"content":"Which three options can prevent your SOQL queries from being selective?","options":["A. Using trailing % wildcards.","B. Using a custom index on a deterministic formula field.","C. Performing large loads and deletions.","D. Using leading % wildcards.","E. Using NOT and != operators."],"answer":"B,D,E","title":"Question 24","explanation":""},{"content":"Universal Containers has more than 10 million records in the Order _c object. The query has timed out when running a bulk query. What should be considered to resolve query timeout?","options":["A. PK Chunking","B. Tooling API","C. Streaming API","D. Metadata API"],"answer":"A","title":"Question 25","explanation":""},{"content":"NTO (Northern Trail Outlets) has a complex Salesforce org which has been developed over past 5 years. Internal users are complaining abt multiple data issues, including incomplete and duplicate data in the org. NTO has decided to engage a data architect to analyze and define data quality standards.\nWhich 3 key factors should a data architect consider while defining data quality standards? Choose 3 answers:","options":["A. Define key fields in staging database for data cleansing","B. Finalize an extract transform load (ETL) tool for data migration","C. Measure data timeliness and consistency","D. Measure data completeness and accuracy","E. Define data duplication standards and rules"],"answer":"C,D,E","title":"Question 26","explanation":""},{"content":"","options":[],"answer":"","title":"Question ","explanation":""},{"content":"Universal Containers has a legacy system that captures Conferences and Venues. These Conferences can occur at any Venue. They create hundreds of thousands of Conferences per year. Historically, they have only used\n20 Venues. Which two things should the data architect consider when de-normalizing this data model into a single Conference object with a Venue picklist? Choose 2 answers","options":["A. Bulk API limitations on picklist fields.","B. Limitations on master -detail relationships.","C. Standard list view in-line editing.","D. Org data storage limitations."],"answer":"A,D","title":"Question 28","explanation":""},{"content":"DreamHouse Realty has a data model as shown in the image. The Project object has a private sharing model, and it has Roll-Up summary fields to calculate the number of resources assigned to the project, total hours for the project, and the number of work items associated to the project.\nThere will be a large amount of time entry records to be loaded regularly from an external system into Salesforce.\nWhat should the Architect consider in this situation?","options":["A. Load all data after deferring sharing calculations.","B. Load all data using external IDs to link to parent records.","C. Calculate summary values instead of Roll-Up by using workflow.","D. Calculate summary values instead of Roll-Up by using triggers."],"answer":"A","title":"Question 29","explanation":""},{"content":"UC has a salesforce org with multiple automated processes defined for group membership process. UC also have multiple admins on staff that perform manual adjustments to the role hierarchy. The automated task and manual task overlap daily and UC is experiencing \"Lock errors\" consistently.\nWhat should a data architect recommend mitigate these errors?","options":["A. Enable sharing recalculations","B. Ask salesforce support for addition CPU power.","C. Remove SOQL statements from APEX loops.","D. Enable granular locking."],"answer":"C","title":"Question 30","explanation":""},{"content":"Universal Containers keeps its Account data in Salesforce and its Invoice data in a third -party ERP system. They have connected the Invoice data through a Salesforce external object. They want data from both Accounts and Invoices visible in one report in one place. What two approaches should an architect suggest for achieving this solution? Choose 2 answers","options":["A. Create a report in an external system combining Salesforce Account data and Invoice data from the ERP.","B. Create a report combining data from the Account standard object and the Invoices external object.","C. Create a Visualforce page combining Salesforce Account data and Invoice external object data.","D. Create a separate Salesforce report for Accounts and Invoices and combine them in a dashboard."],"answer":"A,C","title":"Question 31","explanation":""},{"content":"A customer is operating in a highly reputated industry and is planning to implement SF. The customer information maintained in SF, includes the following:\n* Personally, identifiable information (PII)\n* IP restrictions on profiles organized by Geographic location\n* Financial records that need to be private and accessible only by the assigned Sales associate.\n* User should not be allowed to export information from Salesforce.\nEnterprise security has mandate access to be restricted to users within a specific geography and detail monitoring of user activity. Which 3 Salesforce shield capabilities should a data architect recommend? Choose\n3 answers:","options":["A. Restrict access to SF from users outside specific geography","B. Encrypt Sensitive Customer information maintained in SF.","C. Prevent Sales users access to customer PII information","D. Event monitoring to monitor all user activities","E. Transaction security policies to prevent export of SF Data."],"answer":"A,B,E","title":"Question 32","explanation":""},{"content":"Universal Containers (UC) has a requirement to create an Account plan object that is related to the Account object. Each Account plan needs to have an Account object, but the accessibility requirement of the Account plan is different from the Account object. What should an Architect recommend?","options":["A. Create a custom account plan object as detail with Account as mater in a master-detail relationship.","B. Create an account plan object with a lookup relationship to Account with validation rules to enforce the Account association.","C. Create a custom account plan object as detail with Account as master with additional sharing rules to allow access.","D. Create an account plan object with a lookup relations to Account without any validation rules to enforce the Account association."],"answer":"B","title":"Question 33","explanation":""},{"content":"A casino is implementing salesforce and is planning to build a customer 360 view for a customer who visits its resorts. The casino currently maintained the following systems that records customer activity:\n1. Point of sales system: All purchases for a customer.\n2. Salesforce: All customer service activity and sales activity for a customer.\n3. Mobile app: All bookings, preferences and browser activity for a customer.\n4. Marketing: All email, SMS and social campaigns for a customer.\nCustomer service agents using salesforce would like to view the activities from all system to provide supports to customers. The information has to be current and real time.\nWhat strategy should the data architect implement to satisfy this requirement?","options":["A. Use a customer data mart to view the 360 view of customer.","B. Explore external data sources in salesforce to build 360 view of customer.","C. Migrate customer activities from all 4 systems into salesforce.","D. Periodically upload summary information in salesforce to build 360 view."],"answer":"B","title":"Question 34","explanation":""},{"content":"To address different compliance requirements, such as general data protection regulation (GDPR), personally identifiable information (PII), of health insurance Portability and Accountability Act (HIPPA) and others, a SF customer decided to categorize each data element in SF with the following:\nData owner\nSecurity Level, such as confidential\nCompliance types such as GDPR, PII, HIPPA\nA compliance audit would require SF admins to generate reports to manage compliance.\nWhat should a data architect recommend to address this requirement?","options":["A. Use field metadata attributes for compliance categorization, data owner, and data sensitivity level.","B. Build reports for field information, then export the information to classify and report for Audits.","C. Use metadata API, to extract field attribute information and use the extract to classify and build reports","D. Create a custom object and field to capture necessary compliance information and build custom reports."],"answer":"A","title":"Question 35","explanation":""},{"content":"A data architect has been tasked with optimizing a data stewardship engagement for a Salesforce instance Which three areas of Salesforce should the architect review before proposing any design recommendation? Choose 3 answers","options":["A. Review the sharing model to determine impact on duplicate records.","B. Run key reports to determine what fields should be required.","C. Determine if any integration points create records in Salesforce.","D. Export the setup audit trail to review what fields are being used.","E. Review the metadata xml files for redundant fields to consolidate."],"answer":"A,B,E","title":"Question 36","explanation":""},{"content":"Universal Containers wants to develop a dashboard in Salesforce that will allow Sales Managers to do data exploration using their mobile device (i.e., drill down into sales-related data) and have the possibility of adding ad-hoc filters while on the move. What is a recommended solution for building data exploration dashboards in Salesforce?","options":["A. Create a Dashboard in an external reporting tool, export data to the tool, and add link to the dashboard in Salesforce.","B. Create a standard Salesforce Dashboard and connect it to reports with the appropriate filters.","C. Create a Dashboard in an external reporting tool, export data to the tool, and embed the dashboard in Salesforce using the Canval toolkit.","D. Create a Dashboard using Analytics Cloud that will allow the user to create ad-hoc lenses and drill down."],"answer":"D","title":"Question 37","explanation":""},{"content":"What are two key artifacts used to document the data architecture for a multi -system enterprise Salesforce implementation? Choose 2 answers","options":["A. Non-functional requirements","B. Integration specification","C. User stories","D. Data model"],"answer":"B,D","title":"Question 38","explanation":""},{"content":"Universal Containers (UC) uses Salesforce for tracking opportunities (Opportunity). UC uses an internal ERP system for tracking deliveries and invoicing. The ERP system supports SOAP API and OData for bi-directional integration between Salesforce and the ERP system. UC has about one million opportunities. For each opportunity, UC sends 12 invoices, one per month. UC sales reps have requirements to view current invoice status and invoice amount from the opportunity page. When creating an object to model invoices, what should the architect recommend, considering performance and data storage space?","options":["A. Create a custom object Invoice _c with a master -detail relationship with Opportunity.","B. Create an external object Invoice _x with a Lookup relationship with Opportunity.","C. Use Streaming API to get the current status from the ERP and display on the Opportunity page.","D. Create a custom object Invoice _c with a Lookup relationship with Opportunity."],"answer":"B","title":"Question 39","explanation":""},{"content":"Universal Containers (UC) is in the process of migrating lagacy inventory data from an enterprise resources planning (ERP) system into Sales Cloud with the following requirements:\nLegacy inventory data will be stored in a custom child objects called Inventory_c.\nInventory data should be related to the standard Account object.\nThe Inventory_c object should Inhent the same sharing rules as the Account object.\nAnytime an Account record is deleted in Salesforce, the related Inventory_c record(s) should be deleted as well.\nWhat type of relationship field should a data architect recommend in this scenario?","options":["A. Master-detail relationship filed on Account, related to Inventory_c","B. Lookup relationship fields on Inventory related to Account","C. Indirect lookup relationship field on Account, related to Inventory_c","D. Master-detail relationship filed on Inventory_c, related to Account"],"answer":"A","title":"Question 40","explanation":""},{"content":"DreamHouse Realty has a data model as shown in the image. The Project object has a private sharing model, and it has Roll-Up summary fields to calculate the number of resources assigned to the project, total hours for the project, and the number of work items associated to the project.\nThere will be a large amount of time entry records to be loaded regularly from an external system into Salesforce.\nWhat should the Architect consider in this situation?","options":["A. Calculate summary values instead of Roll-Up by using triggers.","B. Calculate summary values instead of Roll-Up by using workflow.","C. Load all data using external IDs to link to parent records.","D. Load all data after deferring sharing calculations."],"answer":"D","title":"Question 41","explanation":""},{"content":"DreamHouse Realty uses Custom Metadata Types instead of Custom setting.\nWhat is an advantage of this decision?","options":["A. Custom metadata records are editable in Apex.","B. Report definitions can include references to Custom Metadata Types.","C. Custom metadata records are NOT copied from production to sandbox.","D. Packages can be used to deploy Custom metadata records."],"answer":"D","title":"Question 42","explanation":"Explanation/Reference:"},{"content":"Universal Containers (UC) has implemented Sales Cloud for its entire sales organization, UC has built a custom object called projects_c that stores customers project detail and employee bitable hours.\nThe following requirements are needed:\nA subnet of individuals from the finance team will need to access to the projects object for reporting and adjusting employee utilization.\nThe finance users will not access to any sales objects, but they will need to interact with the custom object.\nWhich license type a data architect recommend for the finance team that best meets the requirements?","options":["A. Sales Cloud","B. Lighting platform plus","C. Service Cloud","D. Light Platform Start"],"answer":"B","title":"Question 43","explanation":""},{"content":"UC is migrating data from legacy system to SF. UC would like to preserve the following information on records being migrated:\nDate time stamps for created date and last modified date.\nOwnership of records belonging to inactive users being migrated to Salesforce.\nWhich 2 solutions should a data architect recommends to preserve the date timestamps and ownership on records? Choose 2 answers.","options":["A. Enable update records with Inactive Owners Permission","B. Enable Set Audit fields upon Record Creation Permission","C. Enable modify all and view all permission.","D. Log a case with SF to update these fields"],"answer":"A,B","title":"Question 44","explanation":""},{"content":"Universal Containers (UC) is implementing a Salesforce project with large volumes of data and daily transactions. The solution includes both real-time web service integrations and Visualforce mash -ups with back -end systems. The Salesforce Full sandbox used by the project integrates with full-scale back -end testing systems. What two types of performance testing are appropriate for this project?\nChoose 2 answers","options":["A. Stress testing against the web services hosted by the integration middleware.","B. Post go -live automated page -load testing against the Salesforce Production org.","C. Pre -go -live unit testing in the Salesforce Full sandbox.","D. Pre -go -live automated page -load testing against the Salesforce Full sandbox."],"answer":"A,D","title":"Question 45","explanation":""},{"content":"An Architect needs to assist Get Cloudy Consulting to maintain Lead data, even after Lead records are deleted and the Recycle Bin emptied.\nWhat should the Architect do to implement this solution?","options":["A. Send data to a Data Warehouse and mark Leads as deleted in that system.","B. Use a Converted Lead report to display data on Leads that have been deleted.","C. Use a Lead standard report and filter on the IsDeleted standard field.","D. Query Salesforce with the queryAll API method or using the ALL ROWS SOQL keywords."],"answer":"A","title":"Question 46","explanation":""},{"content":"A customer wants to maintain geographic location information including latitude and longitude in a custom object. What would a data architect recommend to satisfy this requirement?","options":["A. Create custom fields to maintain latitude and longitude information","B. Create formula fields with geolocation function for this requirement.","C. Create a geolocation custom field to maintain this requirement","D. Recommend app exchange packages to support this requirement."],"answer":"A","title":"Question 47","explanation":""},{"content":"Cloud Kicks needs to optimize data stewardship engagement for a Salesforce instance.\nBefore proposing design recommendations, the Data Architect is first assessing relevant areas of Salesforce.\nWhich three areas are appropriate to assess? (Choose three.)","options":["A. Export the setup audit trail to review what fields are being used.","B. Assess the sharing model to determine impact on duplicate records.","C. Run key reports to determine what fields should be required.","D. Assess the metadata xml files for redundant fields to consolidate.","E. Determine if any integration points create records in Salesforce."],"answer":"B,C,D","title":"Question 48","explanation":""},{"content":"Ursa Major Solar has 4 million rows of data in Salesforce that are used in reports to assess historical trends. Both performance and data storage limits have become an issue.\nWhich two strategies are appropriate when discussing the issue with stakeholders? (Choose two.)","options":["A. Configure the Salesforce Archiving feature to archive older records and remove them from the data storage limits.","B. Utilize scheduled batch Apex to copy aggregate information into a custom object and delete the original records.","C. Combine Analytics Snapshots with a purging plan by reporting on the snapshot data and deleting the original records.","D. Utilize Data Loader to extract data, aggregate it, and write it back to a custom object, then delete the original records."],"answer":"A,B","title":"Question 49","explanation":""},{"content":"Universal Containers (UC) is a business that works directly with individual consumers (B2C). They are moving from a current home-grown CRM system to Salesforce. UC has about one million consumer records.\nWhat should the architect recommend for optimal use of Salesforce functionality and also to avoid data loading issues?","options":["A. Load one Account record and one Contact record for each individual consumer.","B. Create one Account and load individual consumers as Contacts linked to that one Account.","C. Create a Custom Object Individual Consumer c to load all individual consumers.","D. Load all individual consumers as Account records and avoid using the Contact object."],"answer":"A","title":"Question 50","explanation":""},{"content":"Universal Containers would like to have a Service-Level Agreement (SLA) of 1 day for any data loss due to unintentional or malicious updates of records in Salesforce. What approach should be suggested to address this requirement?","options":["A. Evaluate a third-party AppExchange app, such as OwnBackup or Spanning, etc., for backup and archival purposes.","B. Build a daily extract job and extract data to on-premise systems for long-term backup and archival purposes.","C. Store all data in shadow custom objects on any updates and deletes, and extract them as needed .","D. Schedule a Weekly Extract Service for key objects and extract data in XL sheets to on- premise systems."],"answer":"A","title":"Question 51","explanation":""},{"content":"Cloud Kicks has a system environment that is complex, and they plan on creating a data governance program for the first time.\nWhat are two initial actions Cloud Kicks should take to initiate an assessment of data architecture? (Choose two.)","options":["A. Work with database administrators to assess current database performance metrics.","B. Work with executive sponsorship to assess enterprise data strategy and goals.","C. Work with business units and IT to assess current operational systems and data models.","D. Work with IT program managers to assess current velocity of projects in the pipeline."],"answer":"B,C","title":"Question 52","explanation":""},{"content":"Northern Trail Outfitters (NTO) has outgrown its current Salesforce org and will be migrating to a new org shortly. As part of this process, NTO will be migrating all of its metadata and data. NTO's data model in the source org has a complex relationship hierarchy with several master-detail and lookup relationships across objects, which should be maintained in the target org.\nWhich three things should a data architect do to maintain the relationship hierarchy during migration? (Choose three.)","options":["A. Create an external ID field for each object in the target org and map source record IDs to this field.","B. Replace source record IDs with new record IDs from the target org in the import file.","C. Use data loader to export the data from the source org and then import/upsert into the target org in sequential order.","D. Keep the relationship fields populated with the source record IDs in the import file.","E. Redefine the master-detail relationship fields to lookup relationship fields in the target org."],"answer":"A,C,D","title":"Question 53","explanation":""},{"content":"Members of DreamHouse Realty sales team are reporting that searches are yielding too many irrelevant, outdated records. Management requires that data for historical reporting. DreamHouse Realty has enough data storage.\nIn this situation, which strategy should a data architect use to ensure a better user experience for the Sales Reps?","options":["A. Use Batch Apex to archive old data on a rolling nightly basis.","B. Archive and purge old data from Salesforce on a monthly basis.","C. Hide old data from Sales Reps by setting data access to Private.","D. Hide old data from Sales Reps by creating a Permission Set."],"answer":"B","title":"Question 54","explanation":""},{"content":"A Customer is migrating 10 million order and 30 million order lines into Salesforce using Bulk API. The Engineer is experiencing time-out errors or long delays querying parents order IDs in Salesforce before importing related order line items. What is the recommended solution?","options":["A. Leverage Batch Apex to update order ID on related order lines after import.","B. Query only indexed ID field values on the imported order to import related order lines.","C. Leverage a sequence of numbers on the imported orders to import related order lines.","D. Leverage an External ID from source system orders to import related order lines."],"answer":"D","title":"Question 55","explanation":""},{"content":"Get Cloudy Consulting is migrating their legacy system's users and data to Salesforce. They will be creating\n15,000 users, 1.5 million Account records, and 15 million Invoice records. The visibility of these records is controlled by a 50 owner and criteria-based sharing rules.\nGet Cloudy Consulting needs to minimize data loading time during this migration to a new organization.\nWhich two approaches will accomplish this goal? (Choose two.)","options":["A. Contact Salesforce to activate indexing before uploading the data.","B. Create the users, upload all data, and then deploy the sharing rules.","C. First, load all account records, and then load all user records.","D. Defer sharing calculations until the data has finished uploading."],"answer":"B,D","title":"Question 56","explanation":""},{"content":"Northern Trail Outfitters (NTO) wants to implement backup and restore for Salesforce data, Currently, it has data backup processes that runs weekly, which back up all Salesforce data to an enterprise data warehouse (EDW). NTO wants to move to daily backups and provide restore capability to avoid any data loss in case of outage.\nWhat should a data architect recommend for a daily backup and restore solution?","options":["A. Use AppExchange package for backup and restore.","B. Use Bulk API to extract data on daily basis to EDW and REST API for restore.","C. Use ETL for backup and restore from EDW.","D. Change weekly backup process to daily backup, and implement a custom restore solution."],"answer":"A","title":"Question 57","explanation":""},{"content":"Cloud Kicks has the following requirements:\n- Data needs to be sent from Salesforce to an external system to generate invoices from their Order Management System (OMS).\n- A Salesforce administrator must be able to customize which fields will be sent to the external system without changing code.\nWhat are two approaches for fulfilling these requirements? (Choose two.)","options":["A. A Field Set that determines which fields to send in an HTTP callout.","B. An ObjectField to determine which fields to send in an HTTP callout.","C. An Outbound Message to determine which fields to send to the OMS.","D. Turn on the field-level security permissions for the fields to send."],"answer":"A,C","title":"Question 58","explanation":""},{"content":"A company has 12 million records, and a nightly integration queries these records.\nWhich two areas should a Data Architect investigate during troubleshooting if queries are timing out? (Choose two.)","options":["A. Make sure the query doesn't contain NULL in any filter criteria.","B. Create a formula field instead of having multiple filter criteria.","C. Modify the integration users' profile to have View All Data.","D. Create custom indexes on the fields used in the filter criteria."],"answer":"A,D","title":"Question 59","explanation":""},{"content":"UC has a variety of systems across its technology landscape, including SF, legacy enterprise resource planning (ERP) applications and homegrown CRM tools. UC has decided that they would like to consolidate all customer, opportunity and order data into Salesforce as part of its master data management (MDM) strategy.\nWhat are the 3 key steps that a data architect should take when merging data from multiple systems into Salesforce? Choose 3 answers:","options":["A. Install a 3rd party AppExchange tool to handle the merger","B. Work with Stakeholders to define record and field survivorship rules","C. Analyze each system's data model and perform gap analysis","D. Utilize an ETL tool to merge, transform and de-duplicate data.","E. Create new fields to store additional values from all the systems."],"answer":"A,C,D","title":"Question 60","explanation":""},{"content":"A large retail B2C customer wants to build a 360 view of its customer for its call center agents. The customer interaction is currently maintained in the following system: 1. Salesforce CRM\n2. Custom billing solution\n3. Customer Master Data management (MDM)\n4. Contract Management system\n5. Marketing solution\nWhat should a data architect recommend that would help upgrade uniquely identify customer across multiple systems:","options":["A. Create a custom field as external id to maintain the customer Id from the MDM solution.","B. Store the salesforce id in all the solutions to identify the customer.","C. Create a customer data base and use this id in all systems.","D. Create a custom object that will serve as a cross reference for the customer id."],"answer":"A","title":"Question 61","explanation":""},{"content":"A company is introducing a new data quality process and needs an Architect to recommend an appropriate approach. The new process will monitor the data that users are manually entering into the system through the Salesforce UI.\nWhich recommendation is correct?","options":["A. Create data-quality dashboards by using an app from the AppExchange.","B. Enable users to import their data using the Salesforce Import tools.","C. Use a 3rd-party solution from the AppExchange for data uploads.","D. Validate the format of phone numbers and postal codes by using Apex."],"answer":"A","title":"Question 62","explanation":"Explanation/Reference:"},{"content":"UC is building a salesforce application to track contacts and their respective conferences that they have attended with the following requirements:\n1. Contacts will be stored in the standard contact object.\n2. Conferences will be stored in a custom conference__c object.\n3. Each contact may attend multiple conferences and each conference may be related to multiple contacts.\nHow should a data architect model the relationship between the contact and conference objects?","options":["A. Create a master detail relationship field on the Contact object.","B. Create a master detail relationship field on the Conference object.","C. Implement a Contact Conference junction object with master detail relationship to both contact and conference__c.","D. Create a lookup relationship field on contact object."],"answer":"C","title":"Question 63","explanation":""},{"content":"Universal Containers (UC) is planning to launch its Customer Community. The community will allow user to register shipment requests which are then processed by UC employees.\nShipment requests contain header information, and then a list of no more than 5 items being shipped. UC will initially roll out its community to 5,000 customers in Europe, and will ultimately roll out to 20,000 customers worldwide within the next two years. UC expects an average of 10 shipment requests per week per customer. UC wants customers to be able to view up to three years of shipment requests and use Saleforce reports. What is the recommended solution for UC's Data Architect to address the requirements?","options":["A. Create an external custom object to track shipment requests and a child external object to track shipment items. External objects are stored off-platform in Heroku's Postgres database.","B. Create a custom object to track shipment requests with five lookup custom fields for each item being shipped Implement an archiving process that moves data off-platform after three years.","C. Create an external custom object to track shipment requests with five lookup custom fields for each item being shipped. External objects are stored off-platform in Heroku's Postgres database.","D. Create a custom object to track shipment requests and a child custom object to track shipment items. Implement an archiving process that moves data off-platform after three years."],"answer":"D","title":"Question 64","explanation":""},{"content":"Every year, Ursa Major Solar has more than 1 million orders. Each order contains an average of 10 line items. The Chief Executive Officer (CEO) needs the Sales Reps to see how much money each customer generates year-over-year. However, data storage is running low in Salesforce.\nWhich approach for data archiving is appropriate for this scenario?","options":["A. 1. Annually export and delete orders and order line items. 2. Store them in a zip file in case the data is needed later.","B. 1. Annually aggregate order amount data to store in a custom object. 2. Delete those orders and order line items.","C. 1. Annually delete orders and order line items. 2. Ensure the customer has order information in another system.","D. 1. Annually export and delete order line items. 2. Store them in a zip file in case the data is needed later."],"answer":"B","title":"Question 65","explanation":""},{"content":"UC has millions of Cases and are running out of storage. Some user groups need to have access to historical cases for up to 7 years.\nWhich 2 solutions should a data architect recommend in order to minimize performance and storage issues?\nChoose 2 answers:","options":["A. Leverage big object to archive case data and lightning components to show archived data.","B. Export data out of salesforce and store in Flat files on external system.","C. Leverage on premise data archival and build integration to view archived data.","D. Create a custom object to store case history and run reports on it."],"answer":"A,C","title":"Question 66","explanation":""},{"content":"Universal Container (UC) has around 200,000 Customers (stored in Account object). They get 1 or 2 Orders every month from each Customer. Orders are stored in a custom object called \"Order c\"; this has about 50 fields. UC is expecting a growth of 10% year -over -year.\nWhat are two considerations an architect should consider to improve the performance of SOQL queries that retrieve data from the Order _c object? Choose 2 answers","options":["A. Reduce the number of triggers on Order _c object.","B. Make the queries more selective using indexed fields.","C. Work with Salesforce Support to enable Skinny Tables.","D. Use SOQL queries without WHERE conditions."],"answer":"B,C","title":"Question 67","explanation":""},{"content":"Salesforce is being deployed in Ursa Major Solar's disparate, multi-system ERP environment. Ursa major Solar wants to maintain data synchronization between systems.\nWhich two techniques should be used to achieve this goal? (Choose two.)","options":["A. Utilize an MDM strategy to outline a single source of truth.","B. Integrate Salesforce with the ERP environment.","C. Build synchronization reports and dashboards.","D. Utilize workbench to update files within systems."],"answer":"A,B","title":"Question 68","explanation":""},{"content":"DreamHouse Realty has an integration that creates records in a Salesforce Custom Object. The Custom Object has a field marked as required on the page layout.\nDreamHouse Realty has noticed that many of the records coming from the external system are missing data in this field.\nThe Architect needs to ensure this field always contains data coming from the source system.\nWhich two approaches should the Architect take? Choose 2 answers","options":["A. Blame the customer's external system for bad data.","B. Set up a Validation Rule to prevent blank values.","C. Mark the field required in setup at the field level.","D. Create a Workflow to default a value into this field."],"answer":"B,C","title":"Question 69","explanation":""},{"content":"NTO has implemented salesforce for its sales users. The opportunity management in salesforce is implemented as follows:\n1. Sales users enter their opportunities in salesforce for forecasting and reporting purposes.\n2. NTO has a product pricing system (PPS) that is used to update opportunity amount field on opportunities on a daily basis.\n3. PPS is the trusted source within the NTO for opportunity amount.\n4. NTO uses opportunity forecast for its sales planning and management.\nSales users have noticed that their updates to the opportunity amount field are overwritten when PPS updates their opportunities.\nHow should a data architect address this overriding issue?","options":["A. Change opportunity amount field access to read only for sales users using field level security.","B. Create a custom field for opportunity amount that PPS updates separating the field that sales user updates.","C. Create a custom field for opportunity amount that sales users update separating the fields that PPS updates.","D. Change PPS integration to update only opportunity amount fields when values is NULL."],"answer":"A","title":"Question 70","explanation":""},{"content":"Get Cloudy Consulting monitors 15,000 servers, and these servers automatically record their status every 10 minutes. Because of company policy, these status reports must be maintained for 5 years. Managers at Get Cloudy Consulting need access to up to one week's worth of these status reports with all of their details.\nAn Architect is recommending what data should be integrated into Salesforce and for how long it should be stored in Salesforce.\nWhich two limits should the Architect be aware of? (Choose two.)","options":["A. Webservice callout limits","B. Workflow rule limits","C. Data storage limits","D. API Request limits"],"answer":"C,D","title":"Question 71","explanation":""},{"content":"Universal Containers (UC) is a business that works directly with individual consumers (B2C). They are moving from a current home-grown CRM system to Salesforce. UC has about one million consumer records. What should the architect recommend for optimal use of Salesforce functionality and also to avoid data loading issues?","options":["A. Create a Custom Object Individual Consumer c to load all individual consumers.","B. Load one Account record and one Contact record for each individual consumer.","C. Create one Account and load individual consumers as Contacts linked to that one Account.","D. Load all individual consumers as Account records and avoid using the Contact object."],"answer":"B","title":"Question 72","explanation":""},{"content":"Northern Trail Outfitters is migrating to Salesforce from a legacy CRM system that identifies the agent relationships in a look-up table.\nWhat should the data architect do in order to migrate the data to Salesforce?","options":["A. Migrate the data and assign to a non-person system user.","B. Create custom object to store agent relationships.","C. Migrate to Salesforce without a record owner.","D. Assign record owners based on relationship."],"answer":"B","title":"Question 73","explanation":""},{"content":"Universal containers is implementing Salesforce lead management. UC Precure lead data from multiple sources and would like to make sure lead data as company profile and location information. Which solution should a data architect recommend to make sure lead data has both profile and location information? Option","options":["A. Leverage external data providers populate company profile and location data","B. Ask sales people to search for populating company profile and location data","C. Export data out of Salesforce and send to another team to populate company profile and location data","D. Run reports to identify records which does not have company profile and location data"],"answer":"A","title":"Question 74","explanation":""},{"content":"Universal Containers (UC) management has identified a total of ten text fields on the Contact object as important to capture any changes made to these fields, such as who made the change, when they made the change, what is the old value, and what is the new value. UC needs to be able to report on these field data changes within Salesforce for the past 3 months. What are two approaches that will meet this requirement?\nChoose 2 answers","options":["A. LII Turn on field Contact object history tracking for these ten fields, then create reports on contact history.","B. Write an Apex trigger on Contact after insert event and after update events and store the old values in another custom object.","C. Create a workflow to evaluate the rule when a record is created and use field update actions to store previous values for these ten fields in ten new fields.","D. Create a Contact report including these ten fields and Salesforce Id, then schedule the report to run once a day and send email to the admin."],"answer":"A,B","title":"Question 75","explanation":""},{"content":"Universal Container has implemented Sales Cloud to manage patient and related health records. During a recent security audit of the system it was discovered that same standard and custom fields need to encrypted.\nWhich solution should a data architect recommend to encrypt existing fields?","options":["A. Use Apex Crypto Class encrypt customer and standard fields.","B. Implement shield platform encryption to encrypt and standard fields","C. Expert data out of Salesforce and encrypt custom and standard fields.","D. Implement classic encryption to encrypt custom and standard fields."],"answer":"B","title":"Question 76","explanation":""},{"content":"Cloud Kicks stores Invoice records in a custom object. Invoice records are being sent to the Accounting department with missing States and incorrectly formatted Postal Codes.\nWhich two actions should Cloud Kicks take to improve data quality? (Choose two.)","options":["A. Utilize a Validation Rule with a CONTAINS operator on address fields.","B. Change each address field to required on the Page Layout.","C. Write an Apex Trigger to require all fields to be populated.","D. Utilize a Validation Rule with a REGEX operator on Postal Code."],"answer":"A,D","title":"Question 77","explanation":""},{"content":"A data architect has been tasked with optimizing a data stewardship engagement for a Salesforce instance Which three areas of Salesforce should the architect review before proposing any design recommendation?\nChoose 3 answers","options":["A. Determine if any integration points create records in Salesforce.","B. Review the metadata xml files for redundant fields to consolidate.","C. Export the setup audit trail to review what fields are being used.","D. Run key reports to determine what fields should be required.","E. Review the sharing model to determine impact on duplicate records."],"answer":"B,D,E","title":"Question 78","explanation":""},{"content":"Cloud Kicks has the following requirements:\n- Data needs to be sent from Salesforce to an external system to generate invoices from their Order Management System (OMS).\n- A Salesforce administrator must be able to customize which fields will be sent to the external system without changing code.\nWhat are two approaches for fulfilling these requirements? (Choose two.)","options":["A. An ObjectField to determine which fields to send in an HTTP callout.","B. Turn on the field-level security permissions for the fields to send.","C. A Field Set that determines which fields to send in an HTTP callout.","D. An Outbound Message to determine which fields to send to the OMS."],"answer":"C,D","title":"Question 79","explanation":"Explanation"},{"content":"Universal Containers (UC) requires 2 years of customer related cases to be available on SF for operational reporting. Any cases older than 2 years and upto 7 years need to be available on demand to the Service agents. UC creates 5 million cases per yr.\nWhich 2 data archiving strategies should a data architect recommend? Choose 2 options:","options":["A. Use Big objects for cases older than 2 years, and use nightly batch to move them.","B. Use custom objects for cases older than 2 years and use nightly batch to move them.","C. Use Heroku and external objects to display cases older than 2 years and bulk API to hard delete from Salesforce.","D. Sync cases older than 2 years to an external database, and provide access to Service agents to the database"],"answer":"A,C","title":"Question 80","explanation":""},{"content":"DreamHouse Realty needs an Architect to develop a solution that will integrate data and resolve duplicates and discrepancies between Salesforce and one or more external systems.\nWhat are two important questions the Architect should answer when determining whether to use Master Data Management in the solution? (Choose two.)","options":["A. Will Salesforce replace a legacy system?","B. How many systems are integrating with each other?","C. Are the systems cloud-based or on-premise?","D. Does the system of record change for different tables?"],"answer":"B,D","title":"Question 81","explanation":""},{"content":"Every year, Ursa Major Solar has more than 1 million orders. Each order contains an average of 10 line items.\nThe Chief Executive Officer (CEO) needs the Sales Reps to see how much money each customer generates year-over-year. However, data storage is running low in Salesforce.\nWhich approach for data archiving is appropriate for this scenario?","options":["A. 1. Annually aggregate order amount data to store in a custom object. 2. Delete those orders and order line items.","B. 1. Annually delete orders and order line items. 2. Ensure the customer has order information in another system.","C. 1. Annually export and delete orders and order line items. 2. Store them in a zip file in case the data is needed later.","D. 1. Annually export and delete order line items. 2. Store them in a zip file in case the data is needed later."],"answer":"A","title":"Question 82","explanation":""},{"content":"Universal Containers (UC) has multi -level account hierarchies that represent departments within their major Accounts. Users are creating duplicate Contacts across multiple departments. UC wants to clean the data so as to have a single Contact across departments. What two solutions should UC implement to cleanse their data?\nChoose 2 answers","options":["A. Make use of a third -party tool to help merge duplicate Contacts across Accounts.","B. Use Data.com to standardize Contact address information to help identify duplicates.","C. Make use of the Merge Contacts feature of Salesforce to merge duplicates for an Account.","D. Use Workflow rules to standardize Contact information to identify and prevent duplicates."],"answer":"A,B","title":"Question 83","explanation":""},{"content":"Universal Containers (UC) provides shipping services to its customers. They use Opportunities to track customer shipments. At any given time, shipping status can be one of the 10 values. UC has 200,000 Opportunity records. When creating a new field to track shipping status on opportunity, what should the architect do to improve data quality and avoid data skew?","options":["A. Create a picklist field, values sorted alphabetically.","B. Create a text field and make it an external ID.","C. Create a Lookup to custom object ShippingStatus c.","D. Create a Master -Detail to custom object ShippingStatus c."],"answer":"A","title":"Question 84","explanation":""},{"content":"Universal Containers (UC) wants to capture information on how data entities are stored within the different applications and systems used within the company. For that purpose, the architecture team decided to create a data dictionary covering the main business domains within UC. Which two common techniques are used building a data dictionary to store information on how business entities are defined?","options":["A. Use the Salesforce Metadata API.","B. Use Salesforce Object Query Language.","C. Use a data definition language.","D. Use an entity relationship diagram."],"answer":"A,D","title":"Question 85","explanation":""},{"content":"Company S was recently acquired by Company T. As part of the acquisition, all of the data for the Company S's Salesforce instance (source) must be migrated into the Company T's Salesforce instance (target).\nCompany S has 6 million Case records.\nAn Architect has been tasked with optimizing the data load time.\nWhat should the Architect consider to achieve this goal?","options":["A. Directly leverage Salesforce-to-Salesforce functionality to load Case data.","B. Pre-process the data, then use Data Loader with SOAP API to upsert with zip compression enabled.","C. Load the data in multiple sets using Bulk API parallel processes.","D. Utilize the Salesforce Org Migration Tool from the Setup Data Management menu."],"answer":"B","title":"Question 86","explanation":""},{"content":"Universal Containers has a rollup summary field on account to calculate the count of contacts associated with an account. During the account load, Salesforce is throwing an \"Unable to lock a row\" error.\nWhich solution should a data architect recommend to resolve the error?","options":["A. Perform batch job in parallel mode, and reduce batch size","B. Defer rollup summary fields calculation during data migration","C. Leverage data loader platform API to load data","D. Perform batch job in serial mode, and reduce batch size"],"answer":"D","title":"Question 87","explanation":"Explanation/Reference: https://salesforce.stackexchange.com/questions/181798/roll-up-summary-implications-and-behind- the-scenes-calculations"},{"content":"Universal Containers is migrating 100,000 accounts from an enterprise resource planning (ERP) to Salesforce and is concerned about ownership skew and performances.\nWhich three recommendations should a data architect provide to prevent ownership skew? (Choose three.)","options":["A. Assign view all permissions on profile to give access to account","B. Keep users out of public groups that can be used as the source for sharing rules","C. Assign a default user as owner of accounts and do not assign any role to default user","D. Assign a default user as owner of accounts, and assign role in hierarchy","E. Assign a default user as owner of accounts and assign top most role in hierarchy"],"answer":"A,B,C","title":"Question 88","explanation":""},{"content":"Which two best practices should be followed when using SOSL for searching?","options":["A. Use searches against single Objects for greater speed and accuracy.","B. Use Find in \"ALL FIELDS\" for faster searches.","C. Use SOSL option to ignore custom indexes as search fields are pre-indexed.","D. Keep searches specific and avoid wildcards where possible."],"answer":"B,D","title":"Question 89","explanation":""},{"content":"The Chief Technology Officer (CTO) of Ursa Major Solar wants error messages to appear when a future date is detected in a custom AnniversaryDate_c field on the Contact object. Additionally, the CTO wants the ability to translate the error messages.\nWhich two approaches should an Architect use to fulfill this requirement? (Choose two.)","options":["A. Create a validation rule and translate the error message with translation workbench.","B. Implement an external validation API with translation functionality.","C. Create a trigger on Contact and add an error to the record with a custom label.","D. Create a workflow field update to set the standard ErrorMessage field."],"answer":"A,C","title":"Question 90","explanation":""},{"content":"Universal Containers (UC) has a very large and complex Salesforce org with hundreds of validation rules and triggers. The triggers are responsible for system updates and data manipulation as records are created or updates by users. A majority of the automation tool within UC'' org were not designed to run during a data load. UC is importing 100,000 records into Salesforce across several objects over the weekend.\nWhat should a data architect do to mitigate any unwanted results during the import?","options":["A. Ensure duplication and matching rules and defined.","B. Import the data in smaller batches over a 24-hour period.","C. Bulkily the trigger to handle import leads.","D. Ensure validation rules, triggers and other automation tools are disabled."],"answer":"D","title":"Question 91","explanation":""},{"content":"Universal Containers (UC) is using Salesforce Sales & Service Cloud for B2C sales and customer service but they are experiencing a lot of duplicate customers in the system. Which are two recommended approaches for UC to avoid duplicate data and increase the level of data quality?","options":["A. Use Data.com Clean","B. Use a data wharehouse.","C. Use an Enterprise Service Bus.","D. Use Duplicate Management."],"answer":"A,D","title":"Question 92","explanation":""},{"content":"Northern trail Outfitters (NTO) uses Sales Cloud and service Cloud to manage sales and support processes. Some of NTOs team are complaining they see new fields on their page unsure of which values need be input. NTO is concerned about lack of governance in making changes to Salesforce.\nWhich governance measure should a data architect recommend to solve this issue?","options":["A. Create and manage a data dictionary and ups a governance process for changes made to common objects.","B. Create validation rules with error messages to explain why the fields is used","C. Create reports to identify which users are leaving blank, and use external data sources o agreement the missing data.","D. Add description fields to explain why the field is used, and mark the field as required."],"answer":"A","title":"Question 93","explanation":""},{"content":"Universal Containers (UC) has a Salesforce instance with over 10.000 Account records.\nThey have noticed similar, but not identical. Account names and addresses. What should UC do to ensure proper data quality?","options":["A. Use a service to standardize Account addresses, then use a 3rd -party tool to merge Accounts based on rules.","B. Enable Account de -duplication by creating matching rules in Salesforce, which will mass merge duplicate Accounts.","C. Make the Account Owner clean their Accounts' addresses, then merge Accounts with the same address.","D. Run a report, find Accounts whose name starts with the same five characters, then merge those Accounts."],"answer":"B","title":"Question 94","explanation":""},{"content":"Cloud Kicks has the following requirements:\n- They want to automatically archive all inactive Account data that is older than 3 years.\n- The information does not need to remain accessible within the application.\nWhich two approaches should the Architect recommend to meet this requirement? (Choose two.)","options":["A. Schedule jobs to export and delete using an ETL tool.","B. Export the data by using the Force.com Workbench.","C. Schedule a weekly export file from the Salesforce UI.","D. Schedule jobs to export and delete using the Data Loader."],"answer":"A,D","title":"Question 95","explanation":""},{"content":"The data architect for UC has written a SOQL query that will return all records from the Task object that do not have a value in the WhatId field:\nSelect id, description, Subject from Task where WhatId != NULL\nWhen the data architect usages the query to select values for a process a time out error occurs.\nWhat does the data architect need to change to make this query more performant?","options":["A. Change query to SOSL. ??","B. Change the where clause to filter by a deterministic defined value.","C. Add limit 100 to the query.","D. Remove description from the requested field set."],"answer":"B","title":"Question 96","explanation":""},{"content":"UC has a variety of systems across its technology landscape, including SF, legacy enterprise resource planning (ERP) applications and homegrown CRM tools. UC has decided that they would like to consolidate all customer, opportunity and order data into Salesforce as part of its master data management (MDM) strategy.\nWhat are the 3 key steps that a data architect should take when merging data from multiple systems into Salesforce? Choose 3 answers:","options":["A. Analyze each system's data model and perform gap analysis","B. Utilize an ETL tool to merge, transform and de-duplicate data.","C. Create new fields to store additional values from all the systems.","D. Install a 3rd party AppExchange tool to handle the merger","E. Work with Stakeholders to define record and field survivorship rules"],"answer":"A,B,E","title":"Question 97","explanation":""},{"content":"Cloud Kicks is launching a Partner Community, which will allow users to register shipment requests that are then processed by Cloud Kicks employees. Shipment requests contain header information, and then a list of no more than 5 items being shipped.\nFirst, Cloud Kicks will introduce its community to 6,000 customers in North America, and then to 24,000 customers worldwide within the next two years. Cloud Kicks expects 12 shipment requests per week per customer, on average, and wants customers to be able to view up to three years of shipment requests and use Salesforce reports.\nWhat is the recommended solution for the Cloud Kicks Data Architect to address the requirements?","options":["A. Create an external custom object to track shipment requests and a child external object to track shipment items. External objects are stored off-platform in Heroku's Postgres database.","B. Create a custom object to track shipment requests and a child custom object to track shipment items. Implement an archiving process that moves data off-platform after three years.","C. Create an external custom object to track shipment requests with five lookup custom fields for each item being shipped. External objects are stored off-platform in Heroku's Postgres database.","D. Create a custom object to track shipment requests with five lookup custom fields for each item being shipped Implement an archiving process that moves data off-platform after three years."],"answer":"B","title":"Question 98","explanation":""},{"content":"Universal Containers would like to remove data silos and connect their legacy CRM together with their ERP and with Salesforce. Most of their sales team has already migrated to Salesforce for daily use, although a few users are still on the old CRM until some functionality they require is completed. Which two techniques should be used for smooth interoperability now and in the future.","options":["A. Replicate ongoing changes in the legacy CRM to Salesforce to facilitate a smooth transition when the legacy CRM is eventually retired.","B. Work with stakeholders to establish a Master Data Management plan for the system of record for specific objects, records, and fields.","C. Specify the legacy CRM as the system of record during transition until it is removed from operation and fully replaced by Salesforce.","D. Do not connect Salesforce and the legacy CRM to each other during this transition period, but do allow both to interact with the ERP."],"answer":"B,C","title":"Question 99","explanation":""},{"content":"Which three characteristics of a Skinny table help improve report and query performance?","options":["A. Skinny tables provide a view across multiple objects for easy access to combined data.","B. Skinny tables can be used to create custom indexes on multi-select picklist fields.","C. Skinny tables can contain frequently used fields and thereby help avoid joins.","D. Skinny tables do not include records that are available in the recycle bin.","E. Skinny tables are kept in sync with changes to data in the source tables."],"answer":"A,C,E","title":"Question 100","explanation":""},{"content":"Universal Containers (UC) has a complex system landscape and is implementing a data governance program for the first time Which two first steps would be appropriate for UC to initiate an assessment of data architecture? Choose 2 answers","options":["A. Engage with business units and IT to assess current operational systems and data models.","B. Engage with IT program managers to assess current velocity of projects in the pipeline.","C. Engage with database administrators to assess current database performance metrics.","D. Engage with executive sponsorship to assess enterprise data strategy and goals."],"answer":"A,D","title":"Question 101","explanation":""},{"content":"A customer monitors over 10,000 servers and these servers automatically record their status every 15 minutes The customer is required to maintain all of these status reports for a period of 10 years. Service Reps need access to up to one week's worth of these status reports with all of their details. What are two limits an architect should consider when recommending what data should be integrated into Salesforce and for how long it should be stored in Salesforce?\nChoose 2 answers","options":["A. Data storage limits","B. API Request limits","C. Webservice callout limits","D. Workflow rule limits"],"answer":"A,B","title":"Question 102","explanation":""},{"content":"DreamHouse Realty has a data model as shown in the image. The Project object has a private sharing model, and it has Roll-Up summary fields to calculate the number of resources assigned to the project, total hours for the project, and the number of work items associated to the project.\nThere will be a large amount of time entry records to be loaded regularly from an external system into Salesforce.","options":["A. Load all data after deferring sharing calculations.","B. Calculate summary values instead of Roll-Up by using triggers.","C. Load all data using external IDs to link to parent records.","D. Calculate summary values instead of Roll-Up by using workflow."],"answer":"A","title":"Question 103","explanation":""},{"content":"UC is implementing sales cloud for patient management and would like to encrypt sensitive patient records being stored in files.\nWhich solution should a data architect recommend to solve this requirement?","options":["A. Store files outside of salesforce and access them to real time.","B. Implement 3rd party App Exchange app to encrypt files.","C. Implement shield platform encryption to encrypt files.","D. Use classic encryption to encrypt files."],"answer":"C","title":"Question 104","explanation":""},{"content":"UC needs to load a large volume of leads into salesforce on a weekly basis. During this process the validation rules are disabled.\nWhat should a data architect recommend to ensure data quality is maintained in salesforce.","options":["A. Ensure the lead data is preprocessed for quality before loading into salesforce.","B. Develop custom APEX batch process to improve quality once the load is completed.","C. Allow validation rules to be activated during the load of leads into salesforce.","D. Activate validation rules once the leads are loaded into salesforce to maintain quality."],"answer":"B","title":"Question 105","explanation":""},{"content":"Universal Containers keeps its Account data in Salesforce and its Invoice data in a third -party ERP system.\nThey have connected the Invoice data through a Salesforce external object. They want data from both Accounts and Invoices visible in one report in one place. What two approaches should an architect suggest for achieving this solution? Choose 2 answers","options":["A. Create a report in an external system combining Salesforce Account data and Invoice data from the ERP.","B. Create a Visualforce page combining Salesforce Account data and Invoice external object data.","C. Create a separate Salesforce report for Accounts and Invoices and combine them in a dashboard.","D. Create a report combining data from the Account standard object and the Invoices external object."],"answer":"A,B","title":"Question 106","explanation":""},{"content":"Cloud Kicks has a Salesforce instance with 12,000 Account records. Managers at the company have noticed similar, but not identical, Account names and addresses.\nThe Chief Technology Officer (CTO) at Cloud Kicks is concerned about proper data quality.\nWhich steps should the CTO take to address this issue?","options":["A. 1. Have the Account Owner clean their Accounts' addresses.\n         2. Merge Accounts with the same address.","B. 1. Run a report.\n         2. Find Accounts whose name starts with the same five characters, and merge those Accounts.","C. 1. Enable Account de-duplication by creating matching rules in Salesforce.\n         2. The system will then mass merge duplicate Accounts.","D. 1. Use a service to standardize Account addresses.\n         2. Use a 3rd-party tool to merge Accounts based on rules."],"answer":"C","title":"Question 107","explanation":""},{"content":"A large automobile company has implemented Salesforce for its sales associates. Leads flow from its website to Salesforce using a batch integration in Salesforce. The batch job converts the leads to Accounts in Salesforce. Customers visiting their retail stores are also created in Salesforce as Accounts.\nThe company has noticed a large number of duplicate Accounts in Salesforce. On analysis, it was found that certain customers could interact with its website and also visit the store. The sales associates use Global Search to search for customers in Salesforce before they create the customers.\nWhich option should a data architect choose to implement to avoid duplicates?","options":["A. leverage duplicate rules in Salesforce to validate duplicates during the account creation process.","B. Develop an Apex class that searches for duplicates and removes them nightly.","C. Build a custom search functionality that allows sales associates to search for customer in real time upon visiting their retail stores.","D. Implement an MDM solution to validate the customer information before creating Salesforce."],"answer":"A","title":"Question 108","explanation":""},{"content":"Universal Containers (UC) is expecting to have nearly 5 million shipments records in its Salesforce org. Each shipment record has up to 10 child shipment item records. The Shipment custom object has an Organization-wide Default (OWD) sharing model set to Private and the Shipment Item custom object has a Master-Detail relationship to Shipment. There are 25 sharing rules set on the Shipment custom object, which allow shipment records to be shared to each of UC's 25 business areas around the globe. These sharing rules use public groups, one for each business area plus a number of groups for management and support roles. UC has a high turnover of Sales Reps and often needs to move Sales Reps between business areas in order to meet local demand. What feature would ensure that performance, when moving Sales Reps between regions, remains adequate while meeting existing requirements?","options":["A. Contact Salesforce to create Skinny tables on Shipment.","B. Implement data archiving for old Shipment records.","C. Contact Salesforce to enable Defer Sharing Rules","D. Configure shipment OWD to Public Read/Write."],"answer":"C","title":"Question 109","explanation":""},{"content":"All accounts and opportunities are created in Salesforce. Salesforce is integrated with three systems:\n* An ERP system feeds order data into Salesforce and updates both Account and Opportunity records.\n* An accounting system feeds invoice data into Salesforce and updates both Account and Opportunity records.\n* A commission system feeds commission data into Salesforce and updates both Account and Opportunity records.\nHow should the architect determine which of these systems is the system of record?","options":["A. Whatever integration data flow runs last will, by default, determine which system is the system of record.","B. Account and opportunity data originates in Salesforce, and therefore Salesforce is the system of record.","C. Data flows should be reviewed with the business users to determine the system of record per object or field.","D. Whatever system updates the attribute or object should be the system of record for that field or object."],"answer":"C","title":"Question 110","explanation":""},{"content":"A customer is operating in a highly regulated industry and is planning to implement Salesforce. The customer information maintained in Salesforce, includes the following:\n1. Personally identifiable information (PII)\n2. IP restrictions on profiles organized by geographic location\n3. Financial records that need to be private and accessible only by the assigned sales associate\n4. Users should not be allowed to export information from Salesforce\nEnterprise Security has mandated access to be restricted to users within a specific geography and detail monitoring of user activity.\nWhich three Salesforce Shield capabilities should a data architect recommend? (Choose three.)","options":["A. Prevent sales users access to customer PII information","B. Restrict access to Salesforce from users outside specific geography","C. Encrypt sensitive customer information maintained in Salesforce","D. Event monitoring to monitor all user activity","E. Transaction Security policies to prevent export of Salesforce data"],"answer":"B,C,D","title":"Question 111","explanation":""},{"content":"Company S was recently acquired by Company\nT. As part of the acquisition, all of the data for the Company S's Salesforce instance (source) must be migrated into the Company T's Salesforce instance (target). Company S has 6 million Case records.\nAn Architect has been tasked with optimizing the data load time.\nWhat should the Architect consider to achieve this goal?","options":["A. Pre-process the data, then use Data Loader with SOAP API to upsert with zip compression enabled.","B. Directly leverage Salesforce-to-Salesforce functionality to load Case data.","C. Utilize the Salesforce Org Migration Tool from the Setup Data Management menu.","D. Load the data in multiple sets using Bulk API parallel processes."],"answer":"A","title":"Question 112","explanation":""},{"content":"NTO has multiple systems across its enterprise landscape including salesforce, with disparate version the customer records.\nIn salesforce, the customer is represented by the contact object.\nNTO utilizes an MDM solution with these attributes:\n1. The MDM solution keeps track of customer master with a master key.\n2. The master key is a map to the record ID's from each external system that customer data is stored within.\n3. The MDM solution provides de-duplication features, so it acts as the single source of truth.\nHow should a data architect implement the storage of master key within salesforce?","options":["A. Store the master key in Heroku postgres and use Heroku connect for synchronization.","B. Store the master key on the contact object as an external ID (Field for referential imports)","C. Create a custom object to store the master key with a lookup field to contact.","D. Create an external object to store the master key with a lookup field to contact."],"answer":"B","title":"Question 113","explanation":""},{"content":"Universal Containers is exporting 40 million Account records from Salesforce using Informatica Cloud. The ETL tool fails and the query log indicates a full table scan time-out failure. What is the recommended solution?","options":["A. Modify the export job header to specify Sforce-Enable-PKChunking.","B. Modify the export query with LIMIT clause with Batch size 10,000.","C. Modify the export query that includes standard index fields(s).","D. Modify the export job header to specify Export-in-Parallel."],"answer":"A","title":"Question 114","explanation":""},{"content":"NTO has multiple systems across its enterprise landscape including salesforce, with disparate version the customer records.\nIn salesforce, the customer is represented by the contact object.\nNTO utilizes an MDM solution with these attributes:\n1. The MDM solution keeps track of customer master with a master key.\n2. The master key is a map to the record ID's from each external system that customer data is stored within.\n3. The MDM solution provides de-duplication features, so it acts as the single source of truth.\nHow should a data architect implement the storage of master key within salesforce?","options":["A. Create an external object to store the master key with a lookup field to contact.","B. Create a custom object to store the master key with a lookup field to contact.","C. Store the master key in Heroku postgres and use Heroku connect for synchronization.","D. Store the master key on the contact object as an external ID (Field for referential imports)"],"answer":"D","title":"Question 115","explanation":""},{"content":"DreamHouse Realty recently implemented a Sales Cloud. Managers have noticed that sales reps are entering an insufficient amount of data to run insightful reports and dashboards. The managers would like to monitor and measure data quality metrics.\nWhich solution addresses this requirement?","options":["A. Utilize third-party AppExchange tools to measure and monitor data quality.","B. Use custom objects and fields to calculate data quality.","C. Run and generate reports to view the quality of sample data.","D. Export the data to an enterprise data warehouse and use BI tools for data quality."],"answer":"A","title":"Question 116","explanation":""},{"content":"UC has migrated its Back-office data into an on-premise database with REST API access. UC recently implemented Sales cloud for its sales organization. But users are complaining about a lack of order data inside SF.\nUC is concerned about SF storage limits but would still like Sales cloud to have access to the data.\nWhich design patterns should a data architect select to satisfy the requirement?","options":["A. Develop a bidirectional integration between the on-premise system and Salesforce.","B. Use SF Connect to virtualize the data in SF and avoid storage limits.","C. Migrate and persist the data in SF to take advantage of native functionality.","D. Build a UI for the on-premise system and iframe it in Salesforce"],"answer":"B","title":"Question 117","explanation":""},{"content":"Ursa Major Solar has defined a new Data Quality Plan for their Salesforce data.\nWhich two approaches should an Architect recommend to enforce the plan throughout the organization? (Choose two.)","options":["A. Enforce critical business processes by using Workflow, Validation Rules, and Apex code.","B. Schedule a weekly dashboard displaying records that are missing information to be sent to managers for review.","C. Ensure all data is stored in an external system and set up an integration to Salesforce for view-only access.","D. Schedule reports that will automatically catch duplicates and merge or delete the records every week."],"answer":"A,B","title":"Question 118","explanation":""},{"content":"What are two valid metadata types that should be included to document the data architecture of a Salesforce org? Choose 2 answers","options":["A. Document","B. SecuritySettings","C. RecordType","D. CustomField"],"answer":"C,D","title":"Question 119","explanation":""},{"content":"Universal Containers has millions of rows of data in Salesforce that are being used in reports to evaluate historical trends. Performance has become an issue, as well as data storage limits. Which two strategies should be recommended when talking with stakeholders?","options":["A. Combine Analytics Snapshots with a purging plan by reporting on the snapshot data and deleting the original records.","B. Use scheduled batch Apex to copy aggregate information into a custom object and delete the original records.","C. Use Data Loader to extract data, aggregate it, and write it back to a custom object, then delete the original records.","D. Configure the Salesforce Archiving feature to archive older records and remove them from the data storage limits."],"answer":"B,D","title":"Question 120","explanation":""},{"content":"Universal Containers (UC) wants to store product data in Salesforce, but the standard Product object does not support the more complex hierarchical structure which is currently being used in the product master system.\nHow can UC modify the standard Product object model to support a hierarchical data structure in order to synchronize product data from the source system to Salesforce?","options":["A. Create a custom lookup field on the standard Product to reference the parent record in the hierarchy.","B. Create a custom master-detail field on the standard Product to reference the child record in the hierarchy.","C. Create an Apex trigger to synchronize the Product Family standard picklist field on the Product object.","D. Create a custom lookup filed on the standard Product to reference the child record in the hierarchy."],"answer":"A","title":"Question 121","explanation":""},{"content":"Northern Trail Outfitters (NTO) has implemented Salesforce for its sales users. The opportunity management in Salesforce is implemented as follows:\n1. Sales users enter their opportunities in Salesforce for forecasting and reporting purposes.\n2. NTO has a product pricing system (PPS) that is used to update Opportunity Amount field on opportunities on a daily basis.\n3. PPS is the trusted source within NTO for Opportunity Amount.\n4. NTO uses Opportunity Forecast for its sales planning and management.\nSales users have noticed that their updates to the Opportunity Amount field are overwritten when PPS updates their opportunities.\nHow should a data architect address this overwriting issue?","options":["A. Create a custom field for Opportunity amount that PPS updates separating the field sales user updates.","B. Change PPS integration to update only Opportunity Amount field when the value is null.","C. Create a custom field for Opportunity Amount that sales users update separating the field that PPS updates.","D. Change Opportunity Amount field access to Read Only for sales users using field-level security."],"answer":"C","title":"Question 122","explanation":""},{"content":"Two million Opportunities need to be loaded in different batches into Salesforce using the Bulk API in parallel mode.\nWhat should an Architect consider when loading the Opportunity records?","options":["A. Group batches by the AccountId field.","B. Create indexes on Opportunity object text fields.","C. Use the Name field values to sort batches.","D. Order batches by Auto-number field."],"answer":"A","title":"Question 123","explanation":""},{"content":"Cloud Kicks has the following requirements:\n* Their Shipment custom object must always relate to a Product, a Sender, and a Receiver (all separate custom objects).\n* If a Shipment is currently associated with a Product, Sender, or Receiver, deletion of those records should not be allowed.\n* Each custom object must have separate sharing models.\nWhat should an Architect do to fulfill these requirements?","options":["A. Create two Master-Detail and one Lookup relationship to the parent records.","B. Create a Master-Detail relationship to each of the three parent records.","C. Create a required Lookup relationship to each of the three parent records.","D. Associate the Shipment to each parent record by using a VLOOKUP formula field."],"answer":"C","title":"Question 124","explanation":""},{"content":"NTO has outgrown its current salesforce org and will be migrating to new org shortly. As part of this process NTO will be migrating all of its metadata and dat a. NTO's data model in the source org has a complex relationship hierarchy with several master detail and lookup relationships across objects, which should be maintained in target org.\nWhat 3 things should a data architect do to maintain the relationship hierarchy during migration?\nChoose 3 answers:","options":["A. Use data loader to export the data from source org and then import or Upsert into the target org in sequential order.","B. Redefine the master detail relationship fields to lookup relationship fields in the target org.","C. Keep the relationship fields populated with the source record ID's in the import file.","D. Create a external id field for each object in the target org and map source record ID's to this field.","E. Replace source record ID's with new record ID's from the target org in the import file."],"answer":"A,D,E","title":"Question 125","explanation":""},{"content":"The invoicing system at Universal Containers requires that attachments associated with the Invoice _c custom object be classified by Types (i.e., \"Receipt,\" \"Invoice PDF,\" etc.) so that reporting can be done on invoices showing the number of attachments grouped by Type. What approach should be taken to categorize the attachments to meet these requirements?","options":["A. Create a custom picklist field for the Type on the standard Attachment object with the values.","B. Add additional options to the standard ContentType picklist field for the Attachment object.","C. Create a custom object related to the Invoice object with a picklist field for the Type.","D. Add a ContentType picklist field to the Attachment layout and create additional picklist options."],"answer":"C","title":"Question 126","explanation":""},{"content":"Universal Containers has deployed Salesforce for case management The company is having difficulty understanding what percentage of cases are resolved from the initial call to their support organization. What first step is recommended to implement a reporting solution to measure the support reps case closure rates?","options":["A. Create a report on Case analytic snapshots.","B. Create Contact and Opportunity Reports and Dashboards.","C. Install AppExchange packages for available reports.","D. Enable field history tracking on the Case object."],"answer":"D","title":"Question 127","explanation":""},{"content":"","options":[],"answer":"","title":"Question ","explanation":""},{"content":"Universal Container is Implementing salesforce and needs to migrate data from two legacy systems. UC would like to clean and duplicate data before migrate to Salesforce.\nWhich solution should a data architect recommend a clean migration?","options":["A. Define external IDs for an object, migrate second database to first database, and load into Salesforce.","B. Define duplicate rules in Salesforce, and load data into Salesforce from both databases.","C. Set up staging data base, and define external IDs to merge, clean duplicate data, and load into Salesforce.","D. Define external IDs for an object, Insert data from one database, and use upsert for a second database"],"answer":"D","title":"Question 129","explanation":""}]